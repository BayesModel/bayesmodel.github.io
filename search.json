[{"path":"index.html","id":"contexto","chapter":"Unidad 1 Contexto","heading":"Unidad 1 Contexto","text":"El curso “Una primera aproximación la Estadística Bayesiana”, con una duración de 10 horas, está ofertado alumnado de doctorado con una formación científica en el ámbito BIO.El curso se desarrollará íntegramente online través de videoconferencia síncrona, durante un total de 10 horas, seccionadas en 4 sesiones de dos horas y media cada una de ellas, los días 8, 10, 15 y 17 de noviembre de 2022, de 16 18:30h.Se presentarán los contenidos través de ejemplos prácticos programados en R, para que el estudiantado pueda ir generando resultados y comentando las interpretaciones derivadas del análisis.La evaluación es continua basada en la interacción con el profesorado durante las sesiones de trabajo.","code":""},{"path":"index.html","id":"objetivos-de-aprendizaje","chapter":"Unidad 1 Contexto","heading":"1.1 Objetivos de aprendizaje","text":"Conocer los conceptos básicos en el planteamiento bayesiano de la Estadística.Identificar la relevancia de la información previa y de expertos, y la proporcionada por los datos.Conocer los procedimientos básicos para conjugar la información disponible.Aplicar los conocimientos básicos en problemas sencillos.Descubrir las dificultades computacionales en la inferencia bayesiana.","code":""},{"path":"index.html","id":"contenidos-propuestos","chapter":"Unidad 1 Contexto","heading":"1.2 Contenidos propuestos","text":"De probabilidad va la historia: la relevancia de las probabilidades condicionadas y el teorema de Bayes.La jerga base: incertidumbre, priori, posteriori y verosímil.Manos en la masa 1: ¿con qué probabilidad ocurrió?Manos en la masa 2: ¿con qué abundancia ocurrió?Curioseando para saber más: manuales y software.","code":""},{"path":"index.html","id":"contenidos-definitivos","chapter":"Unidad 1 Contexto","heading":"1.3 Contenidos definitivos","text":"SESIÓN 1: Probabilidades, Bayes y las proporciones.SESIÓN 2: INLA y la regresión.SESIÓN 3: INLA y el ANOVA.SESIÓN 4: INLA y los GLM.","code":""},{"path":"index.html","id":"inla","chapter":"Unidad 1 Contexto","heading":"1.4 INLA","text":"INLA es una librería de R que aproxima la inferencia Bayesiana para\nmodelos gausianos latentes (LGM). Sus siglas provienen de Integrated\nNested Laplace Approximation (INLA), que es un método para aproximar las\ninferencias bayesianas través de la aproximación de Laplace.Aunque la metodología INLA se ha desarrollado sobre modelos que se\npueden expresar como campos aleatorios markovianos gausianos (Gaussian\nMarkov random fields, GMRF), es viable para una gran familia de modelos\nhabituales en la práctica estadística.Disponemos de referencias múltiples y documentación de esta librería en\nla web r-inla.org, y en particular en el\nmanual de referencia de Gómez-Rubio (2021) titulado Bayesian inference\nINLA,\ntambién publicado por Chapman & Hall-CRC\nPress.","code":""},{"path":"index.html","id":"instalación","chapter":"Unidad 1 Contexto","heading":"1.4.1 Instalación","text":"Para instalar la librería INLA hemos de ejecutar, desde R, el comandoPara instalar actualizaciones, basta con ejecutarLas descargas y documentación completa sobre INLA está disponible en\nR-INLA home.Ya desde R, para pedir ayuda sobre funciones en INLA, basta usar el\ncomando inla.doc(), especificando dentro y entrecomillada, la\nfunción/objeto sobre el que se solicita ayuda. Por ejemplo,\ninla.doc(\"ar1\") o inla.doc(\"loggamma\").También utilizaremos una librería accesoria de INLA, brinla, desarrollada por Faraway, Yue y Wan, 2022.","code":"\ninstall.packages(\"INLA\", repos=c(getOption(\"repos\"), \n                INLA=\"https://inla.r-inla-download.org/R/stable\"), \n                dep=TRUE)\n# y a continuación la cargamos con:\nlibrary(INLA)\noptions(repos = c(getOption(\"repos\"), \n                  INLA=\"https://inla.r-inla-download.org/R/testing\"))\nupdate.packages(\"INLA\", dep=TRUE)\ninstall.packages(\"remotes\")\nremotes::install_github(\"julianfaraway/brinla\")"},{"path":"index.html","id":"fundamentos","chapter":"Unidad 1 Contexto","heading":"1.4.2 Fundamentos","text":"INLA está basado en la resolución de integrales vía la aproximación de\nLaplace, que aproxima el integrando través de una expansión de Taylor\nde segundo grado que permite calcular la integral analíticamente.\n\\[\\begin{eqnarray*}\nI_n&=&\\int_x exp[nf(x)]dx \\\\\n&\\approx& \\int_x exp[n(f(x_0)+1/2 (x-x_0)^2 f''(x_0))] dx \\\\\n&=& exp[nf(x_0)] \\cdot \\sqrt{\\frac{2\\pi}{-n f''(x_0)}}\n\\end{eqnarray*}\\]Evita así los largos tiempos de simulación de las cadenas de Markov\nMonte Carlo. Cuando las distribuciones integrar son Gausianas, Laplace\nda órdenes buenos de aproximación. Y este es el principio que usa para\nmodelizar la mayoría de los modelos habituales, que se integran dentro\nde la amplia clase de los modelos gausianos latentes, en los que se\naplica INLA.INLA se ha aplicado en mapeo estadístico, modelos de cohorte\nmultidimensionales, modelos de asociación espacial, genética, análisis\nmedioambientales, salud y epidemiología, dinámicas de infecciones,\nestudios agronómicos, meta-análisis, impacto del cambio climático y\nmuchos más ámbitos (Rue et al, 2017).","code":""},{"path":"inlabasics.html","id":"inlabasics","chapter":"Unidad 2 Regresión lineal","heading":"Unidad 2 Regresión lineal","text":"","code":""},{"path":"inlabasics.html","id":"introducción","chapter":"Unidad 2 Regresión lineal","heading":"2.1 Introducción","text":"Una vez presentados los fundamentos de INLA vamos utilizarlo para trabajar progresivamente desde los modelos más sencillos los más sofisticados. Empezamos aquí con el modelo de regresión lineal simple, para continuar generalizando con el de regresión lineal múltiple.Partimos de la base de datos Davis (en la librería carData), que contiene 200 registros de 5 variables relacionadas con un estudio sobre habituación de hombres y mujeres la realización de ejercicio físico de forma regular. Las variables que se registraron son sexo, peso y altura (reales y reportados). Vamos indagar la relación entre el peso real (weight) y el reportado (repwt) través de un análisis de regresión lineal simple.","code":"\ndata(Davis,package=\"carData\")\nplot(weight ~ repwt, data=Davis)\n# Excluimos el valor outlier y los NA\ndavis=Davis %>%\n  filter(weight<160) %>%\n  slice(which(!is.na(repwt)))"},{"path":"inlabasics.html","id":"variables-y-relaciones","chapter":"Unidad 2 Regresión lineal","heading":"2.2 Variables y relaciones","text":"Entendemos como variable respuesta y=weight, de tipo numérico (continua), y como variable explicativa o covariable, x=repwt, también numérica.La especificación de respuesta \\(y\\) y predictores \\(x_1,x_2,...\\), en INLA se registra en una fórmula del tipo:en la que podemos prescindir del \\(1\\) que identifica la interceptación, pues el ajuste, por defecto, siempre se resolverá con su estimación, salvo que en su lugar se escriba un ‘-1’.En nuestro problema tendríamos pues:continuación es procedente elegir el modelo sobre la respuesta, o lo\nque es lo mismo, la verosimilitud.","code":"\nformula= y ~ 1 + x_1 + x_2 +...\nformula = weight ~ repwt"},{"path":"inlabasics.html","id":"verosimilitud","chapter":"Unidad 2 Regresión lineal","heading":"2.3 Verosimilitud","text":"En principio es razonable asumir normalidad en la respuesta, además de independencia entre todas las observaciones. Así, el modelo propuesto para la respuesta es:\\[(y_i|\\mu_i,\\sigma^2) \\sim N(\\mu_i,\\sigma^2), =1,...,n\\]donde y=weight y x=repwt, e \\(=1,...,n\\) es un subíndice que identifica cada uno de los registros disponibles en el banco de datos. La media esperada contiene la relación lineal entre covariable y respuesta, \\(\\mu_i=\\theta+\\beta x_i\\), donde \\(\\theta\\) es la interceptación de la recta de regresión y \\(\\beta\\) el coeficiente que explica la relación lineal entre \\(x\\) e \\(y\\). El vector \\((\\theta,\\beta)\\) identifica los efectos latentes, en cuya inferencia posterior estamos interesados, y que están involucrados directamente en la media o predictor lineal. El modelo, o lo que es lo mismo, la verosimilitud, depende también de un parámetro de dispersión \\(\\sigma^2\\) sobre el que también querremos inferir.Veamos cómo especificar este modelo con INLA. La función names(inla.models()) proporciona un listado de todos los\ntipos de modelos posibles, tanto para los datos (likelihood), para los efectos latentes (latent), los parámetros\n(prior), y otras opciones que de momento nos interesan. El listado completo de todas las distribuciones disponibles para cada uno de los tipos de modelos lo obtenemos con el comando inla.list.models(). En particular, si ejecutamos names(inla.models()$likelihood), obtenemos todas las distribuciones disponibles para modelizar los datos.La distribución gaussian identifica la distribución normal que hemos planteado en nuestro modelo de regresión lineal. Para obtener información sobre cómo está parametrizada y cuáles son las priors por defecto, basta consultar la documentación gaussian con el comando:Para ajustar un modelo sencillo en INLA hay que echar mano de la función inla, en la que introducimos en primer lugar la formula, con la relación entre las variables, continuación el modelo, en el argumento family, y después el banco de datos sobre el que trabajamos. Si especificamos el argumento family, la función inla interpreta por defecto la opción gaussian, esto es, normalidad para los datos, de modo que podríamos excluir dicha especificación cuando modelizamos datos normales.Adelantamos pues un paso más en nuestro problema, añadiendo la verosimilitud normal y la base de datos.","code":"\n# documentación (parametrización y priors) del modelo normal\ninla.doc(\"gaussian\")\n# Asumiendo datos normales\nfit=inla(formula,family=\"gaussian\", data)\n# equivalente a\nfit=inla(formula, data)\n# ajuste del modelo\nformula = weight ~ 1+ repwt\nfit=inla(formula,family=\"gaussian\",data=davis)"},{"path":"inlabasics.html","id":"hiperparámetros","chapter":"Unidad 2 Regresión lineal","heading":"2.4 Hiperparámetros","text":"INLA identifica como hiperparámetros todos aquellos parámetros en el modelo que se corresponden con efectos latentes, esto es, relacionados con el predictor o respuesta esperada. En nuestro modelo, el único hiperparámetro es la varianza \\(\\sigma^2\\), sobre la que es preciso especificar una distribución priori. Para la varianza \\(\\sigma^2\\) es habitual asumir una gamma inversa difusa, con media y varianza grandes.En INLA, en lugar de asignar distribuciones priori sobre las\nvarianzas, se hace sobre el logaritmo de las precisiones, para facilitar\nel cálculo del máximo de la log-posterior (obtenida de la\nlog-verosimilitud y la log-prior). Así, asumir una gamma inversa difusa\n\\(GaI(\\alpha,\\beta)\\) para la varianza es equivalente una Gamma difusa\n\\(Ga(\\alpha,\\beta)\\) para la precisión \\(\\tau=1/\\sigma^2\\), y una\nlog-gamma difusa \\(Log-Gamma(\\alpha,\\beta)\\) para la log-precisión\n\\(log(\\tau)\\).Por defecto, como ya verificamos en la documentación de la verosimilitud gausiana, (con inla.doc(\"gaussian\")), la distribución priori por defecto sobre la log-precisión (\\(\\theta_1\\) en la ayuda) es la log-gamma difusa \\(LogGa(1,5\\cdot 10^{-5})\\), lo que da un valor esperado para la precisión \\(\\tau\\) de 20000 y una varianza de \\(4\\cdot 10^8\\).Para modificar la distribución priori de un parámetro podemos utilizar cualquiera de las distribuciones que ofrece INLA en su listado names(inla.models()$prior) (siempre buscando coherencia con la información sobre el parámetro en cuestión).Para definir una prior para los parámetros o hiperparámetros en INLA hay\nque definir los siguientes argumentos:prior, el nombre de la distribución priori (para hiperparámetros, alguna de las opciones en names(inla.models()$prior))param, los valores de los parámetros de la priorinitial, el valor inicial para el hiperparámetrofixed, variable booleana para decir si el hiperparámetro es fijo o aleatorio.La modificación la haremos con el argumento control.family=list(hyper=list(...)) en la función inla, al que le proporcionaremos una lista con el nombre de los parámetros (el short name con el que los identifica INLA en la documentación), que apunta una lista con la distribución (prior) y los parámetros (param) utilizar.En nuestro problema, si tenemos información previa sobre la precisión del modelo, reconocida como prec (short name), y queremos especificar una priori \\(Ga(1,0.001)\\) para la precisión, habremos de utilizar la siguiente sintaxis:Si nos conformamos con la previa por defecto de INLA, el modelo que estamos asumiendo en nuestro problema de regresión lineal simple será:\\[\\begin{eqnarray*}\n(y_i|\\mu_i,\\sigma^2) &\\sim & N(\\mu_i,\\sigma^2), =1,...,n \\\\\n\\tau=1/\\sigma^2 & \\sim & Ga(1,0.00005)\n\\end{eqnarray*}\\]","code":"\nprec.info = list(prior=\"loggamma\", param =c(1,0.001))\nfit2=inla(formula,family=\"gaussian\",data=davis,\n      control.family = list(hyper = list(prec = prec.info)))"},{"path":"inlabasics.html","id":"efectos-fijos","chapter":"Unidad 2 Regresión lineal","heading":"2.5 Efectos fijos","text":"Una variable explicativa entra en el modelo como efecto fijo cuando\nse piensa que afecta todas las observaciones del mismo modo, y que su efecto es de interés primario en el estudio.En un modelo de regresión lineal todos los efectos latentes en el predictor lineal, interceptación y coeficientes de covariables, son efectos fijos. Ante ausencia de información, las priors para los efectos fijos, esto es, (\\(\\theta,\\beta\\)) en nuestro caso, se asumen normales centradas en cero y con varianzas grandes. En INLA la interceptación \\(\\beta\\) tiene por defecto una prior gausiana con media y precisión igual cero (una distribución plana objetiva, que integra 1), y los coeficientes \\(\\beta\\) también tienen una prior gausiana con media cero y precisión igual 0.001. Estos valores por defecto se pueden consultar con el comando inla.set.control.fixed.default(), que da la siguiente información:mean=0 y mean.intercept=0 son las medias de la distribución normal para los coeficientes \\(\\beta\\) y la interceptación \\(\\theta\\) respectivamenteprec=0.001 y prec.intercept=0 son las precisiones respectivas de las normales para \\(\\beta\\) y \\(\\theta\\).Con todo, los parámetros de las priors sobre los efectos fijos se pueden modificar través del argumento control.fixed=list(...) en la función inla, utilizando siempre los nombres que atribuye INLA los diferentes parámetros e hiperparámetros (short name). Por ejemplo, si queremos modificar la precisión de los efectos fijos para hacerla igual 0.001 (esto es, varianza 1000), utilizamos la siguiente sintaxis:Volvemos sobre nuestro ejemplo, y asumiendo las priori por defecto de INLA tendremos:\n\\[\\begin{eqnarray*}\n(y_i|\\theta,\\beta,\\sigma^2) & \\sim & N(\\theta+\\beta x_i,\\sigma^2), =1,...,n \\\\\n\\theta & \\sim & N(0,\\infty) \\\\\n\\beta & \\sim & N(0,1000) \\\\\n\\tau=1/\\sigma^2 & \\sim & Ga(1,0.00005)\n\\end{eqnarray*}\\]","code":"\nformula = weight ~ 1+ repwt\nfit=inla(formula,family=\"gaussian\",data=davis,\n         control.fixed=list(prec=0.001,prec.intercept=0.001))"},{"path":"inlabasics.html","id":"resultados","chapter":"Unidad 2 Regresión lineal","heading":"2.6 Resultados","text":"Para mostrar una descriptiva de los resultados del ajuste obtenido con fit=inla(...),\nutilizamos la sintaxis siguiente:summary(fit) proporciona una descriptiva del ajustenames(fit$marginals.fixed) lista los nombres de todos los efectos fijosfit$summary.fixed resume la inferencia posterior sobre los efectos fijosnames(fit$marginals.hyperpar) lista los nombres de todos los hiperparámetrosfit$summary.hyperpar da un resumen de la inferencia posterior de\nlos parámetros e hiperparámetrosfit$summary.fitted.values resume la inferencia posterior sobre los valores ajustadosfit$mlik da la estimación de la log-verosimilitud marginal, útil para evaluar y comparar modelos.Veamos los resultados para nuestro problema de regresión.Obtenemos pues la salida con un descriptivo de la distribución posterior para los efectos fijos interceptación, \\(\\theta\\), y el coeficiente del regresor repwt, \\(\\beta\\), con la media, desviación típica y cuantiles con los que podemos evaluar la región creíble al 95%.También muestra continuación una tabla con los descriptivos de la distribución posterior para la precisión \\(\\tau=1/\\sigma^2\\) de los datos.Si queremos obtener los nombres con los que INLA reconoce los efectos fijos (interceptación y coeficiente del regresor) e hiperparámetros (precisión de los datos), llamamos aY podemos pedir descriptivos específicos de las distribuciones de los efectos fijos y de los hiperparámetros.Para describir la marginal posterior sobre cada uno de los datos ajustados:Si queremos hacer un análisis de sensibilidad sobre las distribuciones priori, reajustamos el modelo con otras priors y comparamos los resultados.","code":"\n# ajuste del modelo \nformula = weight ~ 1+ repwt\nfit=inla(formula,family=\"gaussian\",data=davis)\nsummary(fit)\n#> \n#> Call:\n#>    c(\"inla.core(formula = formula, family = family, \n#>    contrasts = contrasts, \", \" data = data, quantiles = \n#>    quantiles, E = E, offset = offset, \", \" scale = \n#>    scale, weights = weights, Ntrials = Ntrials, strata = \n#>    strata, \", \" lp.scale = lp.scale, link.covariates = \n#>    link.covariates, verbose = verbose, \", \" lincomb = \n#>    lincomb, selection = selection, control.compute = \n#>    control.compute, \", \" control.predictor = \n#>    control.predictor, control.family = control.family, \n#>    \", \" control.inla = control.inla, control.fixed = \n#>    control.fixed, \", \" control.mode = control.mode, \n#>    control.expert = control.expert, \", \" control.hazard \n#>    = control.hazard, control.lincomb = control.lincomb, \n#>    \", \" control.update = control.update, \n#>    control.lp.scale = control.lp.scale, \", \" \n#>    control.pardiso = control.pardiso, only.hyperparam = \n#>    only.hyperparam, \", \" inla.call = inla.call, inla.arg \n#>    = inla.arg, num.threads = num.threads, \", \" \n#>    blas.num.threads = blas.num.threads, keep = keep, \n#>    working.directory = working.directory, \", \" silent = \n#>    silent, inla.mode = inla.mode, safe = FALSE, debug = \n#>    debug, \", \" .parent.frame = .parent.frame)\") \n#> Time used:\n#>     Pre = 2.5, Running = 0.19, Post = 0.0225, Total = 2.71 \n#> Fixed effects:\n#>              mean    sd 0.025quant 0.5quant 0.975quant mode\n#> (Intercept) 2.734 0.814      1.135    2.734      4.333   NA\n#> repwt       0.958 0.012      0.935    0.958      0.982   NA\n#>             kld\n#> (Intercept)   0\n#> repwt         0\n#> \n#> Model hyperparameters:\n#>                                          mean    sd\n#> Precision for the Gaussian observations 0.199 0.021\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.161    0.198\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.242   NA\n#> \n#> Marginal log-Likelihood:  -426.74 \n#>  is computed \n#> Posterior summaries for the linear predictor and the fitted values are computed\n#> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')\nfit$mlik\n#>                                            [,1]\n#> log marginal-likelihood (integration) -426.7364\n#> log marginal-likelihood (Gaussian)    -426.7356\nnames(fit$marginals.fixed)\n#> [1] \"(Intercept)\" \"repwt\"\nnames(fit$marginals.hyperpar)\n#> [1] \"Precision for the Gaussian observations\"\n# descriptivos efectos fijos\nfit$summary.fixed\n#>                  mean         sd 0.025quant  0.5quant\n#> (Intercept) 2.7338115 0.81434226  1.1349853 2.7338114\n#> repwt       0.9583742 0.01213599  0.9345471 0.9583742\n#>             0.975quant mode          kld\n#> (Intercept)  4.3326384   NA 6.170374e-10\n#> repwt        0.9822012   NA 6.170055e-10\n# descriptivos varianza\nfit$summary.hyperpar\n#>                                              mean\n#> Precision for the Gaussian observations 0.1990648\n#>                                                 sd\n#> Precision for the Gaussian observations 0.02084997\n#>                                         0.025quant\n#> Precision for the Gaussian observations  0.1609615\n#>                                          0.5quant\n#> Precision for the Gaussian observations 0.1983573\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations  0.2417812   NA\n# medias de los efectos fijos\nfit$summary.fixed$mean\n#> [1] 2.7338115 0.9583742\n# descriptivos primer efecto fijo\nfit$summary.fixed[1,]\n#>                 mean        sd 0.025quant 0.5quant\n#> (Intercept) 2.733812 0.8143423   1.134985 2.733811\n#>             0.975quant mode          kld\n#> (Intercept)   4.332638   NA 6.170374e-10\nhead(fit$summary.fitted.values)\n#>                          mean        sd 0.025quant 0.5quant\n#> fitted.Predictor.001 76.52862 0.2162585   76.10407 76.52862\n#> fitted.Predictor.002 51.61089 0.2441367   51.13162 51.61089\n#> fitted.Predictor.003 54.48602 0.2189954   54.05610 54.48602\n#> fitted.Predictor.004 69.82000 0.1750262   69.47640 69.82000\n#> fitted.Predictor.005 59.27789 0.1855915   58.91354 59.27789\n#> fitted.Predictor.006 75.57025 0.2087564   75.16043 75.57025\n#>                      0.975quant mode\n#> fitted.Predictor.001   76.95317   NA\n#> fitted.Predictor.002   52.09017   NA\n#> fitted.Predictor.003   54.91594   NA\n#> fitted.Predictor.004   70.16360   NA\n#> fitted.Predictor.005   59.64223   NA\n#> fitted.Predictor.006   75.98007   NA\n# ajuste del modelo \nformula = weight ~ 1+ repwt\nfit2=inla(formula,family=\"gaussian\",data=davis,\n         control.fixed = list(mean.intercept = 100, \n                                 prec.intercept = 0.001,\n                                 prec = 0.001), \n            control.family = list(hyper = list(\n              prec = list(prior=\"loggamma\", param =c(1,0.001)))))\nfit2$summary.fixed\n#>                 mean         sd 0.025quant 0.5quant\n#> (Intercept) 2.798268 0.81410178  1.2008931 2.797925\n#> repwt       0.957434 0.01213256  0.9335996 0.957439\n#>             0.975quant mode          kld\n#> (Intercept)   4.397591   NA 6.327950e-10\n#> repwt         0.981240   NA 6.322509e-10\nfit2$summary.hyperpar\n#>                                              mean\n#> Precision for the Gaussian observations 0.1990957\n#>                                                 sd\n#> Precision for the Gaussian observations 0.02084583\n#>                                         0.025quant\n#> Precision for the Gaussian observations  0.1608887\n#>                                          0.5quant\n#> Precision for the Gaussian observations 0.1983734\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations  0.2417365   NA"},{"path":"inlabasics.html","id":"distribuciones-posteriores","chapter":"Unidad 2 Regresión lineal","heading":"2.7 Distribuciones posteriores","text":"Para obtener la distribución marginal de los valores ajustados y predichos necesitamos incorporar la función inla el argumento control.compute=list(return.marginals.predictor=TRUE).Tras conseguir un ajuste con inla, podemos acceder todas las distribuciones marginales posteriores y predictivas través de:fit$marginals.fixed da las distribuciones posteriores marginales de los efectos fijosfit$marginals.fixed$xx da la distribución del efecto fijo xx, y también se puede seleccionar con su ordinal en el conjunto de efectos fijos fit$marginals.fixed[[]]fit.marginals.hyperpar da las distribuciones posteriores marginales de los parámetros e hiperparámetrosfit$marginals.fitted.values da las distribuciones posteriores marginales para los valores ajustadosCon estas distribuciones, reconocidas como marginal, podemos hacer cálculos y gráficos de interés través de estas funciones que operan sobre las distribuciones y que podemos consultar con ?inla.marginal:inla.dmarginal(x, marginal, ...) da la densidad en xinla.pmarginal(q, marginal, ...) da las probabilidades o función de distribucióninla.qmarginal(p, marginal,...) da los cuantilesinla.rmarginal(n, marginal) permite obtener \\(n\\) simulacionesinla.hpdmarginal(p, marginal,...) da la región HPDinla.smarginal(marginal, ...) da un suavizado con splines de la distribución marginalinla.emarginal(fun, marginal, ...) calcula el valor esperado de una funcióninla.mmarginal(marginal,...) calcula la moda posteriorinla.tmarginal(fun, marginal,...) transforma la distribución marginal de una función del parámetroinla.zmarginal(marginal,...) calcula descriptivos de la marginal.Veamos algunos ejemplos sobre nuestro problema. Vamos mostrar continuación, en un único gráfico, las distribuciones posteriores de los efectos fijos y el parámetro de dispersión de los datos $, con líneas verticales que marquen el valor esperado posterior (en azul) y el HPD95% en rojo.Si queremos la distribución posterior de alguna de las medias \\(\\mu_i=\\theta+ \\beta x_i\\), necesitamos añadir el argumento control.compute=list(return.marginals.predictor=TRUE) en inla. Así podremos representar, por ejemplo, la distribución posterior sobre el peso esperado para el individuo que aparece en el registro 1 de la base de datos, \\(\\mu_1=\\theta+\\beta x_1\\):","code":"\n# library(gridExtra)\n# library(ggplot2)\n\ng=list() # lista en que almacenamos los gráficos con d.posteriores\n# Efectos fijos\nnames.fixed=names(fit$marginals.fixed)\nn.fixed=length(names.fixed)\nnames=c(expression(theta),expression(beta))\nfor (i in 1:n.fixed){\n g[[i]] = ggplot(as.data.frame(fit$marginals.fixed[[i]])) + \n  geom_line(aes(x = x, y = y)) +\n  labs(x=names[i],y=\"\")+\n   geom_vline(xintercept=inla.hpdmarginal(0.95,fit$marginals.fixed[[i]]),\n             linetype=\"dashed\",color=\"red\")+\n  geom_vline(xintercept=inla.emarginal(function(x) x,fit$marginals.fixed[[i]]),\n             linetype=\"dashed\",color=\"blue\")\n}\n\n\n# Parámetros\ng[[3]]= ggplot(as.data.frame(fit$marginals.hyperpar[[1]])) + \n  geom_line(aes(x = x, y = y)) +\n  labs(x=expression(tau),y=\"\")+\n  geom_vline(xintercept=inla.hpdmarginal(0.95,fit$marginals.hyperpar[[1]]),\n             linetype=\"dashed\",color=\"red\")+\n  geom_vline(xintercept=inla.emarginal(function(x) x,fit$marginals.hyperpar[[1]]),\n             linetype=\"dashed\",color=\"blue\")\n\n# Transformamos la posterior en tau para obtener la posterior de sigma\nsigma.post=inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[1]])\n# y la pintamos\ng[[4]]= ggplot(as.data.frame(sigma.post)) + \n  geom_line(aes(x = x, y = y)) +\n  labs(x=expression(sigma),y=\"\")+\n  geom_vline(xintercept=inla.hpdmarginal(0.95,sigma.post),\n             linetype=\"dashed\",color=\"red\")+\n  geom_vline(xintercept=inla.emarginal(function(x) x,sigma.post),\n             linetype=\"dashed\",color=\"blue\")\n\nlibrary(gridExtra)\ngrid.arrange(g[[1]],g[[2]],g[[3]],g[[4]],ncol=2)\nfit=inla(formula,family=\"gaussian\",data=davis,\n         control.compute=list(return.marginals.predictor=TRUE))\nggplot(as.data.frame(fit$marginals.fitted.values[[1]]),aes(x=x,y=y))+\n  geom_line()+\n  labs(x=expression(mu[1]),y=\"D.Posterior\")"},{"path":"inlabasics.html","id":"simulación-de-la-posterior","chapter":"Unidad 2 Regresión lineal","heading":"2.8 Simulación de la posterior","text":"Cuando queremos inferir sobre funciones de los efectos latentes e hiperparámetros que proporciona INLA por defecto , podemos recurrir simular de las distribuciones posteriores de los efectos involucrados, y con ellas evaluar la función que nos interesa, para conseguir una muestra de su distribución posterior.Para ello es preciso que al ajustar el modelo con inla hayamos incluido el argumento control.compute=list(config=TRUE).Para obtener simulaciones de las correspondientes distribuciones posteriores, utilizamos las funciones:inla.posterior.sample(n, fit,selection), para simular los efectos latentes, donde \\(n\\) es el número de simulaciones pretendido, fit es el ajuste obtenido con inla y selection es una lista con el nombre de las componentes (efectos latentes) simular.inla.hyperpar.sample(n,fit,improve.marginals=TRUE) para simular de parámetros e hiperparámetros.Para describir las distribuciones de los nuevos parámetros que queremos evaluar con dichas simulaciones, utilizaremos:inla.posterior.eval() para funciones sobre los efectos fijosinla.hyperpar.eval() para funciones sobre los hiperparámetrosImaginemos que queremos obtener la distribución posterior de \\((\\theta+\\beta \\cdot 50)\\), que correspondería con el peso real de un sujeto que ha declarado un peso de 50kg. Hemos de simular pues, de las distribuciones posteriores de \\(\\theta\\) y de \\(\\beta\\), para luego aplicar la función correspondiente sobre las simulaciones y obtener una muestra posterior de \\(\\theta+\\beta\\cdot 50\\).Esto nos devuelve una lista de la dimensión del número de simulaciones (cada simulación en un elemento de la lista), y en cada uno de los elementos tenemos los valores simulados de los hiperparámetros (hyper), de los efectos latentes (latent)y la log-densidad de la posterior en esos valores (logdens)Ahora con la función inla.posterior.sample.eval, dado que nuestra función depende de efectos fijos (latentes), \\((\\theta,\\beta)\\), evaluamos la operación pretendida, y con descriptivos gráficos y numéricos de las simulaciones, podemos aproximar los descriptivos de la distribución posterior.","code":"\n# reajustamos para poder simular de las posterioris\nfit <- inla(formula, data = davis,\n  control.compute = list(config = TRUE))\n# simulamos especificando los parámetros en los que tenemos interés\nsims = inla.posterior.sample(100, fit, selection = list(\"(Intercept)\"=1,repwt = 1))\nlength(sims)\n#> [1] 100\nnames(sims[[1]])\n#> [1] \"hyperpar\" \"latent\"   \"logdens\"\nsims[[1]]$hyperpar\n#> Precision for the Gaussian observations \n#>                               0.2505139\nsims[[1]]$latent\n#>                sample:1\n#> (Intercept):1 2.8313992\n#> repwt:1       0.9585235\n sims[[1]]$logdens\n#> $hyperpar\n#> [1] 0.2376631\n#> \n#> $latent\n#> [1] 994.2187\n#> \n#> $joint\n#> [1] 994.4563\npeso_real=inla.posterior.sample.eval(function(...) {(Intercept)+repwt*50},sims)\npeso_real\n#>        sample:1 sample:2 sample:3 sample:4 sample:5\n#> fun[1] 50.75757 51.00211 50.81452 50.48819 51.01456\n#>        sample:6 sample:7 sample:8 sample:9 sample:10\n#> fun[1] 50.65266 50.40258  50.5857 50.51099  50.74704\n#>        sample:11 sample:12 sample:13 sample:14 sample:15\n#> fun[1]  50.45872  50.79086  50.38265  50.49108  50.50584\n#>        sample:16 sample:17 sample:18 sample:19 sample:20\n#> fun[1]  51.20382  50.16677  50.70345  51.07635  51.11918\n#>        sample:21 sample:22 sample:23 sample:24 sample:25\n#> fun[1]  51.34425  49.92724  50.53316  50.60164  50.66512\n#>        sample:26 sample:27 sample:28 sample:29 sample:30\n#> fun[1]  50.89163  50.86119  50.57894  50.60078  50.73711\n#>        sample:31 sample:32 sample:33 sample:34 sample:35\n#> fun[1]  50.68396  50.80576  50.92342   50.4854  50.70413\n#>        sample:36 sample:37 sample:38 sample:39 sample:40\n#> fun[1]  50.38373  50.61038   50.9331  50.24209  51.06696\n#>        sample:41 sample:42 sample:43 sample:44 sample:45\n#> fun[1]  50.31825  50.51111  50.68007  50.72257  50.52619\n#>        sample:46 sample:47 sample:48 sample:49 sample:50\n#> fun[1]  50.72865  50.44717  50.61546  50.98671  50.75872\n#>        sample:51 sample:52 sample:53 sample:54 sample:55\n#> fun[1]  50.77419  51.16021  50.64901  50.60562  51.14359\n#>        sample:56 sample:57 sample:58 sample:59 sample:60\n#> fun[1]  50.58056  50.81765  50.72873  50.29278  50.58415\n#>        sample:61 sample:62 sample:63 sample:64 sample:65\n#> fun[1]  50.54525  50.80294  50.69425  50.49219  50.50537\n#>        sample:66 sample:67 sample:68 sample:69 sample:70\n#> fun[1]  50.73417  50.57529  50.60725  50.37823  50.70478\n#>        sample:71 sample:72 sample:73 sample:74 sample:75\n#> fun[1]  50.77854  50.33784  50.52722  50.76166  50.24785\n#>        sample:76 sample:77 sample:78 sample:79 sample:80\n#> fun[1]  50.47597  50.74489  50.41521  50.71571  50.72621\n#>        sample:81 sample:82 sample:83 sample:84 sample:85\n#> fun[1]  50.68913  50.49569  50.33421  50.70655  50.35378\n#>        sample:86 sample:87 sample:88 sample:89 sample:90\n#> fun[1]  50.56429  50.37601  50.97446  50.73115  50.55942\n#>        sample:91 sample:92 sample:93 sample:94 sample:95\n#> fun[1]  50.55898  50.58556  50.70385   50.2915  50.42068\n#>        sample:96 sample:97 sample:98 sample:99 sample:100\n#> fun[1]  50.65897  50.79597  50.69118  50.66096   50.49659\npred=data.frame(peso=as.vector(peso_real))\nsummary(pred)\n#>       peso      \n#>  Min.   :49.93  \n#>  1st Qu.:50.50  \n#>  Median :50.65  \n#>  Mean   :50.65  \n#>  3rd Qu.:50.76  \n#>  Max.   :51.34\nggplot(pred,aes(x=peso))+\n  geom_histogram(aes(y=..density..), colour=\"black\", fill=\"white\")+\n  geom_density(alpha=.2, fill=\"#80E7F5\") \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"inlabasics.html","id":"regresión-lineal-múltiple-con-inla","chapter":"Unidad 2 Regresión lineal","heading":"2.9 Regresión lineal múltiple con INLA","text":"Vemos continuación cómo se trabaja la regresión múltiple con INLA, simplemente añadiendo más predictores.El modelo de regresión asume una distribución normal para los datos, datos los efectos latentes (todos los relacionados con el valor esperado o predictor lineal) y el resto de parámetros o hiperparámetros del modelo (en nuestro caso la varianza de los datos).Si tenemos \\(n\\) observaciones\n\\[ (y_i|\\mu_i,\\sigma^2) \\sim N(\\mu_i,\\sigma^2), \\ \\ =1,...n\\]\ndonde \\(\\mu_i\\) representa la media y \\(\\sigma^2\\) la varianza de los datos.\n\\[E(y_i|\\mu_i,\\sigma^2)=\\mu_i, \\ Var(y_i|\\mu_i,\\sigma^2)=\\sigma^2\\]\nSi tenemos varios regresores \\(x_1,x_2,...,x_J\\), la media \\(\\mu_i\\) coincide con el predictor lineal \\(\\eta_i\\) que se construye partir de una combinación lineal de los predictores:\n\\[\\mu_i=\\eta_i=\\theta+ \\sum_{j=1}^J \\beta_j x_{ij}\\]\nNos queda continuación especificar las distribuciones priori sobre el vector de efectos latentes, en nuestro caso efectos fijos, \\((\\theta,\\beta_1,...,\\beta_J)\\), y sobre el parámetro de dispersión o hiperparámetro \\(\\sigma^2\\).Cuando tenemos información previa especificamos distribuciones difusas (vagas) sobre los parámetros. En INLA por defecto tendremos:\\[\\begin{eqnarray*}\n\\theta &\\sim& N(0,\\sigma_{\\theta}^2)  \\\\\n\\beta_j &\\sim& N(0,\\sigma_{\\beta}^2) \\\\\nlog(\\tau=1/\\sigma^2) &\\sim& Log-Ga(1,0.00005)\n\\end{eqnarray*}\\]\ncon \\(\\sigma_{\\theta}^2=\\infty\\) y \\(\\sigma_{\\beta}^2=1000\\).Ejemplificamos el análisis de regresión lineal múltiple sobre la base de datos usair, en la librería brinla. Esta BD contiene datos recopilados para investigar los factores determinantes de la polución, utilizando el nivel de SO2 como variable dependiente y las restantes como variables explicativas potenciales. Las relaciones entre las variables que incluye se muestra en la Figura 2.1 continuación.\nFigura 2.1: Relaciones entre variables en la base de datos usair(brinla).\nApreciamos ya en el gráfico una correlación positiva muy alta entre las variables pop y manuf, y relevante para negtemp y days y también para precip y days, lo que posteriormente condicionará la selección de variables.","code":"\ndata(usair, package = \"brinla\")\nlibrary(GGally) # contiene la función de graficado 'ggpairs'\npairs.chart <- ggpairs(usair, lower = list(continuous = \"cor\"), \n                       upper = list(continuous = \"points\", combo = \"dot\"))\nggplot2::theme(axis.text = element_text(size = 6)) \n#> List of 1\n#>  $ axis.text:List of 11\n#>   ..$ family       : NULL\n#>   ..$ face         : NULL\n#>   ..$ colour       : NULL\n#>   ..$ size         : num 6\n#>   ..$ hjust        : NULL\n#>   ..$ vjust        : NULL\n#>   ..$ angle        : NULL\n#>   ..$ lineheight   : NULL\n#>   ..$ margin       : NULL\n#>   ..$ debug        : NULL\n#>   ..$ inherit.blank: logi FALSE\n#>   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n#>  - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n#>  - attr(*, \"complete\")= logi FALSE\n#>  - attr(*, \"validate\")= logi TRUE\npairs.chart"},{"path":"inlabasics.html","id":"selección-de-variables","chapter":"Unidad 2 Regresión lineal","heading":"2.9.1 Selección de variables","text":"Cuando trabajamos con más de una variable predictora en regresión lineal (realmente en cualquier modelo) surge un problema adicional, que es la selección de variables, o selección del mejor modelo de predicción. Esto se resuelve en INLA utilizando diversos criterios de selección entre los que destacamos:la verosimilitud marginal (valor de la log-verosimilitud): mlik; al cambiarle el signo tendremos -(log-likelihood)el criterio de información de la deviance (DIC): dicel criterio de información bayesiana ampliado (WAIC): waicla transformada integral predictiva (PIT): cpoEl procedimiento utilizar para la selección del modelo (de variables) es el siguiente:ajustar todos los modelos resultantes de todas las combinaciones posibles de predictoras,calcular los índices de selección para cada uno de ellosproceder con la selección en base dichos valores.Siempre se prefieren modelos con los valores más bajos para estos criterios y se descartan los que proporcionan valores más altos. Cuando es el mismo modelo el que proporciona el valor mínimo en estos criterios, habremos de optar por alguno de ellos.Por defecto, al ajustar un modelo con inla, nos devuelve la log-verosimilitud marginal (accesible con fit$mlik si el ajuste se guardó en el objeto fit). Para obtener las otras medidas de selección, hemos de incluir como argumento de la función inla, la opción control.compute = list(dic = TRUE, waic = TRUE)). Los valores por defecto de control.compute los podemos consultar ejecutando el comando inla.set.control.compute.default().Vayamos pues con el ajuste del modelo de regresión con todas las variables. Recordemos que si especificamos el argumento family, interpreta por defecto la opción gaussian, esto es, normalidad para los datos. Así ajustamos el modelo y obtenemos las siguientes inferencias sobre los efectos fijos.La inferencia posterior sobre la desviación típica de los datos, \\(\\sigma\\), la resolvemos con sus descriptivos.Para seleccionar las variables relevantes seguimos el procedimiento descrito anteriormente. Añadimos también el ajuste del modelo de regresión frecuentista, para el que calculamos como criterio de bondad de ajuste el AIC.Ya solo resta comparar los resultados, respecto de cada uno de los criterios, para seleccionar con qué variables nos quedamos, y por lo tanto con qué modelo de predicción. Basta con encontrar el modelo que proporciona el mínimo valor en cada uno de los criterios.Concluimos pues que, tanto el criterio AIC en el modelo de regresión frecuentista, como los criterios DIC y WAIC en el modelo de regresión bayesiano, proporcionan el mejor ajuste. Este mejor modelo incluye como predictores las variables ‘negtemp+manuf+pop+wind+precip’. Reajustamos el modelo con estas variables para derivar las inferencias y predicciones.Las inferencias sobre los efectos fijos y la precisión de los datos se muestran continuación.Y en la Figura 2.2 se muestran las distribuciones posteriores de todos los efectos latentes (efectos fijos) en el modelo: interceptación y coeficientes de los regresores.\nFigura 2.2: Distribuciones posteriores de los efectos latentes.\n","code":"\nformula <-  SO2 ~ negtemp + manuf + wind + precip + days\nfit= inla(formula, data = usair, \n          control.compute = list(dic = TRUE, waic = TRUE))\n#summary(fit)\nround(fit$summary.fixed,3)\n#>                mean     sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 135.492 49.867     37.145  135.500    233.798\n#> negtemp       1.769  0.634      0.518    1.769      3.020\n#> manuf         0.026  0.005      0.017    0.026      0.035\n#> wind         -3.723  1.935     -7.537   -3.723      0.093\n#> precip        0.625  0.387     -0.139    0.625      1.388\n#> days         -0.057  0.174     -0.400   -0.057      0.287\n#>             mode kld\n#> (Intercept)   NA   0\n#> negtemp       NA   0\n#> manuf         NA   0\n#> wind          NA   0\n#> precip        NA   0\n#> days          NA   0\nsigma.post= inla.tmarginal(function(tau) tau^(-1/2),\n                           fit$marginals.hyperpar[[1]])\ninla.zmarginal(sigma.post)\n#> Mean            15.6716 \n#> Stdev           1.8567 \n#> Quantile  0.025 12.5293 \n#> Quantile  0.25  14.3471 \n#> Quantile  0.5   15.4921 \n#> Quantile  0.75  16.7995 \n#> Quantile  0.975 19.8192\n# variables en la bd\nvars=names(usair)[-1] # variables predictoras (excluye v.dpte)\nnvars=length(vars) # nº variables predictoras\n\n# Truco para concatenar todos los modelos posibles en una fórmula (de Faraway)\nlistcombo <- unlist(sapply(1:nvars,\n                           function(x) combn(nvars, x, simplify=FALSE)),\n                    recursive=FALSE)\npredterms <- lapply(listcombo, \n                    function(x) paste(vars[x],collapse=\"+\"))\nnmodels <- length(listcombo)\ncoefm <- matrix(NA,length(listcombo),4,\n                dimnames=list(predterms,c(\"AIC\",\"DIC\",\"WAIC\",\"MLIK\")))\n\n# Ajuste de todos los modelos posibles\nfor(i in 1:nmodels){\n  formula <- as.formula(paste(\"SO2 ~ \",predterms[[i]]))\n  # modelo frecuentista\n  lmi <- lm(formula, data=usair)\n  # modelo bayesiano\n  result <- inla(formula, family=\"gaussian\", data=usair, control.compute=list(dic=TRUE, waic=TRUE))\n  coefm[i,1] <- AIC(lmi)\n  coefm[i,2] <- result$dic$dic\n  coefm[i,3] <- result$waic$waic\n  coefm[i,4] <- -result$mlik[1]\n}\ngana.aic = predterms[which.min(coefm[,1])]\ngana.dic = predterms[which.min(coefm[,2])]\ngana.waic = predterms[which.min(coefm[,3])]\ngana.mlik = predterms[which.min(coefm[,4])]\ngana.aic;gana.dic\n#> [[1]]\n#> [1] \"negtemp+manuf+pop+wind+precip\"\n#> [[1]]\n#> [1] \"negtemp+manuf+pop+wind+precip\"\ngana.waic;gana.mlik\n#> [[1]]\n#> [1] \"negtemp+manuf+pop+wind+precip\"\n#> [[1]]\n#> [1] \"manuf\"\nformula=SO2 ~ negtemp+manuf+pop+wind+precip\nfit=inla(formula, family=\"gaussian\", data=usair, control.compute=list(dic=TRUE, waic=TRUE))\nfit$summary.fixed\n#>                     mean          sd   0.025quant\n#> (Intercept) 100.01692186 30.13151150 40.597582836\n#> negtemp       1.12028310  0.41418094  0.303570089\n#> manuf         0.06489628  0.01548630  0.034362685\n#> pop          -0.03934764  0.01488003 -0.068687542\n#> wind         -3.07264759  1.75614298 -6.534398013\n#> precip        0.41922526  0.21541745 -0.005530982\n#>                 0.5quant   0.975quant mode          kld\n#> (Intercept) 100.02049534 159.41578050   NA 1.157747e-08\n#> negtemp       1.12031023   1.93684044   NA 1.160732e-08\n#> manuf         0.06489603   0.09543130   NA 1.161951e-08\n#> pop          -0.03934729  -0.01000972   NA 1.161879e-08\n#> wind         -3.07290095   0.39055363   NA 1.155193e-08\n#> precip        0.41923174   0.84394444   NA 1.161777e-08\nfit$summary.hyperpar\n#>                                                mean\n#> Precision for the Gaussian observations 0.005066164\n#>                                                  sd\n#> Precision for the Gaussian observations 0.001178386\n#>                                          0.025quant\n#> Precision for the Gaussian observations 0.003036713\n#>                                            0.5quant\n#> Precision for the Gaussian observations 0.004975067\n#>                                          0.975quant mode\n#> Precision for the Gaussian observations 0.007617317   NA\nnfixed=length(fit$names.fixed)\ng=list()\nfor(i in 1:nfixed){\n  g[[i]]=ggplot(as.data.frame(fit$marginals.fixed[[i]])) + \n    geom_line(aes(x = x, y = y)) +\n    labs(x=fit$names.fixed[i],y=\"\")+\n    geom_vline(xintercept=inla.hpdmarginal(0.95,fit$marginals.fixed[[i]]),\n               linetype=\"dashed\",color=\"red\")+\n    geom_vline(xintercept=inla.emarginal(function(x) x,fit$marginals.fixed[[i]]),\n               linetype=\"dashed\",color=\"blue\")\n}\ngrid.arrange(g[[1]],g[[2]],g[[3]],g[[4]],g[[5]],g[[6]],ncol=2)"},{"path":"inlabasics.html","id":"predicción-de-medias","chapter":"Unidad 2 Regresión lineal","heading":"2.9.2 Predicción de medias","text":"Por último, si queremos predecir la respuesta esperada para ciertos valores de las variables explicativas, necesariamente existentes en la base de datos, utilizamos el argumento control.predictor en la función inla, especificando en una lista los valores predecir. Veamos cómo hacerlo con inla, ajustando un modelo sobre un data.frame combinado, en el que añadimos tantas filas como predicciones queremos conseguir, con los valores deseados para los predictores (y valores faltantes en la respuesta), y especificamos los valores predecir en un vector indicador, través del argumento control.predictor(list(link=vector.indicador)). Las predicciones se obtienen después, con el resumen de los datos ajustados fitted.values. Recordemos que para poder mostrar las distribuciones predictivas, hemos de añadir en inla el argumento control.compute=list(return.marginals.predictor=TRUE).Así graficamos en la Figura 2.3 la distribución predictiva del nivel de SO2 para una combinación dada de valores de las variables predictivas, específicamente la que aparece en el escenario 1 propuesto, o lo que es lo mismo, en el registro 42 de la base de datos completada con las nuevas predicciones: negtem=-50, manuf=150, pop=200, wind=6 y precip=10.\nFigura 2.3: Distribución predictiva posteriori de SO2 para una configuración dada de los predictores.\n","code":"\n# Predicción con INLA\n## valores de los predictores en los que predecir: 3 escenarios\nformula=SO2 ~ negtemp+manuf+pop+wind+precip\nnew.data <- data.frame(negtemp = c(-50, -60, -40), \n                       manuf = c(150, 100, 400), \n                       pop = c(200, 100, 300), \n                       wind = c(6, 7, 8), \n                       precip = c(10, 30, 20),\n                       days=c(NA, NA,NA))\n\n## añadimos los tres escenarios de predicción a la bd original, \n## dejando como faltantes los valores a predecir de la v.dpte\nusair.combinado <- rbind(usair, data.frame(SO2=c(NA,NA,NA),new.data))\n## creamos un vector con NA's para observaciones y 1's para predicciones\nusair.indicador <- c(rep(NA, nrow(usair)), rep(1, nrow(new.data)))\n## reajustamos el modelo añadiendo la opción de predicción de datos\nfit.pred <- inla(formula, data = usair.combinado, \n                 control.compute=list(return.marginals.predictor=TRUE),\n                 control.predictor = list(link = usair.indicador))\n## y describimos los valores ajustados para los tres escenarios añadidos\nfit.pred$summary.fitted.values[(nrow(usair)+1):nrow(usair.combinado),]\n#>                         mean       sd 0.025quant 0.5quant\n#> fitted.Predictor.42 31.62377 8.207121   15.44168 31.62454\n#> fitted.Predictor.43 26.42297 5.475890   15.62646 26.42334\n#> fitted.Predictor.44 53.16279 7.094010   39.17566 53.16336\n#>                     0.975quant mode\n#> fitted.Predictor.42   47.80119   NA\n#> fitted.Predictor.43   37.21724   NA\n#> fitted.Predictor.44   67.14646   NA\npred=fit.pred$marginals.fitted.values[[42]]\nggplot(as.data.frame(pred)) + \n  geom_line(aes(x = x, y = y)) +\n  labs(x=expression(eta),y=\"\")+\n  geom_vline(xintercept=inla.hpdmarginal(0.95,pred),\n             linetype=\"dashed\",color=\"red\")+\n  geom_vline(xintercept=inla.emarginal(function(x) x,pred),\n             linetype=\"dashed\",color=\"blue\")"},{"path":"inlabasics.html","id":"conclusiones","chapter":"Unidad 2 Regresión lineal","heading":"2.10 Conclusiones","text":"En este tema hemos trabajado con el ajuste con INLA de modelos lineales de regresión, esto es, con efectos fijos. En posteriores temas trabajaremos modelos más sofisticados en los que incluiremos los efectos aleatorios, generalizaremos el modelo lineal y entenderemos el planteamiento de modelos través de modelos jerárquicos bayesianos.","code":""},{"path":"anova.html","id":"anova","chapter":"Unidad 3 Modelo de ANOVA","heading":"Unidad 3 Modelo de ANOVA","text":"","code":""},{"path":"anova.html","id":"introducción-1","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.1 Introducción","text":"El modelo de ANOVA se plantea para comparar poblaciones normales, especialmente cuando son más de dos las poblaciones comparar. Las poblaciones comparar se identifican través de una variable clasificadora (de tipo categórico) que actúa como predictora para estimar respuestas medias supuestamente distintas comparar.","code":""},{"path":"anova.html","id":"el-modelo-de-anova","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.2 El modelo de ANOVA","text":"Consideremos una variable respuesta \\(Y\\) que se distribuye normal, y que viene afectada por una variable de clasificación \\(\\) con \\(\\) niveles de respuesta distintos (uno por cada una de las poblaciones comparar). Supongamos que tenemos \\(n_i\\) observaciones de la respuesta para cada uno de los niveles de respuesta de la variable clasificadora, \\(=1,...,\\). El modelo de ANOVA se plantea asumiendo que en cada nivel o subpoblación, esperamos un valor distinto para la respuesta,\n\\[(y_{ij}|\\mu_i,\\sigma^2) \\sim N(\\mu_i,\\sigma^2)\\]\nde modo que\n\\[E(y_{ij}|\\mu_i,\\sigma^2)=\\mu_i; \\ Var(y_{ij}|\\mu_i,\\sigma^2)=\\sigma^2, \\ \\ =1,...,; \\ j=1,...,n_i\\]\nLa formulación habitual de este modelo se suele dar en términos de un efecto global y común todas las observaciones, \\(\\theta\\), y un efecto diferencial respecto del primer nivel del factor de clasificación \\(\\), \\(\\alpha_i\\), con los que se construye la media (identificada generalmente por \\(\\mu\\)) o predictor lineal (identificada generalmente por \\(\\eta\\)) y que en el modelo lineal coinciden:\n\\[\\mu_{ij}=\\eta_{ij}=\\theta + \\alpha_i\\]\ndonde \\(\\alpha_i=\\mu_i-\\mu_1\\) y \\(\\mu_1=\\theta\\), para \\(\\geq 1\\), esto es, \\(\\alpha_1=0\\).Estamos pues asumiendo que todos los \\(n_i\\) sujetos en el subgrupo de población \\(\\) identificado por la variable clasificadora \\(\\), comparten una media común \\(\\mu_i\\) y cierta variabilidad \\(\\sigma^2\\). Podríamos asumir varianzas distintas para cada subpoblación, pero por simplicidad consideramos que son iguales.En la modelización bayesiana es preciso añadir distribuciones priori para cada uno de los parámetros del modelo: los efectos fijos \\(\\theta,\\alpha_i\\), y la varianza \\(\\sigma^2\\) de los datos. Ante ausencia de información, se asumirán las distribuciones difusas habituales en INLA:\\[\\begin{eqnarray*}\n(Y_{ij}|\\mu_i,\\sigma^2) & \\sim & N(\\mu_i,\\sigma^2) \\\\\n&& \\mu_i = \\theta + \\alpha_i, \\geq 1 \\\\\n\\theta & \\sim & N(0,\\infty)\\\\\n\\alpha_i & \\sim & N(0,1000), \\geq 1\\\\\n\\tau=1/\\sigma^2 & \\sim & Ga(1,0.00005)\n\\end{eqnarray*}\\]","code":""},{"path":"anova.html","id":"anova-de-una-vía","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.3 Anova de una vía","text":"Vamos ilustrar el análisis ANOVA en INLA través de la base de datos coagulation, en la librería faraway, referidos un estudio de tiempos de coagulación de la sangre en 24 animales los que aleatoriamente se les asignó una de entre tres dietas distintas (variable clasificadora diet). Posteriormente, para estudiar el efecto de dichas dietas en la coagulación, se tomaron muestras de los tiempos de coagulación (en la variable coag, que es la respuesta).Estamos planteando un modelo de Anova como el propuesto en la sección anterior, donde \\(\\alpha_i\\) identifica el efecto diferencial sobre la respuesta con la dieta , para el resto de las dietas B y C. Los parámetros del modelo son, como en regresión, los efectos fijos \\((\\theta,\\alpha_i)\\) y la varianza \\(\\sigma^2\\), para los que asumimos las priors difusas que por defecto propone INLA. Ajustamos el modelo y obtenemos las inferencias posterioriAtendiendo los descriptivos de la distribución posterior para los efectos fijos, concluimos:El tiempo esperado de coagulación para los animales que han seguido la dieta es de 61.017(58.675,63.364).Los animales que han seguido la dieta B tienen un tiempo de coagulación esperado superior en 4.978 unidades los de la dieta , y dicha diferencia es significativamente distinta de cero en el contexto bayesiano, dado que su RC incluye al cero, (1.949,8.003).Una conclusión similar se deriva para la dieta C, que da un tiempo de coagulación esperado superior en 6.977 unidades los de la dieta , y una RC (3.947,10.001).Las diferencias en los tiempos de coagulación de seguir una dieta D frente la dieta son relevantes. De hecho, la diferencia entre ellos es de -0.017 y el intervalo RC contiene al cero, (-2.891,2.853).Pintamos continuación en la Figura 3.1 la distribución posterior de los tiempos esperados de coagulación \\(\\mu_i\\) (o predictores lineales) para cada una de las dietas. En la Figura 3.2 se añaden las medias posteriores y las regiones creíbles.\nFigura 3.1: Distribución posterior del tiempo medio de coagulación para las 4 dietas.\nPodríamos ajustar el modelo prescindiendo del efecto de interceptación y estimar directamente los efectos.Con lo cual la representación gráfica se simplifica través, directamente, de las distribuciones posteriores de los efectos fijos.\nFigura 3.2: Distribuciones posteriores, medias y RC del tiempo esperado de coagulación.\nComo ya hacíamos en regresión, podemos inferir sobre la desviación típica de los datos, \\(\\sigma\\), transformando la distribución para la precisión \\(\\tau\\). La distribución posterior junto con su media y RC95% se muestra en la Figura 3.3.\nFigura 3.3: Distribución posterior, media y RC, de la desviación típica de los datos (sigma)\nSi queremos inferir sobre la diferencia entre cualesquiera de los efectos podemos recurrir simular la distribución posterior de las diferencias. Por ejemplo, supongamos que queremos comparar la dieta B con la dieta C. Simulamos entonces de las distribuciones posteriores de \\(\\mu_B\\) y de \\(\\mu_C\\), y obtenemos la diferencia \\(\\mu_B-\\mu_C\\).\\[ \\mu_B^{()} \\sim \\pi(\\mu_B|y), \\ \\mu_C^{()} \\sim \\pi(\\mu_C|y) \\Rightarrow \\mu_C^{()}-\\mu_B^{()} \\sim \\pi(\\mu_C-\\mu_B|y), \\ \\ =1,\\ldots,nsim\\]Podríamos así mismo, calcular cualquier probabilidad con ellas, como por ejemplo la probabilidad de que el tiempo de coagulación de un animal que sigue la dieta C sea 2 unidades superior al de uno que sigue la dieta B.\\[Pr(\\mu_C>\\mu_B+2|y)= Pr(\\mu_C-\\mu_B>2|y)\\]","code":"\ndata(coagulation, package=\"faraway\")\nstr(coagulation)\n#> 'data.frame':    24 obs. of  2 variables:\n#>  $ coag: num  62 60 63 59 63 67 71 64 65 66 ...\n#>  $ diet: Factor w/ 4 levels \"A\",\"B\",\"C\",\"D\": 1 1 1 1 2 2 2 2 2 2 ...\nggplot(coagulation,aes(x=diet,y=coag))+\n  geom_boxplot(aes(color=diet))+\n  theme(legend.position=\"none\")\nformula=coag ~ diet\nfit=inla(formula,family=\"gaussian\",data=coagulation,\n         control.compute=list(config=TRUE,return.marginals.predictor=TRUE))\nfijos=round(fit$summary.fixed,3);fijos\n#>               mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 61.017 1.185     58.675   61.016     63.364\n#> dietB        4.978 1.530      1.949    4.979      8.003\n#> dietC        6.977 1.530      3.947    6.978     10.001\n#> dietD       -0.017 1.452     -2.891   -0.016      2.853\n#>             mode kld\n#> (Intercept)   NA   0\n#> dietB         NA   0\n#> dietC         NA   0\n#> dietD         NA   0\ntau=round(fit$summary.hyperpar,3);tau\n#>                                          mean   sd\n#> Precision for the Gaussian observations 0.197 0.06\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.099     0.19\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.323   NA\nmedias=round(fit$summary.linear.predictor,4)\ndietas=levels(coagulation$diet)\npred=NULL\nfor(i in 1:length(dietas)){\nindex=which(coagulation$diet==dietas[i])[1]\n# distrib. posterior\npost=as.data.frame(fit$marginals.fitted.values[[index]])\n# media\ne=fit$summary.fitted.values[index,1]\nrc.low=fit$summary.fitted.values[index,3]\nrc.up=fit$summary.fitted.values[index,5]\npred=rbind(pred,data.frame(dieta=dietas[i],\n                           post,e,rc.low,rc.up))\n}\n\nggplot(pred, aes(x = x, y =y)) + \n  geom_line(aes(color=dieta))+\n  labs(x=expression(paste(\"Tiempo medio de coagulación:\",mu)),\n       y=\"D.Posterior\")\nformula=coag ~ -1 + diet\nfit=inla(formula,family=\"gaussian\",data=coagulation,\n         control.compute=list(config=TRUE,return.marginals.predictor=TRUE))\nround(fit$summary.fixed,3)\n#>         mean    sd 0.025quant 0.5quant 0.975quant mode kld\n#> dietA 60.916 1.176     58.577   60.919     63.233   NA   0\n#> dietB 65.939 0.961     64.030   65.942     67.832   NA   0\n#> dietC 67.937 0.961     66.028   67.940     69.830   NA   0\n#> dietD 60.958 0.832     59.306   60.960     62.599   NA   0\nround(fit$summary.hyperpar,3)\n#>                                          mean   sd\n#> Precision for the Gaussian observations 0.197 0.06\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.098     0.19\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.324   NA\npred=NULL\nfor(i in 1:length(names(fit$marginals.fixed))){\n  pred=rbind(pred,data.frame(as.data.frame(fit$marginals.fixed[[i]]),\n                  dieta=names(fit$marginals.fixed)[i],\n                  mean=fit$summary.fixed$mean[i],\n                  rc.low=fit$summary.fixed$'0.025quant'[i],\n                  rc.up=fit$summary.fixed$'0.975quant'[i]))}\n\nggplot(pred, aes(x = x, y =y)) + \n  geom_line(aes(color=dieta))+\n  geom_vline(aes(xintercept=mean,color=dieta),linetype=\"dashed\")+\n  geom_vline(aes(xintercept=rc.low,color=dieta),linetype=\"dotted\")+\n  geom_vline(aes(xintercept=rc.up,color=dieta),linetype=\"dotted\")+\n  facet_wrap(vars(dieta))+\n  labs(x=expression(paste(\"Tiempo medio de coagulación:\",mu)),\n       y=\"D.Posterior\",title=\"D.Posterior, medias y RC95%\")+\n  theme(legend.position=\"none\")\nsigma.post=inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[1]])\n# y la pintamos\nggplot(as.data.frame(sigma.post)) + \n  geom_line(aes(x = x, y = y)) +\n  labs(x=expression(sigma),y=\"D.Posterior\")+\n  geom_vline(xintercept=inla.hpdmarginal(0.95,sigma.post),\n             linetype=\"dotted\",color=\"blue\")+\n  geom_vline(xintercept=inla.emarginal(function(x) x,sigma.post),\n             linetype=\"dashed\",color=\"blue\")\n\n# Valor esperado\nsigma.e=round(inla.emarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[1]]),4)\n# HPD95%\nsigma.hpd=round(inla.hpdmarginal(0.95,sigma.post),3)\npaste(\"E(sigma.post)=\",sigma.e,\"HPD95%=(\",sigma.hpd[1],\",\",sigma.hpd[2],\")\")\n#> [1] \"E(sigma.post)= 2.3379 HPD95%=( 1.687 , 3.069 )\"\nsims=inla.posterior.sample(1000,fit,selection=list(dietB=1,dietC=1))\ndif_CB=as.vector(inla.posterior.sample.eval(function(...) dietC-dietB, sims))\npred=data.frame(dif=dif_CB)\nggplot(pred,aes(x=dif))+\n  geom_histogram(aes(y=..density..), colour=\"black\", fill=\"white\")+\n geom_density(alpha=.2, fill=\"#80E7F5\")+\n  geom_vline(xintercept=mean(dif_CB),color=\"red\",size=1.5)+\n  geom_vline(xintercept=quantile(dif_CB,probs=c(0.025,0.975)),color=\"red\",size=1.5,linetype=\"dashed\")+\n  labs(x=\"Diferencia del tiempo esperado de coagulación: dietC-dietB\",y=\"\")\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\ncat(paste(\"Probabilidad posterior de que muC>muB+2 =\",mean(pred$dif>2)))\n#> Probabilidad posterior de que muC>muB+2 = 0.535"},{"path":"anova.html","id":"anova-de-varias-vías","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.4 Anova de varias vías","text":"Generalmente, y en especial cuando trabajamos con experimentación, son varios los factores que controlamos para investigar el efecto que producen en una respuesta continua. Hablamos de modelos de Anova de varias vías.Utilizamos la base de datos butterfat en la librería faraway para ilustrar el ajuste con INLA de un modelo de Anova de varias vías. Esta base de datos contiene 100 registros del contenido en grasa láctea, Butterfat, para muestras aleatorias de 20 vacas (10 de ellas de 2 años y 10 maduras, con más de 4 años -en la variable Age) de cada una de cinco razas (en la variable Breed).El objetivo es investigar las diferencias en materia grasa entre razas y edad, con el fin último de identificar cuáles producen más materia grasa y cuáles menos. Veamos los datos en la Figura 3.4.\nFigura 3.4: Base de datos butterfat, en la librería Faraway\nla vista del gráfico, apreciamos que por lo general, en la mayoría de las razas, las vacas más jóvenes tienen menor contenido en materia grasa que las más viejas. Sin embargo, tal afirmación parece tan clara en las razas Guernsey y Holstein-Fresian, de modo que para modelizar nuestros datos vamos considerar priori, la posibilidad de interacciones entre los factores de clasificación Breed y Age.Cuando nos enfrentamos varios factores de clasificación, cabe la posibilidad de que interaccionen entre ellos, esto es, que en algunos niveles de un factor actúen de forma diferente los otros cuando se combinan con los niveles de algún otro factor. El orden de una interacción viene dado por el número de factores de clasificación que involucra, de modo que hablamos de interacciones de orden 2 si consideramos la interacción entre dos factores, de orden 3 si consideramos la interacción entre tres factores, etc. Generalmente trabajamos con interacciones de orden bajo, dada la complejidad de las conclusiones en interacciones de orden alto. Por otro lado, siempre es importante tener en cuenta de cuántos datos disponemos para conocer priori la posibilidad de estimar con fiabilidad los distintos efectos de interacción: una interacción de dos factores con \\(n_1\\) y \\(n_2\\) niveles de clasificación respectivamente, revierte en la estimación de \\((n_1-1)\\times(n_2-1)\\) efectos de interacción adicionales.Así, en nuestro problema si estamos planteando la posibilidad de que haya interacciones entre los dos factores de clasificación, estamos asumiendo un modelo de tipo siguiente, asumiendo normalidad en la respuesta:\\[(y_{ijk}|\\mu_{ij},\\sigma^2) \\sim N(\\mu_{ij},\\sigma^2)\\]\ncon\n\\[\\mu_{ij}=\\theta+ \\alpha_i + \\beta_j + \\alpha\\beta_{ij}\\]\ndonde en nuestro ejemplo, \\(\\alpha_i\\) es el efecto diferencial (respecto del primer nivel) que aporta el nivel \\(\\) de la variable Breed, \\(\\beta_j\\) el efecto asociado la variable Age, y \\(\\alpha\\beta\\) la correspondiente interacción entre ellas. En R una interacción de orden 2 entre dos variables \\(f_1\\) y \\(f_2\\) se especifica con \\(f_1:f_2\\); los efectos principales y la interacción se pueden especificar de varios modos alternativos:\n\\[f_1+f_2+f_1:f_2 \\equiv f_1*f_2 \\equiv (f_1+f_2)\\hat{} 2\\]Veamos cómo ajustar con INLA este modelo, recabando también los criterios de selección DIC y WAIC.Observamos en la inferencia posterior para los efectos fijos, que todas las RC asociadas los efectos de interacción contienen al cero, lo que descarta la relevancia de la interacción la hora de predecir la respuesta. Reajustamos pues el modelo eliminando la interacción, y comprobamos que efectivamente al eliminarla conseguimos reducir los valores del DIC y WAIC que usamos habitualmente para la selección de variables.Observamos ya partir del modelo ajustado, que el efecto de la edad es relevante (su RC incluye al cero), pero sin embargo sí que hay diferencias debido las razas.Reajustamos de nuevo el modelo, excluyendo la variable Age, y verificamos la reducción (ligera) del DIC/WAIC, lo cual justifica usar este modelo para la predicción.Procederíamos igual que en el modelo de Anova de una vía para la representación de las distribuciones posteriores sobre las medias o predictores lineales en cada una de las razas. Igualmente representaremos la distribución posterior del parámetro de dispersión de los datos \\(\\sigma\\).","code":"\ndata(butterfat,package=\"faraway\")\nstr(butterfat)\n#> 'data.frame':    100 obs. of  3 variables:\n#>  $ Butterfat: num  3.74 4.01 3.77 3.78 4.1 4.06 4.27 3.94 4.11 4.25 ...\n#>  $ Breed    : Factor w/ 5 levels \"Ayrshire\",\"Canadian\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ Age      : Factor w/ 2 levels \"2year\",\"Mature\": 2 1 2 1 2 1 2 1 2 1 ...\nggplot(butterfat,aes(x=Breed,y=Butterfat))+\n  geom_boxplot(aes(color=Age))+\n  coord_flip()\nformula=Butterfat ~ Breed * Age\nfit=inla(formula,data=butterfat,\n         control.compute=list(dic = TRUE, waic = TRUE))\nround(fit$summary.fixed,3)\n#>                                   mean    sd 0.025quant\n#> (Intercept)                      3.966 0.131      3.708\n#> BreedCanadian                    0.522 0.186      0.157\n#> BreedGuernsey                    0.933 0.186      0.568\n#> BreedHolstein-Fresian           -0.303 0.186     -0.668\n#> BreedJersey                      1.167 0.186      0.802\n#> AgeMature                        0.188 0.186     -0.177\n#> BreedCanadian:AgeMature         -0.287 0.263     -0.804\n#> BreedGuernsey:AgeMature         -0.086 0.263     -0.603\n#> BreedHolstein-Fresian:AgeMature -0.175 0.263     -0.692\n#> BreedJersey:AgeMature            0.131 0.263     -0.386\n#>                                 0.5quant 0.975quant mode\n#> (Intercept)                        3.966      4.224   NA\n#> BreedCanadian                      0.522      0.887   NA\n#> BreedGuernsey                      0.933      1.298   NA\n#> BreedHolstein-Fresian             -0.303      0.062   NA\n#> BreedJersey                        1.167      1.532   NA\n#> AgeMature                          0.188      0.553   NA\n#> BreedCanadian:AgeMature           -0.287      0.230   NA\n#> BreedGuernsey:AgeMature           -0.086      0.431   NA\n#> BreedHolstein-Fresian:AgeMature   -0.175      0.342   NA\n#> BreedJersey:AgeMature              0.131      0.648   NA\n#>                                 kld\n#> (Intercept)                       0\n#> BreedCanadian                     0\n#> BreedGuernsey                     0\n#> BreedHolstein-Fresian             0\n#> BreedJersey                       0\n#> AgeMature                         0\n#> BreedCanadian:AgeMature           0\n#> BreedGuernsey:AgeMature           0\n#> BreedHolstein-Fresian:AgeMature   0\n#> BreedJersey:AgeMature             0\nfit$dic$dic\n#> [1] 120.486\nfit$waic$waic\n#> [1] 121.7376\nformula=Butterfat ~ Breed + Age\nfit=inla(formula,data=butterfat,\n         control.predictor=list(compute=TRUE),\n         control.compute=list(return.marginals.predictor=TRUE,\n                              dic = TRUE, waic = TRUE))\nfit$summary.fixed\n#>                             mean        sd  0.025quant\n#> (Intercept)            4.0077184 0.1012486  3.80873700\n#> BreedCanadian          0.3784787 0.1307114  0.12159362\n#> BreedGuernsey          0.8899744 0.1307114  0.63308912\n#> BreedHolstein-Fresian -0.3905147 0.1307114 -0.64739962\n#> BreedJersey            1.2324714 0.1307114  0.97558611\n#> AgeMature              0.1045993 0.0826701 -0.05787069\n#>                         0.5quant 0.975quant mode\n#> (Intercept)            4.0077182  4.2067008   NA\n#> BreedCanadian          0.3784790  0.6353626   NA\n#> BreedGuernsey          0.8899746  1.1468581   NA\n#> BreedHolstein-Fresian -0.3905145 -0.1336306   NA\n#> BreedJersey            1.2324717  1.4893551   NA\n#> AgeMature              0.1045993  0.2670692   NA\n#>                                kld\n#> (Intercept)           2.525098e-09\n#> BreedCanadian         2.524912e-09\n#> BreedGuernsey         2.524916e-09\n#> BreedHolstein-Fresian 2.524914e-09\n#> BreedJersey           2.524911e-09\n#> AgeMature             2.525145e-09\nfit$waic$waic\n#> [1] 116.3439\nfit$dic$dic\n#> [1] 115.3807\nformula=Butterfat ~ Breed \nfit=inla(formula,data=butterfat,\n         control.predictor=list(compute=TRUE),\n         control.compute=list(return.marginals.predictor=TRUE,\n                              dic = TRUE, waic = TRUE))\nfit$summary.fixed\n#>                             mean         sd 0.025quant\n#> (Intercept)            4.0600181 0.09271695  3.8778078\n#> BreedCanadian          0.3784786 0.13112186  0.1207924\n#> BreedGuernsey          0.8899742 0.13112186  0.6322879\n#> BreedHolstein-Fresian -0.3905148 0.13112186 -0.6482008\n#> BreedJersey            1.2324713 0.13112186  0.9747849\n#>                         0.5quant 0.975quant mode\n#> (Intercept)            4.0600180  4.2422295   NA\n#> BreedCanadian          0.3784788  0.6361636   NA\n#> BreedGuernsey          0.8899745  1.1476590   NA\n#> BreedHolstein-Fresian -0.3905146 -0.1328296   NA\n#> BreedJersey            1.2324715  1.4901560   NA\n#>                                kld\n#> (Intercept)           2.471523e-09\n#> BreedCanadian         2.471605e-09\n#> BreedGuernsey         2.471606e-09\n#> BreedHolstein-Fresian 2.471604e-09\n#> BreedJersey           2.471603e-09\nfit$waic$waic\n#> [1] 115.9279\nfit$dic$dic\n#> [1] 115.0093"},{"path":"anova.html","id":"análisis-de-ancova","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.5 Análisis de ANCOVA","text":"En ocasiones tenemos una variable respuesta de tipo numérico, y como posibles predictores, tanto variables de tipo numérico como variables clasificadoras o factores. Surge entonces la posibilidad de que los predictores numéricos afecten la respuesta de modo distinto en diferentes niveles de clasificación de los factores; hablamos entonces de interacción entre covariables y factores. Veamos un ejemplo para comprender cómo funcionan estos modelos y cómo se ajustan con INLA.Consideramos los datos de Galton sobre la regresión de las alturas de los hijos sobre la de los padres (Fte: Galton’s Height Data). Tenemos la estatura del padre, de la madre y del hijo/, identificado/por su sexo.\nVamos formular un modelo de regresión de la estatura de los hijos en función de la de sus padres y su género.Asumimos pues como respuesta la variable y=Height, como regresores las variables \\(x_1=\\)Father y \\(x_2=\\)Mother con las estaturas del padre y la madre respectivamente, y con factor de clasificación la variable \\(G=\\)Gender, con niveles M/F. En principio cabrían posibles interacciones entre los regresores (estaturas del padre y de la madre) y los factores de clasificación (sexo del sujeto). Esto implicaría que las pendientes de relación ‘estatura padres’ versus ‘estatura hijos’ serían paralelas para los sujetos hombres y mujeres. Planteamos pues, para predecir la respuesta del sujeto \\(j\\) en el grupo \\(\\) del factor de clasificación (Gender), \\(y_{ij}\\), el modelo:\\[(y_{ij}|\\mu_{ij},\\sigma^2) \\sim N(\\mu_{ij},\\sigma^2)\\]\ncon el predictor lineal\n\\[\\eta_{ij}=\\mu_{ij}=\\beta_0+ \\alpha_M+ (\\beta_1 + \\beta_1^M) x_{1j} + (\\beta_2+ \\beta_2^M) x_{2j} ;\\ \\  j =1,...,n_i; =M,F\\]\ndonde \\(\\alpha_M\\) es el efecto diferencial global de los hombres frente las mujeres al predecir la estatura, y \\(\\beta_1^M, \\beta_2^M\\) son los efectos diferenciales que afectan los regresores para los sujetos varones, y por lo tanto que provocan pendientes distintas al predecir la estatura del sujeto con las de los padres, en función de si este es hombre o mujer.Asumimos una distribución vaga sobre todos los efectos fijos y \\(\\tau=1/\\sigma^2\\), y ajustamos el modelo Gausiano en INLA:Observamos que ninguna de las interacciones tienen un efecto considerar (su RC posterior incluye al cero), de modo que las descartamos y reajustamos el modelo sin ellas.\\[\\eta_{ij}=\\mu_{ij}=\\beta_0 + \\alpha_M + \\beta_1  x_{1j} + \\beta_2 x_{2j} ;\\ \\  j =1,...,n; =M,F.\\]Ahora todos los efectos fijos son relevantes para predecir la estatura de los hijos. Utilizamos este modelo para derivar las inferencias.Representamos continuación en la Figura 3.5 las distribuciones posteriores de los efectos fijos:\nFigura 3.5: Distribución posterior de los efectos fijos\nEn media observamos que la estatura de los hombres es 5.23 unidades superior la de las mujeres.Con estas distribuciones podemos calcular cualquier probabilidad, como por ejemplo,la probabilidad de que la estatura de un hombre supere en 5 unidades la de una mujer, independientemente de cómo sean sus padres, esto es,\n\\[Pr(\\alpha_M>5|datos)\\]Podemos acceder las distribuciones posteriores de la estatura de cualquiera de los sujetos en la muestra y posicionar las estaturas de sus padres, que se muestran en la Figura 3.6\nFigura 3.6: Predicción de la estatura del primer sujeto en la muestra\nPodemos ir más allá, infiriendo sobre la estatura (esperada) de un sujeto, sea hombre o mujer, cuando su padre mide 1.75m (68.9 pulgadas) y su madre 1.70m (66.9 pulgadas). Expresamos los resultados en centímetros.También graficar las distribuciones posteriores y calcular las probabilidades, por ejemplo, de que dicho sujeto supere el 1.65m si es mujer, o el 1.78m si es hombre (Figura 3.7).\nFigura 3.7: Distribución posterior de la estatura de un sujeto cuyo padre mide 1,75cm y madre 1,07cm.\nPodríamos también, modificar las especificaciones priori sobre los parámetros \\(\\beta_0\\) y \\(\\beta_1\\) mediante el comando control.fixed. Por ejemplo, queremos asumir priori \\(\\beta_0\\sim N(0,10^4)\\) y \\(\\beta_1\\sim N(0,100)\\) y ver cómo afecta las inferencias.Si queremos especificar medias priori diferentes para los coeficientes de los distintos regresores, hemos de especificarlos con listas.Si queremos modificar la especificación de la prior en \\(\\sigma^2\\), o lo que es equivalente, en la precisión \\(\\tau\\), con la distribución \\(log(\\tau) \\sim N(0,1)\\) en lugar de \\(\\tau \\sim Ga(1,10^{-5})\\), vemos cómo afecta la inferencia posterior sobre la precisión.Cuando tenemos información previa disponible sobre la variación de los datos, será generalmente más intuitivo expresarla en términos de la desviación estándar \\(\\sigma\\). Bastará con conseguir la equivalencia en la escala de \\(log(\\tau)\\) para incluirla en el modelo. Por ejemplo, si sabemos que la desviación típica está entre 2 y 14, \\(\\sigma \\sim Unif(2,14)\\), podemos calcular una prior para la log-precisión del siguiente modo:simular una muestra de \\(\\sigma \\sim Unif(2,14)\\)transformar precisionescalcular los parámetros de la Gamma para la precisión, partir de su media y varianzaHacemos los cálculos y graficamos la prior en la Figura 3.8.\nFigura 3.8: Distribución prior para tau con sigma ~ Uniforme(2,14)\nUtilicemos pues esos parámetros para especificar la prior sobre \\(\\tau\\) en INLA:","code":"\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/Galton.txt\"\ndatos<-read.csv(file=url,header=TRUE,dec=\".\", sep=\"\")\nstr(datos)\n#> 'data.frame':    898 obs. of  6 variables:\n#>  $ Family: chr  \"1\" \"1\" \"1\" \"1\" ...\n#>  $ Father: num  78.5 78.5 78.5 78.5 75.5 75.5 75.5 75.5 75 75 ...\n#>  $ Mother: num  67 67 67 67 66.5 66.5 66.5 66.5 64 64 ...\n#>  $ Gender: chr  \"M\" \"F\" \"F\" \"F\" ...\n#>  $ Height: num  73.2 69.2 69 69 73.5 72.5 65.5 65.5 71 68 ...\n#>  $ Kids  : int  4 4 4 4 4 4 4 4 2 2 ...\ndatos %>% \n  pivot_longer(cols=c(\"Father\",\"Mother\"),\n               names_to = \"Parents\",values_to=\"Height_parents\") %>%\n  ggplot(aes(x=Height_parents,y=Height))+\n  geom_point(aes(color=Gender))+\n  geom_smooth(method=\"lm\",aes(color=Gender),se=FALSE)+\n  facet_wrap(vars(Parents))+\n  labs(x=\"Estatura de los padres\",y=\"Estatura de los hijos\")\n#> `geom_smooth()` using formula 'y ~ x'\n\nformula = Height ~ 1+(Father+Mother)*Gender\nfit = inla(formula,family = \"gaussian\",data=datos)\nround(fit$summary.fixed,3)\n#>                  mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept)    16.653 3.887      9.028   16.653     24.277\n#> Father          0.400 0.039      0.324    0.400      0.477\n#> Mother          0.307 0.045      0.218    0.307      0.396\n#> GenderM         2.707 5.428     -7.941    2.707     13.353\n#> Father:GenderM  0.012 0.058     -0.103    0.012      0.126\n#> Mother:GenderM  0.027 0.062     -0.096    0.027      0.149\n#>                mode kld\n#> (Intercept)      NA   0\n#> Father           NA   0\n#> Mother           NA   0\n#> GenderM          NA   0\n#> Father:GenderM   NA   0\n#> Mother:GenderM   NA   0\nformula = Height ~ Father+Mother+Gender\nfit = inla(formula,family = \"gaussian\",data=datos,\n        control.predictor=list(compute=TRUE),\n         control.compute=list(return.marginals.predictor=TRUE,\n                              dic = TRUE, waic = TRUE))\nround(fit$summary.fixed,3)\n#>               mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 15.345 2.747      9.957   15.345     20.733\n#> Father       0.406 0.029      0.349    0.406      0.463\n#> Mother       0.321 0.031      0.260    0.321      0.383\n#> GenderM      5.226 0.144      4.943    5.226      5.508\n#>             mode kld\n#> (Intercept)   NA   0\n#> Father        NA   0\n#> Mother        NA   0\n#> GenderM       NA   0\nfixed=names(fit$marginals.fixed)\ng=list()\nfor(i in 1:length(fixed)){\n  g[[i]]=ggplot(as.data.frame(fit$marginals.fixed[[i]]),aes(x=x,y=y))+\n    geom_line()+\n    geom_vline(xintercept=fit$summary.fixed$mean[i],linetype=\"dashed\")+\n    geom_vline(xintercept=fit$summary.fixed[i,3],linetype=\"dotted\")+\n    geom_vline(xintercept=fit$summary.fixed[i,5],linetype=\"dotted\")+\n    labs(x=fixed[i],y=\"D.posterior\")\n}\ngrid.arrange(g[[1]],g[[2]],g[[3]],g[[4]],ncol=2)\n1-inla.pmarginal(5,fit$marginals.fixed$\"GenderM\")\n#> [1] 0.9414228\n# la predicción del predictor lineal para cada sujeto es:\npred<-fit$marginals.linear.predictor\n# que en este caso coincide con los valores ajustados\nfitted<-fit$marginals.fitted.values\nggplot(as.data.frame(pred$Predictor.1),aes(x=x,y=y))+\n  geom_line()+\n  labs(x=\"Estatura media del sujeto 1\",y=\"D.posterior\")+\n  geom_vline(xintercept=fit$summary.fitted.values$mean[1],linetype=\"dashed\")+\n  geom_vline(xintercept=datos$Father[1],linetype=\"dashed\",color=\"blue\")+\n  geom_vline(xintercept=datos$Mother[1],linetype=\"dashed\",color=\"pink\")+\n  annotate(\"text\",x=datos$Mother[1]+1,y=1,label=\"Madre\")+\n  annotate(\"text\",x=datos$Father[1]-1,y=1,label=\"Padre\")\nnew.data=data.frame(Father=c(68.9,68.9),\n                    Mother=c(66.9,66.9),\n                    Gender=c(\"M\",\"F\"),\n                    Height=c(NA,NA))\ndatos.combinado <- rbind(datos, data.frame(Family=c(NA,NA),new.data,Kids=c(NA,NA)))\n\n## creamos un vector con NA's para observaciones y 1's para predicciones\ndatos.indicador <- c(rep(NA, nrow(datos)), rep(1, nrow(new.data)))\n## reajustamos el modelo añadiendo la opción de predicción de datos\nfit.pred <- inla(formula, data = datos.combinado, \n                 control.compute=list(return.marginals.predictor=TRUE),\n                 control.predictor = list(link = datos.indicador))\n## y describimos los valores ajustados para los escenarios añadidos\nround(fit.pred$summary.fitted.values[(nrow(datos)+1):nrow(datos.combinado),]*2.54,1)\n#>                       mean  sd 0.025quant 0.5quant\n#> fitted.Predictor.899 177.9 0.3      177.3    177.9\n#> fitted.Predictor.900 164.7 0.3      164.0    164.7\n#>                      0.975quant mode\n#> fitted.Predictor.899      178.6   NA\n#> fitted.Predictor.900      165.3   NA\n# Distribuciones predictivas\npred.M=as.data.frame(fit.pred$marginals.fitted.values[[(nrow(datos)+1)]])*2.54\npred.F=as.data.frame(fit.pred$marginals.fitted.values[[(nrow(datos)+2)]])*2.54\nd.pred=rbind(pred.M,pred.F)\n\n# atributo Gender\nd.pred$Gender=rep(c(\"M\",\"F\"),c(nrow(pred.M),nrow(pred.F)))\n# objetivo de estatura\nd.pred$obj=rep(c(178,165),c(nrow(pred.M),nrow(pred.F)))\n\n# cálculo de probabilidades\np165F=round(1-inla.pmarginal(165,pred.F),2)\ncat(paste(\"Pr(estatura>165|mujer,padre=175,madre=170)=\",p165F))\n#> Pr(estatura>165|mujer,padre=175,madre=170)= 0.16\ncat(\"\\n\")\np178M=round(1-inla.pmarginal(178,pred.M),2)\ncat(paste(\"Pr(estatura>178|hombre,padre=175,madre=170)=\",p178M))\n#> Pr(estatura>178|hombre,padre=175,madre=170)= 0.42\n\nd.pred$prob=rep(c(p178M,p165F),c(nrow(pred.M),nrow(pred.F)))\n\n\nggplot(d.pred,aes(x=x,y=y))+\n  geom_line(aes(color=Gender))+\n  geom_vline(aes(xintercept=obj),linetype=\"dashed\")+\n  facet_wrap(vars(Gender),scales=\"free\")+\n  labs(x=\"Estatura\",y=\"D.posterior\")+\n    theme(legend.position = \"none\")\nfit<-inla(formula,family=\"gaussian\",data=datos,\n                   control.fixed=list(mean=0,prec=0.01,\n                   mean.intercept=0, prec.intercept=0.0001))\nround(fit$summary.fixed,3)\n#>               mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 15.335 2.746      9.949   15.335     20.721\n#> Father       0.406 0.029      0.349    0.406      0.463\n#> Mother       0.322 0.031      0.260    0.322      0.383\n#> GenderM      5.225 0.144      4.942    5.225      5.507\n#>             mode kld\n#> (Intercept)   NA   0\n#> Father        NA   0\n#> Mother        NA   0\n#> GenderM       NA   0\nfit = inla(formula,family = \"gaussian\",data=datos,\n                   control.fixed=list(mean=list(Father=0.2,Mother=0.1)))\nround(fit$summary.fixed,3)\n#>               mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 15.345 2.747      9.957   15.345     20.733\n#> Father       0.406 0.029      0.349    0.406      0.463\n#> Mother       0.321 0.031      0.260    0.321      0.383\n#> GenderM      5.226 0.144      4.943    5.226      5.508\n#>             mode kld\n#> (Intercept)   NA   0\n#> Father        NA   0\n#> Mother        NA   0\n#> GenderM       NA   0\nfit_n = inla(formula,family=\"gaussian\", data=datos,\n                   control.family=list(hyper=list(\n                     prec=list(prior=\"gaussian\",param=c(0,1)))))\n# con el modelo log-gamma para precisión\nround(fit$summary.hyperpar,3)\n#>                                          mean   sd\n#> Precision for the Gaussian observations 0.216 0.01\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.197    0.216\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.236   NA\n# con el modelo normal para precisión\nround(fit_n$summary.hyperpar,3)\n#>                                          mean   sd\n#> Precision for the Gaussian observations 0.216 0.01\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.197    0.216\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.236   NA\n# parámetros para sigma~Un(a1,b1)\na1<-2\nb1<-14\n# simulamos sigma de una distribución Unif(a1,b1)\nsigma<-runif(n=10000,min=a1,max=b1)\n# obtenemos la precisión\ntau<-1/sigma^2\n# Calculamos los parámetros alpha,beta de una distrib. Gamma para la precisión\n# mean=alpha/beta; var=alpha/beta^2\nbeta= mean(tau)/var(tau)\nalpha<-mean(tau)*beta\n# dibujamos los valores de la precisión\ntau.seq=sort(tau)\n  # seq(min(tau),max(tau),length=1000)\nprior=data.frame(tau=tau.seq,dprior=dgamma(tau.seq,alpha,beta))\nggplot(prior, aes(x=tau))+\n  geom_histogram(aes(y=..density..),color=\"grey\",fill=\"white\")+\n  geom_line(aes(y=dprior))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nfit = inla(formula,family=\"gaussian\",data=datos,\n                   control.family=list(hyper=list(\n                     prec=list(prior=\"loggamma\",param=c(alpha,beta)))))\nround(fit$summary.hyperpar,3)\n#>                                          mean   sd\n#> Precision for the Gaussian observations 0.214 0.01\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations      0.195    0.214\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations      0.234   NA"},{"path":"anova.html","id":"efectos-aleatorios","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.6 Efectos aleatorios","text":"Desde una perspectiva frecuentista un modelo básico de Anova podría ser un modelo de efectos fijos, pero también de efectos aleatorios. Así por ejemplo el ‘tratamiento’ dado en un ensayo clínico es un efecto relevante para comparar y diferenciar cómo afecta la respuesta; ‘tratamiento’ sería entonces un efecto fijo, por ser un efecto de interés primario. En otro ejemplo, se han aplicado varios fertilizantes cultivos en fincas distintas; el interés primario será comparar los fertilizantes, pero la diversidad de fincas solo se ha incluido para introducir variabilidad e incrementar, por supuesto, el número de datos en el estudio; así pues, ‘fertilizante’ será un efecto fijo, pero es un objetivo comparar las fincas, por lo que se considerará como un efecto aleatorio.Una variable predictiva, numérica o categórica, entra en el modelo como efecto fijo cuando se piensa que afecta todas las observaciones del mismo modo, y que su efecto es de interés primario en el estudio.\nEn un contexto bayesiano un efecto fijo tendrá un coeficiente asociado al que se le asigna menudo una distribución priori vaga (mínimo informativa), como una gausiana con media cero y varianza (conocida) grande. En cualquier caso, la distribución priori que se asume para los efectos fijos es siempre una distribución conocida.Un efecto aleatorio identifica variables de tipo categórico que son de interés primario en la investigación, pero que se considera que añaden incertidumbre y por lo tanto variabilidad la respuesta. La modelización habitual de los efectos aleatorios es una prior gausiana con media cero y una precisión desconocida, para la que será preciso asignar, así mismo, una distribución priori. La distribución priori de los efectos aleatorios tiene parámetros desconocidos, llamados hiperparámetros, los que habrá que asignar también distribuciones priori.Puesto que salimos del modelo lineal, seguiremos asumiendo una respuesta normal, gaussian, con media igual un predictor lineal \\(\\mu=\\eta=\\theta+ Z u\\), donde \\(Z\\) es la correspondiente matriz de diseño para los efectos aleatorios \\(z_1, z_2,...\\). Se asume además una varianza desconocida \\(\\sigma^2\\).En INLA la fórmula de predicción de una respuesta \\(y\\) partir de un conjunto de efectos aleatorios z1,z2,… se especifica como:donde la función \\(f()\\) especifica la relación entre el predictor lineal de la respuesta y los efectos aleatorios \\(z\\). La función \\(f()\\) tiene muchos argumentos, que se pueden consultar con el comando ?f. El tipo de relación asumida se incluye en el argumento model o modelo latente, que tiene como posibilidades names(inla.models()$latent). En el modelo lineal, la opción habitual es model=\"iid\", que asume efectos aleatorios independientes e idénticamente distribuidos.Veamos cómo ajustar un modelo de efectos aleatorios partir de un ejemplo sencillo. Comenzamos con la base de datos broccoli en la librería faraway. Varios cultivadores suministran brócoli una planta de procesamiento de alimentos. La planta da instrucciones los cultivadores para que empaquen el brócoli en cajas de tamaño estándar. Debe haber 18 racimos de brócoli por caja y cada racimo debe pesar entre 1,33 y 1,5 libras. Debido que los productores utilizan diferentes variedades, métodos de cultivo, etc., hay cierta variación en el peso de los racimos. El responsable de la planta seleccionó 3 cultivadores al azar y luego 4 cajas al azar suministradas por estos cultivadores. Se seleccionaron 3 racimos de brocoli de cada caja (modo de repeticiones).La variable de interés es el peso del racimo de brócoli, en la variable wt. Sin embargo, dado cómo se ha seleccionado la muestra, el objetivo es ni la comparación entre cultivadores (grower), ni entre cajas (box), asumiendo que tenemos varios racimos (cluster) en cada una de las combinaciones de los anteriores factores. Sin embargo, de manera lógica intuimos que habrá variabilidad entre cajas (efecto aleatorio box) y también entre cultivadores (efecto aleatorio grower), lo que nos conduce un modelo en el que todos los predictores, box y grower intervienen como efectos aleatorios; la variable cluster la aprovechamos modo de repeticiones de medidas en una misma caja de un mismo cultivador.La base de datos cuenta con 36 registros (3 observaciones en cada combinación grower-box.\\[(y_{ijk}|\\mu_{ij},\\sigma^2 ) \\sim N(\\mu_{ij},\\sigma^2)\\]con \\[\\eta_{ij} =\\mu_{ij}= \\theta + \\alpha_i^G + \\beta_j^B; \\ \\  =2,3; j=2,3,4\\]\nel peso medio que comparten todos los racimos en cada combinación de agricultor-caja: \\(k=1,2,3\\), y donde \\(\\alpha^G\\) representa el efecto aleatorio asociado al cultivador (grower) y \\(\\beta^B\\) la caja (box).Así el vector de efectos latentes está compuesto por el efecto fijo de interceptación \\(theta\\) y los efectos aleatorios \\(u=(\\alpha_2^G,\\alpha_3^G,\\beta_2^B,\\beta_3^B,\\beta_4^B)\\).El siguiente paso es especificar una distribución priori sobre los parámetros. INLA por defecto asigna una prior difusa sobre la interceptación \\(\\theta\\) y también sobre la precisión de los datos \\(\\tau=1/\\sigma^2\\). Dado que los \\(\\alpha_i^G\\) representan el efecto diferencial asociado al cultivador, es razonable asumir independencia entre todos estos parámetros y una distribución idéntica, centrada en el cero (ante ausencia de información) y con una varianza desconocida. Con esto estamos diciendo que en principio tenemos información sobre que efectivamente el efecto cultivador sea relevante (media cero), pero sí que añade cierta variabilidad \\(\\sigma_{\\alpha}^2\\) la respuesta. Del mismo modo, se asume que los \\(\\beta_j^B\\) son priori independientes e idénticamente distribuidos (iid) con una normal centrada en el cero (ante ausencia de información) y con varianza desconocida \\(\\sigma_{\\beta}^2\\).\\[\\begin{eqnarray*}\n\\theta &\\sim & N(0,\\sigma_{\\theta}^2), \\ \\sigma_{\\theta}^2=\\infty \\\\\nlog(\\tau) &\\sim & Log-Ga(1,5\\cdot 10^{-5})\\\\\n\\alpha_i^G & \\sim_{iid} & N(0,\\sigma_{\\alpha}^2), =2,3 \\\\\n\\beta_j^B & \\sim_{iid} & N(0,\\sigma_{\\beta}^2), j=2,3,4\n\\end{eqnarray*}\\]Surgen pues, dos nuevos parámetros en las priori, o hiperparámetros, \\(\\sigma_{\\alpha}^2\\) y \\(\\sigma_{\\beta}^2\\), los que también habrá que asignar una distribución priori. Dado que se trata de varianzas, por defecto INLA asume gammas inversas difusas, o lo que es lo mismo, log-gammas difusas para las precisiones\\[\\begin{eqnarray*}\n\\tau_{\\alpha}=1/\\sigma_{\\alpha}^2 &\\sim & Ga(1,5\\cdot 10^{-5}) \\\\\n\\tau_{\\beta}=1/\\sigma_{\\beta}^2 &\\sim & Ga(1,5\\cdot 10^{-5})\n\\end{eqnarray*}\\]Surgen pues, tres niveles de especificación del modelo: datos, parámetros e hiperparámetros, que generan un modelo jerárquico de tres niveles, y sobre el que hablaremos más adelante.Cuando queremos mostrar los resultados posteriori sobre los efectos aleatorios partir de un ajuste fit con inla, tenemos las siguientes opciones:fit$summary.random resume la inferencia posterior sobre los efectos\naleatoriosnames(fit$marginals.random) lista los nombre de todos los efectos aleatoriosfit$marginals.random da las distribuciones posteriores marginales de los efectos aleatoriosSin embargo, lo relevante en un modelo de efectos aleatorios es la inferencia sobre las varianzas asociadas los datos, pero también la variabilidad extra que añaden los efectos aleatorios:Vemos que tanto la precisión asociada al efecto aleatorio caja (box), como al efecto cultivador, grower, son muy grandes, lo que implica varianzas muy pequeñas que posiblemente nos permitiría prescindir de dichos efectos aleatorios para ajustar un mejor modelo.Cuando transformamos escala de desviaciones estándar, tenemos la distribución posterior para los tres tipos de error, representados en la Figura 3.9.\nFigura 3.9: Distribución posterior de la desviación típica para las tres fuentes de error: datos, caja y cultivador\nobstante, antes de tomar una decisión sobre la exclusión de los efectos aleatorios, vamos hacer una aproximación del porcentaje de varianza explicada por cada una de estas fuentes de variación. Utilizando simulaciones de las distribuciones posteriores de \\(\\sigma^2, \\sigma_{\\alpha}^2\\) y \\(\\sigma_{\\beta}^2\\) vamos calcular la contribución la varianza del efecto cultivador, \\(\\sigma_{\\alpha}^2/(\\sigma^2 + \\sigma_{\\alpha}^2+\\sigma_{\\beta}^2)\\) y la contribución la varianza del efecto caja, \\(\\sigma_{\\beta}^2/(\\sigma^2 + \\sigma_{\\alpha}^2+\\sigma_{\\beta}^2)\\). Esto es, vamos simular de las distribuciones posteriores de las contribuciones la varianza, y calcular con dichas distribuciones, la probabilidad de que sea suficientemente grande, por ejemplo de que dicha contribución sea mayor un 1%. Si dicha probabilidad es considerable, estaremos diciendo que el efecto cultivador (o caja) está provocando demasiada variabilidad, indicador de que se están cumpliendo los estándares de calidad.\\[Pr\\left(\\frac{\\sigma_{\\alpha}^2}{\\sigma^2 + \\sigma_{\\alpha}^2+\\sigma_{\\beta}^2}|y\\right) \\geq 0.01 ; \\ Pr\\left(\\frac{\\sigma_{\\beta}^2}{\\sigma^2 + \\sigma_{\\alpha}^2+\\sigma_{\\beta}^2}|y\\right) \\geq 0.01\\]Ante estos resultados, con probabilidad 0 de que dichos efectos aporten la varianza más de un 1%, se justifica la opción de prescindir de los efectos grower y box como efectos aleatorios y ajustar el modelo con un único efecto fijo global.Vemos que la variación en los indicadores DIC (307.9672252) y WAIC (307.7313201) es despreciable para este nuevo modelo.Inferimos continuación con las distribuciones posteriores para la media global y la varianza de los datos.Hemos concluido con este análisis, que todos los cultivadores han respetado los protocolos de calidad establecidos para el empaquetado en cajas.","code":"\nformula = y ~ 1  + f(z1, model=\"\") + f(z2,model=\"\") \nnames(inla.models()$latent)\n#>  [1] \"linear\"       \"iid\"          \"mec\"         \n#>  [4] \"meb\"          \"rgeneric\"     \"cgeneric\"    \n#>  [7] \"rw1\"          \"rw2\"          \"crw2\"        \n#> [10] \"seasonal\"     \"besag\"        \"besag2\"      \n#> [13] \"bym\"          \"bym2\"         \"besagproper\" \n#> [16] \"besagproper2\" \"fgn\"          \"fgn2\"        \n#> [19] \"ar1\"          \"ar1c\"         \"ar\"          \n#> [22] \"ou\"           \"intslope\"     \"generic\"     \n#> [25] \"generic0\"     \"generic1\"     \"generic2\"    \n#> [28] \"generic3\"     \"spde\"         \"spde2\"       \n#> [31] \"spde3\"        \"iid1d\"        \"iid2d\"       \n#> [34] \"iid3d\"        \"iid4d\"        \"iid5d\"       \n#> [37] \"iidkd\"        \"2diid\"        \"z\"           \n#> [40] \"rw2d\"         \"rw2diid\"      \"slm\"         \n#> [43] \"matern2d\"     \"dmatern\"      \"copy\"        \n#> [46] \"clinear\"      \"sigm\"         \"revsigm\"     \n#> [49] \"log1exp\"      \"logdist\"\ndata(broccoli, package=\"faraway\")\nstr(broccoli)\n#> 'data.frame':    36 obs. of  4 variables:\n#>  $ wt     : num  352 369 383 339 367 328 376 359 388 365 ...\n#>  $ grower : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 2 2 2 3 3 3 1 ...\n#>  $ box    : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 2 ...\n#>  $ cluster: Factor w/ 3 levels \"1\",\"2\",\"3\": 1 2 3 1 2 3 1 2 3 1 ...\nformula = wt ~ f(grower,model=\"iid\")+ f(box,model=\"iid\")\nfit = inla(formula, family=\"gaussian\",data=broccoli,\n           control.compute = list(dic=TRUE,waic=TRUE))  \nfit$summary.random\n#> $grower\n#>   ID          mean          sd  0.025quant      0.5quant\n#> 1  1  7.263538e-07 0.007894824 -0.01591511  6.420347e-07\n#> 2  2 -5.084287e-06 0.007894824 -0.01592288 -4.494085e-06\n#> 3  3  4.357984e-06 0.007894824 -0.01591024  3.852097e-06\n#>   0.975quant mode          kld\n#> 1 0.01591705   NA 3.745040e-07\n#> 2 0.01590927   NA 3.745043e-07\n#> 3 0.01592191   NA 3.745042e-07\n#> \n#> $box\n#>   ID        mean        sd 0.025quant     0.5quant\n#> 1  1  0.04247577 0.5374997  -1.014817  0.038503287\n#> 2  2 -0.02435265 0.5371637  -1.102194 -0.022076617\n#> 3  3 -0.01076043 0.5370313  -1.083948 -0.009755009\n#> 4  4 -0.00736242 0.5370142  -1.079425 -0.006674529\n#>   0.975quant mode          kld\n#> 1   1.126910   NA 6.939304e-07\n#> 2   1.037941   NA 6.637744e-07\n#> 3   1.055560   NA 6.520024e-07\n#> 4   1.060002   NA 6.504877e-07\nfit$summary.hyperpar\n#>                                                 mean\n#> Precision for the Gaussian observations 3.917076e-03\n#> Precision for grower                    1.883236e+04\n#> Precision for box                       3.249673e+00\n#>                                                   sd\n#> Precision for the Gaussian observations 9.621250e-04\n#> Precision for grower                    9.679903e+03\n#> Precision for box                       1.057522e+00\n#>                                           0.025quant\n#> Precision for the Gaussian observations 2.226044e-03\n#> Precision for grower                    5.498160e+03\n#> Precision for box                       1.468091e+00\n#>                                             0.5quant\n#> Precision for the Gaussian observations 3.856152e-03\n#> Precision for grower                    1.702863e+04\n#> Precision for box                       3.166203e+00\n#>                                           0.975quant mode\n#> Precision for the Gaussian observations 5.974765e-03   NA\n#> Precision for grower                    4.263837e+04   NA\n#> Precision for box                       5.541419e+00   NA\nnombres=c(\"sigma\",\"grower\",\"box\")\nsigma.post=as.data.frame(inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[1]]))\nsigma.grower.post =as.data.frame(inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[2]]))\nsigma.box.post = as.data.frame(inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[3]]))\n\nsigma=rbind(sigma.post,sigma.grower.post,sigma.box.post)\nsigma$efecto=rep(c(\"sigma\",\"grower\",\"box\"),\n                 c(nrow(sigma.post),nrow(sigma.grower.post),nrow(sigma.box.post))) \n\nggplot(sigma,aes(x=x,y=y)) + \n  geom_line(aes(color=efecto)) +\n  labs(x=expression(sigma),y=\"D.Posterior\")+\n  facet_wrap(vars(efecto),scales = \"free\")+\n  theme(axis.text.x = element_text(angle = 45))\nn=1000\ntau=as.data.frame(inla.hyperpar.sample(n,fit,improve.marginals=TRUE))\nsigma2=apply(tau,2,function(x) 1/x)\ncolnames(sigma2)=c(\"sigma2d\",\"sigma2G\",\"sigma2B\")\nsigma2=as.data.frame(sigma2)\nsigma2=sigma2 %>%\n  mutate(contrib.G=sigma2G/(sigma2d+sigma2G+sigma2B),\n         contrib.B=sigma2B/(sigma2d+sigma2G+sigma2B))\n\n# contribución a la varianza de grower: Pr(contrib.G>1/100)\ncat(paste(\"Prob.contribución de grower a la varianza > 1%=\",mean(sigma2$contrib.G > 0.01),\"\\n\"))\n#> Prob.contribución de grower a la varianza > 1%= 0\n# contribución a la varianza de box: Pr(contrib.B>1/100)\ncat(paste(\"Prob.contribución de box a la varianza > 1%=\",mean(sigma2$contrib.B > 0.01)))\n#> Prob.contribución de box a la varianza > 1%= 0\nformula = wt ~ 1\nfit = inla(formula, family=\"gaussian\",data=broccoli,\n           control.compute = list(dic=TRUE,waic=TRUE))  \nfit$summary.fixed\n#>                 mean       sd 0.025quant 0.5quant\n#> (Intercept) 358.1666 2.775659   352.6953 358.1667\n#>             0.975quant mode          kld\n#> (Intercept)    363.638   NA 1.042823e-08\nfit$summary.hyperpar\n#>                                               mean\n#> Precision for the Gaussian observations 0.00378082\n#>                                                   sd\n#> Precision for the Gaussian observations 0.0008608017\n#>                                          0.025quant\n#> Precision for the Gaussian observations 0.002272089\n#>                                           0.5quant\n#> Precision for the Gaussian observations 0.00371182\n#>                                          0.975quant mode\n#> Precision for the Gaussian observations 0.005662025   NA\ntheta.post = as.data.frame(fit$marginals.fixed[[1]])\nsigma.post=as.data.frame(inla.tmarginal(function(tau) tau^(-1/2),\n  fit$marginals.hyperpar[[1]]))\n\nposterior=rbind(theta.post,sigma.post)\nposterior$efecto=rep(c(\"theta\",\"sigma\"),\n                     c(nrow(theta.post),nrow(sigma.post)))\nggplot(posterior,aes(x=x,y=y)) + \n  geom_line(aes(color=efecto)) +\n  labs(x=\"\",y=\"D.Posterior\")+\n  facet_wrap(vars(efecto),scales = \"free\")+\n  theme(legend.position = \"none\")"},{"path":"anova.html","id":"modelos-mixtos","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.7 Modelos mixtos","text":"En ocasiones cuando ajustamos un modelo lineal tendremos algunos factores de clasificación que operan como efectos fijos y otros que operan como efectos aleatorios. Estaremos ante modelos lineales mixtos. Siendo estrictos, realmente el modelo con solo efectos aleatorios ya es un modelo mixto, puesto que incluye como efecto fijo una interceptación global.En un modelo lineal mixto seguimos asumiendo una respuesta normal, gaussian, con media igual un predictor lineal \\(\\eta=X\\beta + Z u\\), donde \\(X\\) es una matriz de diseño con los efectos fijos \\(x_1,x_2,...\\), y \\(Z\\) la correspondiente para los efectos aleatorios \\(z_1, z_2,...\\). Se asume además una varianza desconocida que puede ser distinta para distintos niveles de los predictores, e incluso contener correlaciones entre niveles distintos, y que en general se suele expresar través de una matriz de covarianzas \\(\\Sigma\\), \\((y|\\eta,\\Sigma) \\sim N(\\eta,\\Sigma)\\).En INLA la fórmula de predicción de una respuesta \\(y\\) partir de un conjunto de efectos fijos x1,x2,…, y un conjunto de efectos aleatorios z1,z2,… se especifica como:De nuevo mencionar que la opción más habitual para los efectos aleatorios en un modelo lineal es model=\"iid\".","code":"\nformula = y ~ 1 + x1 + x2  + f(z1, model=\"\") + f(z2,model=\"\") "},{"path":"anova.html","id":"datos-longitudinales-con-pendientes-iguales","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.7.1 Datos longitudinales con pendientes iguales","text":"Veamos cómo resolver las inferencias través de un ejemplo disponible en R-bloggers, proporcionado por Patrick Curran y descargable desde Github. Se refieren estos datos, un estudio con 405 niños en los dos primeros años de la escuela infantil, medidos lo largo de cuatro instantes equidistantes (medidos todos en todos los sujetos) para registrar su progreso en lectura y en comportamiento antisocial. Nos centramos aquí exclusivamente en intentar predecir los progresos en lectura (variable read) para cada sujeto (identificado como id) lo largo de los 4 instantes de medición (occasion).Cargamos los datos, prescindimos de los que tienen valores faltantes, y los inspeccionamos en la Figura 3.10.\nFigura 3.10: Descripción de la BD CurranLong sobre desarrollo de las habilidades lectoras en niños.\nComo base vamos asumir normalidad en la respuesta de un sujeto \\(\\) en un instante \\(j\\), y plantear un modelo lineal para obtener nuestras conclusiones.\n\\[( y_{ij}|\\mu_{ij},\\sigma^2 ) \\sim N(\\mu_{ij},\\sigma^2);  \\ =1,...,450; j=1,2,3,4\\]la vista de la Figura 3.10 podríamos considerar el tiempo afecta de modo positivo y lineal sobre las habilidades lectoras (más tiempo, mejores habilidades), lo que convierte la variable occasion en una covariable numérica (efecto fijo): nos interesará cuantificar cómo afecta el tiempo la capacidad lectora.Sin embargo, también en el gráfico apreciamos que cada sujeto arranca de un inicio diferente, o lo que es lo mismo, su recta de predicción tiene una interceptación distinta. Puesto que nos interesa comparar los individuos, planteamos incorporar un efecto aleatorio del sujeto (variable id). Estamos pues, hablando de predecir la habilidad lectora de un sujeto \\(\\) en un instante \\(t_{ij}=j\\) con:\\[\\mu_{ij}=\\theta + \\alpha_i + \\beta \\cdot t_{ij} \\]\ncon\n\\[\\begin{eqnarray*}\n\\text{Nivel II} && \\\\\n\\theta &\\sim & N(0,100) \\\\\n\\beta &\\sim& N(0,100) \\\\\n\\alpha_i &\\sim& N(0,\\sigma_{\\alpha}^2) \\\\\n\\tau=1/\\sigma^2 &\\sim& Ga(0.001,0.001) \\\\\n\\text{Nivel III} && \\\\\n\\tau_{\\alpha}=1/\\sigma_{\\alpha}^2 &\\sim& Ga(0.001,0.001)\n\\end{eqnarray*}\\]La varianza \\(\\sigma_{\\alpha}^2\\) representa la variabilidad existente entre las distintas interceptaciones o niveles cognitivos de los sujetos en el inicio del estudio.En la Figura 3.11 se muestran las distribuciones posteriores obtenidas sobre efectos fijos y varianzas.\nFigura 3.11: Distribuciones posteriores para el modelo con interceptaciones aleatorias por sujeto y efecto fijo del tiempo.\n","code":"\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/curran_dat.csv\"\ncurran_dat=read.csv(url) %>%\n  select(id, occasion, read) %>%\n  filter(complete.cases(.))\n# el identificador de cada sujeto lo convertimos a factor\ncurran_dat$id=as.factor(curran_dat$id)\ncurran_dat$occasion=as.double(curran_dat$occasion)\n# Relaciones\ng1=ggplot(curran_dat, aes(x=as.factor(occasion),y=read))+\n  geom_boxplot()\ng2=ggplot(curran_dat, aes(x=occasion,y=read))+\n  geom_line(aes(group=id),color=\"grey\",size=0.4)\ngrid.arrange(g1,g2,ncol=2)\nprec.prior=list(prec=list(param=c(0.001,0.001)))\nformula= read ~ occasion + f(id,model=\"iid\",hyper = prec.prior) \nfit=inla(formula,family=\"gaussian\",data=curran_dat,\n          control.family=list(hyper=prec.prior))\nfit$summary.fixed\n#>                 mean         sd 0.025quant 0.5quant\n#> (Intercept) 2.703751 0.05266776   2.600408 2.703757\n#> occasion    1.101333 0.01760836   1.066782 1.101336\n#>             0.975quant mode          kld\n#> (Intercept)   2.807060   NA 1.200724e-11\n#> occasion      1.135862   NA 5.550139e-12\nfit$summary.hyperpar\n#>                                             mean        sd\n#> Precision for the Gaussian observations 2.169660 0.1012697\n#> Precision for id                        1.286165 0.1092214\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations   1.975933 2.167725\n#> Precision for id                          1.083681 1.281858\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations   2.374856   NA\n#> Precision for id                          1.513708   NA\n\n# Agrupamos todas las distribuciones posteriores\nnfixed=length(names(fit$marginals.fixed))\nnhyp=length(names(fit$marginals.hyperpar))\nres=NULL\nfor(i in 1:nfixed){\nres=rbind(res,data.frame(fit$marginals.fixed[[i]],\n                         id=names(fit$marginals.fixed)[i],\n                          tipo=\"fixed\"))\n}\nfor(j in 1:nhyp){\n    res=rbind(res,data.frame(\n    inla.tmarginal(function(tau) tau^(-1/2),fit$marginals.hyperpar[[j]]),\n                         id=str_sub(names(fit$marginals.hyperpar)[j], start =15),\n                          tipo=\"sigma\"))\n}\nggplot(res,aes(x=x,y=y))+\n  geom_line(aes(color=id))+\n  facet_wrap(vars(tipo),scales=\"free\")+\n  theme(legend.position=\"top\",\n        legend.title=element_blank(),\n        legend.text = element_text(size=5))"},{"path":"anova.html","id":"datos-longitudinales-con-pendientes-distintas","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.7.2 Datos longitudinales con pendientes distintas","text":"Belenky et al. (2003) describen un estudio de los tiempos de reacción en pacientes los que se ha privado de sueño durante 10 días; cada día se ha ido registrando la respuesta para cada uno de los 18 sujetos en el estudio. Los datos están disponibles como sleepstudy en la librería lme4 y tienen como variables el tiempo medio de reacción en microsegundos (Reaction), el número de días con privación de sueño (Days) y un id para cada sujeto (Subject). Los tiempos de reacción se transforman segundos para tener mayor estabilidad. Aun así, en la Figura 3.12 se aprecia que el número de días de falta de sueño afecta de modo distinto cada sujeto.\nFigura 3.12: Tiempos de reacción en función del número de días con falta de sueño (sleepstudy) para los 18 sujetos en el estudio\nUn modelo razonable para estos datos es un modelo lineal que relacione los tiempos de reacción con los días, pero que tenga interceptaciones y pendientes diferentes para cada sujeto. El efecto sujeto entraría en el modelo como un efecto aleatorio para relacionar todos los datos del mismo sujeto sin perder la asunción de independencia entre las observaciones de sujetos distintos. Si llamamos \\(y=Reaction\\) la respuesta, estaríamos planteando el siguiente modelo:\\[ y_{ij}|\\mu_{ij},\\sigma^2 \\sim N(\\mu,\\sigma^2), =1,...,18; j=1, ...,10\\]con\\[\\mu_{ij}=\\theta + \\alpha_i + \\beta \\cdot x_{ij} + \\gamma_{ij}\\]donde el predictor \\(x\\) es la variable Days, \\((\\theta,\\beta)\\) se tratarían como efectos fijos con prioris difusas ante falta de información, y \\((\\alpha_i,\\gamma_{ij})\\) como efectos aleatorios, con normales centradas en cero y una varianza desconocida la que habría que asignar así mismo, una distribución priori. El modelo jerárquico que surge es pues:\\[\\begin{eqnarray*}\n\\text{Nivel } && \\\\\ny_{ij}|\\mu_{ij},\\sigma^2 &\\sim& N(\\mu,\\sigma^2), =1,...,18; j=1, ...,10 \\\\\n\\text{Nivel II} && \\\\\n\\theta &\\sim & N(0,1000) \\\\\n\\beta &\\sim& N(0,1000) \\\\\n\\alpha_i &\\sim& N(0,\\sigma_{\\alpha}^2) \\\\\n\\gamma_{ij} &\\sim & N(0,\\sigma_{\\gamma})^2 \\\\\n\\tau=1/\\sigma^2 &\\sim& Ga(0.001,0.001)\\\\\n\\text{Nivel III} && \\\\\n\\tau_{\\alpha}=1/\\sigma_{\\alpha}^2 &\\sim& Ga(0.001,0.001) \\\\\n\\tau_{\\gamma}=1/\\sigma_{\\alpha}^2 &\\sim& Ga(0.001,0.001) \\end{eqnarray*}\\]En INLA modelizamos esta propuesta utilizando como predictores;la covariable para generar una interceptación ‘media’ (efecto fijo),el efecto aleatorio de cada sujeto para generar interceptaciones distintas,la interacción entre la covariable y el efecto aleatorio, través de la matriz de diseño que hemos de construir específicamente, y definir en paralelo un índice de la misma dimensión de los datos, para aplicarla. En la interacción la primera variable define el número de grupos y la segunda el valor de la covariable.Obtenemos en consecuencia, efectos fijos e hiperparámetros, cuyas inferencias posteriores se resumen con:Y los efectos aleatorios:En la Figura 3.13 mostramos los datos y también los valores ajustados para las rectas, en términos de las interceptaciones y pendientes medias de las correspondientes distribuciones posteriores, además de la banda de estimación que construimos con los correspondientes percentiles de las posterioris.\nFigura 3.13: Estimaciones posteriores de los predictores lineales: medias y RC.\nEn la Figura 3.14 mostramos la distribución posterior de los errores de datos y aleatorios.\nFigura 3.14: Distribución posterior del error de los datos y el error aleatorio\n","code":"\ndata(sleepstudy,package=\"lme4\")\nsleepstudy$Reaction <- sleepstudy$Reaction / 1000\nggplot(sleepstudy,aes(x=Days,y=Reaction))+\n  geom_point(size=0.5)+\n  geom_smooth(method=\"lm\",color=\"blue\",size=0.5)+\n  facet_wrap(vars(Subject),ncol=6)+\n  theme(axis.text.x = element_text(size=5),\n        axis.text.y = element_text(size=5))\n#> `geom_smooth()` using formula 'y ~ x'\nprec.prior=list(prec=list(param=c(0.001,0.001)))\n# matriz de diseño para la interacción\nZ <- as(model.matrix( ~ 0 + Subject:Days, data = sleepstudy), \"Matrix\")\n# índice para aplicar la matriz de diseño\nDayR=1:nrow(sleepstudy)\nformula= Reaction ~ Days + f(Subject,model=\"iid\",hyper=prec.prior)+\n  f(DayR,model=\"z\",Z=Z,hyper = prec.prior) \nfit=inla(formula,family=\"gaussian\",data=sleepstudy,\n         control.compute=list(config=TRUE))\n#> Warning in inla.model.properties.generic(inla.trim.family(model), mm[names(mm) == : Model 'z' in section 'latent' is marked as 'experimental'; changes may appear at any time.\n#>   Use this model with extra care!!! Further warnings are disabled.\n#> as(<dgCMatrix>, \"dgTMatrix\") is deprecated since Matrix 1.5-0; do as(., \"TsparseMatrix\") instead\nround(fit$summary.fixed,3)\n#>              mean    sd 0.025quant 0.5quant 0.975quant mode\n#> (Intercept) 0.251 0.008      0.236    0.251      0.267   NA\n#> Days        0.010 0.003      0.004    0.010      0.017   NA\n#>             kld\n#> (Intercept)   0\n#> Days          0\nround(fit$summary.hyperpar,3)\n#>                                             mean       sd\n#> Precision for the Gaussian observations 1566.714  182.872\n#> Precision for Subject                   1314.752  571.883\n#> Precision for DayR                      6067.455 2128.979\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations   1231.362 1558.540\n#> Precision for Subject                      520.881 1209.122\n#> Precision for DayR                        2819.866 5762.948\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations   1950.856   NA\n#> Precision for Subject                     2728.303   NA\n#> Precision for DayR                       11105.440   NA\nnames(fit$marginals.random)\n#> [1] \"Subject\" \"DayR\"\nhead(fit$summary.random$Subject)\n#>    ID         mean         sd    0.025quant     0.5quant\n#> 1 308 -0.003768852 0.01446450 -0.0322858911 -0.003748470\n#> 2 309 -0.037614850 0.01485941 -0.0674454901 -0.037392675\n#> 3 310 -0.038204749 0.01487067 -0.0680609887 -0.037981048\n#> 4 330  0.028705900 0.01469936  0.0002843469  0.028533645\n#> 5 331  0.025993562 0.01465095 -0.0023753053  0.025835575\n#> 6 332  0.009899213 0.01447470 -0.0184009765  0.009836371\n#>     0.975quant mode          kld\n#> 1  0.024632654   NA 5.824657e-09\n#> 2 -0.009029191   NA 2.027908e-08\n#> 3 -0.009601917   NA 2.046438e-08\n#> 4  0.058095342   NA 1.427020e-08\n#> 5  0.055251016   NA 1.290466e-08\n#> 6  0.038554205   NA 6.836828e-09\nhead(fit$summary.random$DayR)\n#>   ID         mean          sd   0.025quant     0.5quant\n#> 1  1 6.924170e-06 0.001501481 -0.002937713 6.924374e-06\n#> 2  2 1.056644e-02 0.004274273  0.002188712 1.055373e-02\n#> 3  3 2.106571e-02 0.008121897  0.005144081 2.103764e-02\n#> 4  4 3.184262e-02 0.012056260  0.008205556 3.180029e-02\n#> 5  5 4.249501e-02 0.016013222  0.011099092 4.243829e-02\n#> 6  6 5.322667e-02 0.019979602  0.014052998 5.315581e-02\n#>   0.975quant mode          kld\n#> 1 0.00295156   NA 5.527502e-11\n#> 2 0.01901743   NA 7.952067e-09\n#> 3 0.03714922   NA 1.020975e-08\n#> 4 0.05572392   NA 1.066174e-08\n#> 5 0.07421814   NA 1.083074e-08\n#> 6 0.09280916   NA 1.090778e-08\nsleepstudy.pred = sleepstudy %>%\n  mutate(fitted=fit$summary.fitted.values$mean,\n         rc.low=fit$summary.fitted.values$\"0.025quant\",\n         rc.up=fit$summary.fitted.values$\"0.975quant\") \n\nggplot(sleepstudy.pred,aes(x=Days,y=Reaction))+\n  geom_point(size=0.5)+\n  geom_line(aes(y=fitted),color=\"blue\")+\n  geom_line(aes(y= rc.low),color=\"skyblue\")+\n  geom_line(aes(y=rc.up),color=\"skyblue\")+\n  facet_wrap(vars(Subject),ncol=6)+\n  theme(axis.text.x = element_text(size=5),\n        axis.text.y = element_text(size=5))\nnhyp=length(names(fit$marginals.hyperpar))\nres=NULL\nfor(j in 1:nhyp){\n    res=rbind(res,data.frame(\n    inla.tmarginal(function(tau) tau^(-1/2),fit$marginals.hyperpar[[j]]),\n                         id=str_sub(names(fit$marginals.hyperpar)[j], start =15)))\n}\nggplot(res,aes(x=x,y=y))+\n  geom_line(aes(color=id))+\n  labs(x=expression(sigma),y=\"\")+\n  theme(legend.position=\"top\",\n        legend.title=element_blank(),\n        legend.text = element_text(size=5))"},{"path":"anova.html","id":"efectos-anidados","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.7.3 Efectos anidados","text":"Hablamos de efectos anidados cuando cada miembro de un grupo está contenido completamente dentro de una única unidad de otro grupo. Que un factor esté anidado en otro B, implica que cada nivel de B contiene niveles distintos de , esto es, cada nivel de está vinculado solo algún nivel de B.La base de datos eggs en la librería faraway nos resulta útil para describir este tipo de modelos con efectos anidados. Estos datos son los resultantes de un experimento para testar la consistencia en los tests de laboratorio que realizaban laboratorios distintos, técnicos distintos. Para ello se dividió en varias muestras un tarro de polvo de huevo seco homogeneizado (con idéntico contenido graso). Se enviaron 4 muestras cada uno de los 6 laboratorios. De esas 4 muestras, 2 se etiquetaron como G y 2 como H (aun siendo idénticas). Se dieron instrucciones los laboratorios de dar dos muestras dos técnicos distintos. Los técnicos recibieron instrucciones de dividir sus muestras en dos partes y medir el contenido graso de cada una. Así, cada laboratorio reportó 8 mediciones del contenido graso (Fat), cada técnico 4 mediciones, con 2 réplicas en cada una de las dos muestras.Realmente, el laboratorio, el técnico y la muestra solo deberían generar variabilidad en la respuesta, pero en ningún caso generar mediciones distintas. Estamos pues interesados en investigar la magnitud del error debido al laboratorio, al técnico y la identificación de muestras. Es por ello que tiene sentido considerarlos efectos aleatorios.Tenemos así en este ejemplo, los técnicos (Technician) anidados en los laboratorios (Lab). En la Figura 3.15 se muestra claramente la variación entre laboratorios, entre técnicos, y debida al efecto irreal de tener dos muestras distintas G y H (Sample).\nFigura 3.15: Descripción de eggs: variación entre laboratorios y técnicos.\nEl modelo que planteamos para estimar la respuesta \\(y_{ijk}\\), contenido graso de la muestra \\(k\\) (\\(k=1,2\\)) del laboratorio \\(\\) (\\(=1,...,6\\)), por el técnico \\(j\\) (\\(j=1,2\\)) está basado como siempre, en el modelo normal, \\((y_{ijk}|\\mu_{ijk},\\sigma^2) \\sim N(\\mu_{ijk},\\sigma^2)\\), con una media o predictor lineal representado por:\\[ \\mu_{ijk}= \\theta + \\alpha_i^{lab} + \\beta_{j:}^{tec} + \\gamma_{k:(j:)}^{sam}\\]\ny asumiendo en un segundo nivel del modelo las distribuciones priori:\n\\[\\begin{eqnarray*}\n\\theta &\\sim& N(0,1000) \\\\\n\\tau=1/\\sigma^2 &\\sim& Ga(0.001,0.001) \\\\\n\\alpha_i^{lab}&\\sim& N(0,\\sigma_{lab}^2); \\  = 1,...,4 \\\\\n\\beta_{j:}^{tec}&\\sim& N(0,\\sigma_{tec}^2); \\  j:= 1,...,12 \\\\\n\\gamma_{k:(j:)}^{sam}&\\sim& N(0,\\sigma_{sam}^2); \\ k:(j:)=1,...,24\n\\end{eqnarray*}\\]El tercer nivel recibiría las distribuciones priori para los hiperparámetros \\(\\sigma_{lab}^2, \\sigma_{tec}^2,\\sigma_{sam}^2\\), sobre los que interesa inferir. priori, con mínima información asumiremos \\(GaI(0.001,0.001)\\).Para especificar en INLA los efectos anidados hemos de recurrir la matriz del modelo, model.matrix(), para crear las matrices de los efectos aleatorios anidados.continuación hemos de crear los correspondientes índices, de longitud similar la del número de registros en la base de datos, para aplicarles las correspondientes matrices de efectos anidados, y ya proceder con el ajuste como habitualmente hacemos.\nFigura 3.16: Distribución posterior del error de los datos y el error aleatorio\nAlternativamente podríamos crear una variable índice partir de las matrices de efectos aleatorios, para utilizarlas con model=\"iid\" para describir los efectos aleatorios:En la Figura 3.17 se muestra la distribución posterior del error de los datos y de los errores aleatorios.\nFigura 3.17: Distribución posterior del error de los datos y el error aleatorio\n","code":"\ndata(eggs,package=\"faraway\")\nggplot(eggs,aes(x=Lab,y=Fat))+\n  geom_boxplot(aes(color=Technician))+\n  facet_wrap(vars(Sample))\n# matrices de efectos aleatorios anidados\nZlt <- as(model.matrix( ~ 0 + Lab:Technician, data = eggs), \"Matrix\")\nZlts <- as(model.matrix( ~ 0 + Lab:Technician:Sample, data = eggs), \"Matrix\")\n\n# índices para aplicar los efectos aleatorios\neggs$IDt = eggs$IDts = 1:nrow(eggs)\n\n# Ajuste\nprec.prior=list(prec=list(param=c(0.001,0.001)))\nformula = Fat ~ 1 + f(Lab,model=\"iid\",hyper=prec.prior) +\n  f(IDt,model=\"z\",Z=Zlt,hyper=prec.prior)+\n  f(IDts,model=\"z\",Z=Zlts,hyper=prec.prior)\n\nfit <- inla(formula,data = eggs, \n            control.predictor = list(compute = TRUE), \n            control.family=list(hyper=prec.prior),\n            control.fixed=list(prec.intercept=0.001))\n# inferencias de interés\nround(fit$summary.hyperpar,4)\n#>                                             mean       sd\n#> Precision for the Gaussian observations 142.0218  39.6765\n#> Precision for Lab                       349.8929 651.1105\n#> Precision for IDt                       206.0552 210.5099\n#> Precision for IDts                      366.9446 335.2833\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations    77.8347 137.4879\n#> Precision for Lab                          22.4906 170.1973\n#> Precision for IDt                          26.6547 144.1501\n#> Precision for IDts                         59.8946 270.7299\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations   232.9089   NA\n#> Precision for Lab                        1808.5301   NA\n#> Precision for IDt                         762.2587   NA\n#> Precision for IDts                       1256.5629   NA\nnhyp=length(names(fit$marginals.hyperpar))\nres=NULL\nfor(j in 1:nhyp){\n    res=rbind(res,data.frame(\n    inla.tmarginal(function(tau) tau^(-1/2),fit$marginals.hyperpar[[j]]),\n                         id=str_sub(names(fit$marginals.hyperpar)[j], start =15)))\n}\nggplot(res,aes(x=x,y=y))+\n  geom_line(aes(color=id))+\n  labs(x=expression(sigma),y=\"\")+\n  theme(legend.position=\"top\",\n        legend.title=element_blank(),\n        legend.text = element_text(size=5))\neggs$labtech <- as.factor(apply(Zlt, 1, function(x){names(x)[x == 1]}))\neggs$labtechsamp <- as.factor(apply(Zlts, 1, function(x){names(x)[x == 1]}))\n\nformula=Fat ~ 1 + f(Lab, model = \"iid\", hyper = prec.prior) +\n    f(labtech, model = \"iid\", hyper = prec.prior) +\n  f(labtechsamp, model = \"iid\", hyper = prec.prior)\nfit=inla(formula, data = eggs, \n            control.predictor = list(compute = TRUE), \n            control.family=list(hyper=prec.prior),\n         control.fixed=list(prec.intercept=0.001))\nround(fit$summary.fixed,4)\n#>               mean     sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) 0.3875 0.0554     0.2756   0.3875     0.4994\n#>             mode kld\n#> (Intercept)   NA   0\nround(fit$summary.hyperpar,4)\n#>                                             mean       sd\n#> Precision for the Gaussian observations 141.9194  39.6191\n#> Precision for Lab                       349.8741 651.1154\n#> Precision for labtech                   206.0138 210.4541\n#> Precision for labtechsamp               366.9498 335.2886\n#>                                         0.025quant 0.5quant\n#> Precision for the Gaussian observations    77.8099 137.3972\n#> Precision for Lab                          22.4869 170.1808\n#> Precision for labtech                      26.6557 144.1258\n#> Precision for labtechsamp                  59.8970 270.7334\n#>                                         0.975quant mode\n#> Precision for the Gaussian observations   232.6614   NA\n#> Precision for Lab                        1808.4883   NA\n#> Precision for labtech                     762.0700   NA\n#> Precision for labtechsamp                1256.5812   NA\nnhyp=length(names(fit$marginals.hyperpar))\nres=NULL\nfor(j in 1:nhyp){\n    res=rbind(res,data.frame(\n    inla.tmarginal(function(tau) tau^(-1/2),fit$marginals.hyperpar[[j]]),\n                         id=str_sub(names(fit$marginals.hyperpar)[j], start =15)))\n}\nggplot(res,aes(x=x,y=y))+\n  geom_line(aes(color=id))+\n  labs(x=expression(sigma),y=\"\")+\n  theme(legend.position=\"top\",\n        legend.title=element_blank(),\n        legend.text = element_text(size=5))"},{"path":"anova.html","id":"conclusiones-1","chapter":"Unidad 3 Modelo de ANOVA","heading":"3.8 Conclusiones","text":"Hasta aquí desarrollamos los modelos lineales basados en Anova, esto es, en la integración de factores de clasificación como variables que van explicar diferencias en la respuesta, como los efectos fijos, o variabilidad extra en los datos, como los efectos aleatorios, veces incluso con otros predictores de tipo numérico, e incluso interaccionando con ellos.","code":""},{"path":"glm.html","id":"glm","chapter":"Unidad 4 Modelos lineales generalizados","heading":"Unidad 4 Modelos lineales generalizados","text":"Los modelos lineales generalizados (Generalized Linear Models GLM), son una clase de modelos introducidos por Nelder y Wedderburn (1972) y McCullagh y Nelder (1989), con el objetivo de extender la regresión lineal al caso en el que la variable dependiente se distribuya necesariamente según una normal, pero su distribución todavía pertenezca la familia exponencial (Binomial, Poisson, Gamma, Gausiana inversa básicamente). Trabajamos continuación con dos de los GLM más comunes en epidemiología y ciencias sociales: la regresión logística y la de Poisson, mostrando cómo usar R-INLA.Un modelo lineal generalizado está basado en asumir, además de una distribución de los datos dentro de la familia exponencial, una relación lineal entre cierta transformación del valor esperado de la respuesta \\(E(y_i)\\) y los predictores disponibles, sean covariables, efectos fijos, efectos aleatorios, o incluso alguna función de estos.Si \\(y\\) representa una respuesta observada, \\(x_1,x_2,..\\) una serie de covariables o efectos fijos, y \\(z_1,z_2,...\\) efectos aleatorios, el valor esperado de la respuesta lo denotamos como \\(\\mu\\), que\\[E(y_i|x,z,\\theta)=\\mu_i\\]\nPues bien, la relación entre esta media \\(\\mu\\) y un predictor lineal \\(\\eta\\) que construimos partir de los predictores disponibles, viene dado por una función link \\(g\\) tal que:\\[g(\\mu_i)=\\eta_i=\\mu + \\beta_1 x_{1i} +   \\beta_2 x_{2i} +...+ z_{1i} + z_{2i}+...\\]Todos los parámetros involucrados en el predictor lineal \\(\\eta\\) son los efectos latentes del modelo (fijos o aleatorios). Estos, junto con el resto de parámetros definidos en este primer nivel de la modelización (nivel de datos), han de modelizarse continuación, en un segundo nivel del modelo, con sus correspondientes distribuciones priori.El predictor lineal \\(\\eta\\) está relacionado linealmente con los predictores según:\n\\[\\eta_i=\\mu + \\beta_1 x_{1i} +   \\beta_2 x_{2i} +...+ z_{1i} + z_{2i}+...\\]\nrelación que se suele representar en forma matricial como\n\\[\\eta=X\\beta + Z u\\]Los modelos lineales que hemos visto antes (regresión, anova, ancova, modelos mixtos) se engloban dentro del modelo lineal generalizado.El argumento control.predictor=list(compute=TRUE) en la función inla permite obtener las distribuciones predictivas para el predictor lineal, que en estos casos es distinto los valores ajustados, fit$summary.fitted. Además para obtener la distribución marginal de los valores ajustados y predichos necesitamos incorporar la función inla el argumento control.compute=list(return.marginals.predictor=TRUE), y ya con todo ello podemos:fit$summary.linear.predictor resumir la inferencia posterior sobre los\npredictores lineales (distintos los fitted cuando hay una función link)fit$marginals.linear.predictor graficar y describir las distribuciones posteriores marginales para los predictores lineales","code":""},{"path":"glm.html","id":"modelos-jerárquicos-bayesianos","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.1 Modelos jerárquicos bayesianos","text":"lo largo del curso ya hemos ido comentando en ocasiones, algo sobre la especificación de un modelo en varios niveles. Presentamos ya de lleno estos modelos lineales generalizados como modelos multi-nivel o modelos jerárquicos, denominados así porque se va especificando por niveles (o jerarquías) la información disponible sobre todo aquello que es desconocido, distribución de los datos y parámetros.Un modelo bayesiano se modeliza través de un modelo jerárquico o multinivel en el que en el nivel se define la distribución asumida sobre la variable respuesta y que determina la verosimilitud. Esta variable depende de unos parámetros que definen los efectos fijos y aleatorios, y para los que hay que proporcionar la información previa disponible través de una distribución priori en el segundo nivel del modelo jerárquico. La distribución priori para los efectos fijos generalmente será común todos ellos, mientras que la distribución priori para los efectos aleatorios estará vinculada otros hiperparámetros para los que también será preciso especificar una distribución priori en un tercer nivel de la modelización, y así sucesivamente.\\[\\begin{eqnarray*}\nNivel &&\\\\\n( y | X, Z, \\theta) &\\sim & f(y|x,z,\\theta) \\text{f en fam.exponencial}\\\\\n&& E(y|x,z,\\theta)=\\mu; Var(y|x,z,\\theta)=\\Sigma \\\\\n&& g(\\mu)=\\eta=X\\beta + Z u \\\\\nNivel II &&\\\\\n\\beta &\\sim & N(0,\\sigma_{\\beta}), \\text{ con un valor dado  para } \\sigma_{\\beta} \\\\\nu|\\sigma_u^2 &\\sim_{iid}&  N(0,{\\sigma_u^2}) \\\\\n\\Sigma|s &\\sim& F_{\\Sigma|s} \\\\\nNivel III &&\\\\\n\\sigma_u^2 &\\sim&  F_{\\sigma} \\\\\ns &\\sim&  F_{s}\n\\end{eqnarray*}\\]","code":""},{"path":"glm.html","id":"regresión-logística","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.2 Regresión logística","text":"La regresión logística es el modelo estándar para respuestas binarias (éxitos/fracasos). Tiene dos variaciones, en función de si la respuesta representa observaciones individuales (0/1) o conteos (de éxitos) en grupos de sujetos.Si las observaciones son individualizadas, entonces\\[y_i|\\pi_i \\sim Ber(\\pi_i), \\ =1,...,n\\]\nEn el caso de que sean conteos en grupos,\\[y_i|\\pi_i\\sim Bin(n_i,\\pi_i), \\ =1,...,n\\]\nsiendo \\(n_i\\) el tamaño de cada uno de los \\(n\\) grupos disponibles, y \\(\\pi_i\\) la probabilidad de éxito (output de interés).La relación entre el predictor lineal \\(\\eta\\) construido con los predictores disponibles \\(x=(x_{1},...x_{M})\\) y la probabilidad \\(\\pi\\) se especifica través de la función logit:\n\\[logit(\\pi)=log\\left(\\frac{\\pi}{1-\\pi}\\right)=\\eta=X\\beta=\\beta_0+\\sum_{j=1}^M \\beta_j x_{j}\\]\nde forma que\n\\[\\pi=logit^{-1}(X\\beta)=\\frac{exp(X\\beta)}{1-exp(X\\beta)}\\]\nUna vez especificado el modelo, si hay información previa disponible sobre los efectos (fijos) \\({\\beta_o,\\beta_1,...\\beta_M}\\), se asumen distribuciones priori independientes y normales con media cero y varianza muy grande.","code":""},{"path":"glm.html","id":"interpretación-de-los-coeficientes-en-la-regresión-logit","chapter":"Unidad 4 Modelos lineales generalizados","heading":"Interpretación de los coeficientes en la regresión logit","text":"Puesto que \\(X\\beta=\\beta_0+\\sum_{j=1}^M \\beta_j x_{j}\\), la interceptación del predictor lineal \\(\\beta_0\\) se interpreta como los predictores toman el valor cero si son numéricos, o están en el nivel de referencia (para la estimación) si son categóricos, \\(\\eta(X=0)=\\beta_0=logit(\\pi)\\). En consecuencia, el logit inverso de \\(\\beta_0\\) se interpreta como la probabilidad de éxito \\(\\pi_i\\) cuando los predictores están en su nivel de referencia o son cero.\n\\[logit^{-1}(\\beta_0)=Pr(y=1|X=0).\\]En cuanto la interpretación de cualquier otro coeficiente de regresión en el predictor lineal, como \\(\\beta_1\\), echamos mano del concepto de odds y odds ratio.Los odds ratio, , comparan, través de un cociente, las posibilidades favor de un evento \\(E\\) bajo condiciones y de las posibilidades del mismo evento bajo condiciones B. Nos sirve para evaluar cuánto afecta dicho evento el hecho de variar las condiciones de B .\n\\[(,B)=\\frac{Pr(E|)/(1-Pr(E|))}{Pr(E|B)/(1-Pr(E|B))}.\\]En el modelo logístico, nos interesa saber el efecto que tiene sobre la respuesta (realmente sobre las probabilidad de éxito) el incremento de una unidad en la variable \\(x\\), y para ello consideramos los odds bajo \\(x\\) y los odds bajo \\(x+1\\), y en particular el logaritmo de los odds, log-odds:\n\\[log.odds(x+1)=log \\left( \\frac{P(y=1|x+1)}{P(y=0|x+1)} \\right)=log \\left(\\frac{\\pi}{1-\\pi} | x+1\\right)=\\beta_0+\\beta_1 (x+1)\\]\n\\[log.odds(x)=log \\left(\\frac{P(y=1|x)}{P(y=0|x)} \\right)=log \\left(\\frac{\\pi}{1-\\pi} | x\\right)=\\beta_0+\\beta_1 x\\]\nde modo que\n\\[log((x+1,x))=log \\left(\\frac{ods (x+1)}{ods(x)} \\right) = log.odds(x+1)-log.ods(x)= \\beta_1\\]\ny tenemos entonces que la exponencial del coeficiente \\(\\beta_1\\) nos da el odds ratio asociado dicha covariable.\n\\[exp(\\beta_1)=\\frac{odds(x+1)}{odds(x)}=(x+1,x).\\]\nEs decir, el coeficiente \\(\\beta_1\\) representa el cambio en los odds favor de un éxito cuando se incrementa en una unidad el predictor \\(x\\) al que acompaña en el predictor linea. Esta interpretación es muy común en Epidemiología.","code":""},{"path":"glm.html","id":"intención-de-voto-feb2022","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.2.1 Intención de voto feb2022","text":"Tenemos acceso los datos completos obtenidos en la encuesta encargada por El País y la Cadena Ser la empresa “40dB”, en febrero de 2022, sobre la intención de voto nacional (fuente).Queremos predecir la probabilidad de votar al partido que gobierna mayoritariamente en la actualidad, PSOE, registrado en la variable psoe. Vamos utilizar como predictores dos factores que nos dicen si el sujeto tiene simpatía por ese partido, psoe_sim, y si votó PSOE en las últimas elecciones psoe_past; también utilizaremos la comunidad autónoma ccaa como un efecto aleatorio, para contabilizar posible variación extra.Para ajustar el modelo utilizamos el argumento family=binomial y la opción control.predictor = list(link = 1) para establecer la función link apropiada para tener los valores ajustados en la escala correcta.Las distribuciones posteriores de los exponenciales de los efectos aleatorios se muestran en la Figura 4.1, identificadas en verde las de efectos positivos en la media posterior del predictor lineal (log-odds \\(>1\\)), y en rojo las de efectos negativos, e interpretables como más y menos favorables votar por el PSOE.\nFigura 4.1: Medias y RC posterioris para el log-odds de los efectos aleatorios\nLa distribución posterior de la probabilidad de voto para el PSOE para la comunidad con más variabilidad en el efecto aleatorio (Castilla-La Mancha), viene representada en la Figura 4.2 para las cuatro combinaciones posibles de valores para los predictores de simpatía y voto en el pasado.\nFigura 4.2: Medias y RC posteriores para la probabilidad de voto PSOE\n","code":"\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/barometro_feb22.csv\"\nbarometro_feb22=read.csv(url)\nnames(barometro_feb22)\n#>  [1] \"X\"                   \"id\"                 \n#>  [3] \"sexo\"                \"edad\"               \n#>  [5] \"edad_r\"              \"hab\"                \n#>  [7] \"prov\"                \"ccaa\"               \n#>  [9] \"edu\"                 \"cs\"                 \n#> [11] \"p1\"                  \"p2\"                 \n#> [13] \"p3\"                  \"p4_1\"               \n#> [15] \"p4_2\"                \"p4_3\"               \n#> [17] \"p4_4\"                \"p5\"                 \n#> [19] \"p6\"                  \"p7\"                 \n#> [21] \"hab_r\"               \"clase_social_r\"     \n#> [23] \"situacion_laboral_r\" \"educacion_r\"        \n#> [25] \"ponde\"\ndatos=barometro_feb22 %>%\n  select(id,p2,p3,p5,ccaa) %>%\n  mutate(psoe=1*(p2==\"PSOE (Partido Socialista Obrero Español)\"),\n         psoe_simp=1*(p3==\"PSOE (Partido Socialista Obrero Español)\"),\n         psoe_past=1*(p5==\"PSOE (Partido Socialista Obrero Español)\")) \n#summary(datos)\nprec.prior=list(prec=list(param=c(0.001,0.001)))\nformula = psoe ~ psoe_simp + psoe_past+ f(ccaa,model=\"iid\",hyper=prec.prior)\nfit=inla(formula,family=\"binomial\",data=datos,control.predictor = list(link = 1))\nfit$summary.fixed\n#>                  mean        sd 0.025quant  0.5quant\n#> (Intercept) -3.590584 0.1897382  -3.998972 -3.578293\n#> psoe_simp    3.085807 0.1865761   2.723930  3.084372\n#> psoe_past    2.352354 0.1856856   1.989725  2.351808\n#>             0.975quant mode          kld\n#> (Intercept)  -3.251360   NA 5.807529e-07\n#> psoe_simp     3.455831   NA 3.433699e-07\n#> psoe_past     2.718078   NA 9.427676e-07\nfit$summary.hyperpar\n#>                        mean      sd 0.025quant 0.5quant\n#> Precision for ccaa 70.84301 250.892   1.978347 10.68948\n#>                    0.975quant mode\n#> Precision for ccaa   589.3423   NA\nrandom = as.data.frame(fit$summary.random)\nrandom$pro=1*exp(random$ccaa.mean)>1\nggplot(random,aes(x=exp(ccaa.mean),y=ccaa.ID)) +\n  geom_point(aes(color=pro))+\n  geom_errorbarh(aes(xmin=exp(ccaa.0.025quant),xmax=exp(ccaa.0.975quant),color=pro))+\n  geom_vline(xintercept=1,linetype=\"dotted\")+\n  labs(x=\"Medias y RC posteriores para el log-odds\",y=\"Comunidad autónoma\")+\n  theme(legend.position=\"none\")\ndatos_pred = datos %>%\n  mutate(f.post=round(fit$summary.fitted.values$mean,3),\n        f.rc.low=round(fit$summary.fitted.values$\"0.025quant\",3),\n         f.rc.up=round(fit$summary.fitted.values$\"0.975quant\",3)) %>%\n  distinct(f.post,.keep_all = TRUE) %>%\n  filter(ccaa==\"Castilla - La Mancha\") %>%\n  mutate(simpast=str_c(psoe_simp,psoe_past))\nggplot(datos_pred,aes(x=f.post,y=simpast))+\n  geom_point(aes(color=simpast))+\n  geom_errorbarh(aes(xmin=f.rc.low,xmax=f.rc.up,color=simpast),height=0.2)+\n  labs(x=\"Medias y RC posteriores para la probabilidad de voto PSOE\",title=\"Castilla - La Mancha\")+\n  scale_y_discrete(name=\"\", \n                   labels=c(\"No simpatía/No votó PSOE\",\"No simpatía/Votó PSOE\",\n                            \"Simpatía/No votó PSOE\",\"Simpatía/Votó PSOE\"))+\n  theme(legend.position=\"none\")"},{"path":"glm.html","id":"mortalidad-por-infarto-en-sheffield","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.2.2 Mortalidad por infarto en Sheffield","text":"Utilizamos los datos stroke, disponibles en datasets SSTM-RINLA. Queremos evaluar la presencia de cierta asociación entre los niveles de NOx y el infarto en Sheffield, UK. Se dispone de la concentración anual de NOx medida en \\(\\mu g/m^3\\) y categorizada en quintiles, promediada durante el periodo 1994-1999, en la variable NOx.class y su análoga \\(NOx\\), y el número de muertes por infarto \\(y\\) en cada distrito identificado por el índice de desventajas y privación Townsend (categorizado en quintiles). Se dispone igualmente del tamaño de la población para cada registro, en la variable \\(pop\\). La respuesta \\(y\\) se puede considerar entonces como conteos (de muertes) sobre la población de cada distrito,\n\\[y_i|\\pi_i \\sim Bin(n_i, \\pi_i)\\]\ny el predictor lineal es función del nivel de NOx y del distrito:\n\\[\\eta_i=logit(\\pi_i)=\\beta_0 + \\sum_{k=2}^5 \\beta_{1k} (NOx_i=k)+ \\sum_{h=2}^5 \\beta_{2h} (Townsend_i=h)+logit(\\tilde{p_i})\\]\nsiendo \\(n_i\\) la población (número total de habitantes) del distrito en el que se ubica el registro \\(\\) (disponible en la variable \\(pop\\)). El término \\(\\tilde{p_i}\\) representa el resgo ajustado por sexo y edad de la mortalidad por infarto, calculada utilizando estandarización indirecta con ratios de referencia internos basados en 18 estratos (9 para edad y 2 para género), y que se usa como un riesgo base en el modelo (Maheswaran et al.2006). En el ejemplo se calcula como el ratio de la mortalidad dividido por la población de cada registro.Ajustamos ya el modelo, en el que las variables NOx y Townsend actúan como factores (efectos fijos) y el riesgo base se introduce como offset, para estandarizar los riesgos en función del tamaño de la población y poder equiparar así todos los distritos:Para obtener la probabilidad promedio de muerte por infarto en el distrito Townsend=1 y para el nivel NOx=1, que son los niveles base, nos apoyamos en la interceptación \\(\\beta_0\\). Sobre sus simulaciones será preciso deshacer el logit (con la función logit-inversa):El efecto \\(\\beta_{12}\\) representa el efecto en los log.odds de la mortalidad por infarto de estar en el nivel \\(NOx=2\\) frente al de estar en el nivel \\(NOx=1\\). Si queremos evaluar el odds-ratio, simplemente calculamos la distribución posterior de \\(exp(\\beta_{12})\\) con inla.tmarginal. Si sólo estamos interesados en su media, bastaría utilizar `inla.emarginal’:La probabilidad de muerte por infarto se incrementa en un 14.3% cuando la exposición de NOx cambia del primer al segundo nivel. Los odds-ratio para el resto de los niveles resultan realmente significativos: 11,3% el odds-ratio NOx3/NOx1, 30% NOx4/NOx1 y 53.2% NOx5/NOx1.","code":"\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/Stroke.csv\"\nStroke <- read.csv(url,sep=\",\",dec=\".\",header=TRUE)\n#riesgo base: ajuste por tamaño de la población\nStroke$Adjusted.prob <- Stroke$stroke_exp/Stroke$pop\n# logit del riesgo base\nStroke$logit.adjusted.prob <- log(Stroke$Adjusted.prob/(1-Stroke$Adjusted.prob))                          \nformula.inla <- y ~ 1 + factor(NOx) + factor(Townsend) + offset(logit.adjusted.prob)\nmodel.logistic <- inla(formula.inla, family=\"binomial\", Ntrials=pop, data=Stroke)\nround(model.logistic$summary.fixed[,1:5],3)\n#>                     mean    sd 0.025quant 0.5quant\n#> (Intercept)       -0.181 0.057     -0.293   -0.180\n#> factor(NOx)2       0.132 0.059      0.016    0.132\n#> factor(NOx)3       0.105 0.061     -0.014    0.105\n#> factor(NOx)4       0.261 0.059      0.144    0.260\n#> factor(NOx)5       0.425 0.062      0.302    0.425\n#> factor(Townsend)2  0.077 0.061     -0.043    0.077\n#> factor(Townsend)3  0.137 0.060      0.020    0.137\n#> factor(Townsend)4 -0.132 0.063     -0.255   -0.132\n#> factor(Townsend)5 -0.118 0.067     -0.250   -0.118\n#>                   0.975quant\n#> (Intercept)           -0.071\n#> factor(NOx)2           0.248\n#> factor(NOx)3           0.225\n#> factor(NOx)4           0.377\n#> factor(NOx)5           0.547\n#> factor(Townsend)2      0.198\n#> factor(Townsend)3      0.255\n#> factor(Townsend)4     -0.009\n#> factor(Townsend)5      0.014\nprob.stroke <- inla.tmarginal(function(x) exp(x)/(1+exp(x)), model.logistic$marginals.fixed[[1]])\ninla.zmarginal(prob.stroke)\n#> Mean            0.455034 \n#> Stdev           0.0139168 \n#> Quantile  0.025 0.427486 \n#> Quantile  0.25  0.445615 \n#> Quantile  0.5   0.455082 \n#> Quantile  0.75  0.464485 \n#> Quantile  0.975 0.482137\nggplot(data.frame(prob.stroke),aes(x=x,y=y))+geom_line()+\n         labs(x=expression(pi),y= expression(tilde(p)(paste(pi,\"|\",y,\",\",NOx[1],\",\",TS[1]))))\nodds.nox21 <- inla.tmarginal(function(x) exp(x), model.logistic$marginals.fixed$\"factor(NOx)2\")\ne<-inla.emarginal(exp, model.logistic$marginals.fixed$\"factor(NOx)2\")\nggplot(data.frame(odds.nox21),aes(x=x,y=y))+geom_line()+\n        labs(x=expression(OR(NOx[21])),y= expression(tilde(p)(paste(OR(NOx[21]),\"|\",y))))+\n        geom_vline(xintercept=e,color=\"pink\")+ geom_text(x=e,y=1,label=paste(\"mean=\",round(e,3)),color=\"red\")\ninla.emarginal(exp, model.logistic$marginals.fixed$\"factor(NOx)3\")\n#> [1] 1.113128\ninla.emarginal(exp, model.logistic$marginals.fixed$\"factor(NOx)4\")\n#> [1] 1.299909\ninla.emarginal(exp, model.logistic$marginals.fixed$\"factor(NOx)5\")\n#> [1] 1.532265"},{"path":"glm.html","id":"regresión-de-poisson","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.3 Regresión de Poisson","text":"La regresión de Poisson es útil cuando la variable respuesta representa conteos y estos toman valores discretos entre 0 y \\(+\\infty\\), sin una cota superior de referencia. El parámetro de interés es el número promedio de eventos \\(\\lambda=E(y)\\) y el link natural es el logaritmo, de modo que el predictor lineal está ligado con las covariables y factores según:\n\\[\\eta=log(\\lambda)=x \\beta, \\ \\ \\mbox{ y } \\ \\ \\lambda_i=exp(X \\beta)\\]Un modelo de Poisson puede especificarse según\n\\[y_i \\sim Po(\\lambda_i), =1,...,n\\]\n\\[\\eta_i=log(\\lambda_i)=\\beta_0+\\sum_{m=1}^M \\beta_mx_{im}.\\]Para completar el modelo se especifican distribuciones priori para \\(\\beta\\), típicamente como normales con media cero y una varianza grande cuando hay información disponible de estudios previos u opinión de expertos.Los coeficientes se interpretan través de la función exponencial:\\(exp(\\beta_0)=\\lambda_i\\) cuando todas las \\(x=0\\) si son continuas, o para el primer nivel de las categorías posibles si son categóricas.\\(exp(\\beta_m)\\) es el cambio que se produce en la respuesta promedio \\(y\\) cuando \\(x_m\\) se incrementa en una unidad.La mayoría de las veces que se utiliza la regresión de Poisson, el interés recáe en las ratios o riesgos relativos, más que en el número promedio de casos \\(\\lambda_i\\). Para cambiar la escala en términos de riesgo, ha de utilizarse un offset como factor de corrección en la especificación del modelo. Este offset representa el denominador del riesgo y entra en la regresión en una escala logarítmica, asumiendo que tiene un coeficiente de regresión fijado 1:\n\\[\\eta_i=log(\\lambda_i)=\\beta_0+\\sum_{m=1}^M \\beta_mx_{im}+log(Offset_i)\\]\ndonde el riesgo relativo de que se produzca un evento se obtiene según\n\\[log\\left(\\frac{\\lambda_i}{Offset_i}\\right)=\\beta_0+\\sum_{m=1}^M \\beta_mx_{im}\\]\ny los coeficientes entonces se interpretan en una escala de riesgo. En este caso al exponenciar la interceptación obtenemos el riesgo base, mientras que \\(exp(\\beta_m)\\) representa el cambio en el riesgo relativo debido un cambio de unidad en el predictor correspondiente.","code":""},{"path":"glm.html","id":"incidentes-en-barcos","chapter":"Unidad 4 Modelos lineales generalizados","heading":"4.3.1 Incidentes en barcos","text":"Utilizamos los datos ships.csv en datasets SSTM-RINLA para estimar el riesgo mensual de incidentes en barcos. Los factores potenciales del riesgo son el periodo de construcción (built), el periodo de operación (oper) y el tipo de barco (type).\nEl modelo se escribe en INLA continuación, utilizando como offset el log(months), que son los meses que ha navegado y ponderan en consecuencia el riesgo de incidentes. El modelo con el offset será entonces\n\\[y_i \\sim Poisson (E_i \\rho_i),\\]\ndonde \\(\\eta_i=log(\\rho_i)\\) es el predictor lineal y el promedio del número de incidentes \\(\\lambda_i=E_i \\rho_i\\). El offset se incluye en esta formulación en el predictor lineal.Así, la media de \\(exp(\\beta_0)\\), 0.0018, representa el ratio medio de incidentes por mes entre los barcos que fueron construidos entre el 60 y el 64, han operado entre el 60 y el 74 y son de tipo (las categorías de referencia). El ratio en 1000 meses sería del 1.8.Para los barcos de tipo E el incremento en el ratio mensual de incidentes, comparado con los de tipo es del 42,4%.Otros datos modelizables con una regresión de Poisson son los que provienen del libro de Andrews Herzberg y están descritos en (randomservices.org/random) consistentes en el número de soldados muertos por coces de caballo en diversos cuerpos de caballería del ejército prusiano, entre 1875 y 1894.Este modelo se implementa en INLA, partir de datos simulados, con el siguiente código","code":"\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/Ships.csv\"\nShipsIncidents <- read.csv(url,sep=\",\") \n\nformula.inla <- y ~ 1 + built + oper + type\nmodel.poisson <- inla(formula.inla,family=\"poisson\", data=ShipsIncidents, offset=log(months))\n\nround(model.poisson$summary.fixed[,1:5],3)\n#>               mean    sd 0.025quant 0.5quant 0.975quant\n#> (Intercept) -6.416 0.217     -6.852   -6.413     -5.998\n#> built65-69   0.696 0.150      0.406    0.695      0.994\n#> built70-74   0.819 0.170      0.487    0.818      1.153\n#> built75-79   0.453 0.233     -0.012    0.455      0.903\n#> oper75-79    0.384 0.118      0.153    0.384      0.617\n#> typeB       -0.543 0.178     -0.882   -0.546     -0.185\n#> typeC       -0.688 0.329     -1.366   -0.678     -0.075\n#> typeD       -0.075 0.291     -0.664   -0.069      0.476\n#> typeE        0.326 0.236     -0.141    0.327      0.785\nnames(model.poisson$marginals.fixed)\n#> [1] \"(Intercept)\" \"built65-69\"  \"built70-74\"  \"built75-79\" \n#> [5] \"oper75-79\"   \"typeB\"       \"typeC\"       \"typeD\"      \n#> [9] \"typeE\"\n# ratio medio de incidentes por mes en las categorías base\ninla.emarginal(exp,model.poisson$marginals.fixed[[1]])\n#> [1] 0.001674164\n# riesgo relativo de barcos tipo E\ninla.emarginal(exp,model.poisson$marginals.fixed$typeE)\n#> [1] 1.424414\nurl=\"https://raw.githubusercontent.com/BayesModel/data/main/HorseKicks.txt\"\nhorse<-read.csv(url,sep=\"\", dec=\".\",header=TRUE)\nhorse$sum<-apply(horse[,2:ncol(horse)],1,sum)\n\nfit=inla(sum~1,data=horse,family=\"poisson\",control.predictor=list(compute=TRUE))\nsummary(fit)\n#> \n#> Call:\n#>    c(\"inla.core(formula = formula, family = family, \n#>    contrasts = contrasts, \", \" data = data, quantiles = \n#>    quantiles, E = E, offset = offset, \", \" scale = \n#>    scale, weights = weights, Ntrials = Ntrials, strata = \n#>    strata, \", \" lp.scale = lp.scale, link.covariates = \n#>    link.covariates, verbose = verbose, \", \" lincomb = \n#>    lincomb, selection = selection, control.compute = \n#>    control.compute, \", \" control.predictor = \n#>    control.predictor, control.family = control.family, \n#>    \", \" control.inla = control.inla, control.fixed = \n#>    control.fixed, \", \" control.mode = control.mode, \n#>    control.expert = control.expert, \", \" control.hazard \n#>    = control.hazard, control.lincomb = control.lincomb, \n#>    \", \" control.update = control.update, \n#>    control.lp.scale = control.lp.scale, \", \" \n#>    control.pardiso = control.pardiso, only.hyperparam = \n#>    only.hyperparam, \", \" inla.call = inla.call, inla.arg \n#>    = inla.arg, num.threads = num.threads, \", \" \n#>    blas.num.threads = blas.num.threads, keep = keep, \n#>    working.directory = working.directory, \", \" silent = \n#>    silent, inla.mode = inla.mode, safe = FALSE, debug = \n#>    debug, \", \" .parent.frame = .parent.frame)\") \n#> Time used:\n#>     Pre = 2.19, Running = 0.158, Post = 0.00726, Total = 2.35 \n#> Fixed effects:\n#>              mean    sd 0.025quant 0.5quant 0.975quant mode\n#> (Intercept) 2.282 0.071      2.139    2.283       2.42   NA\n#>             kld\n#> (Intercept)   0\n#> \n#> Marginal log-Likelihood:  -61.30 \n#>  is computed \n#> Posterior summaries for the linear predictor and the fitted values are computed\n#> (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"referencias.html","id":"referencias","chapter":"Referencias","heading":"Referencias","text":"","code":""}]
