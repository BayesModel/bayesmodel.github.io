% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apacite}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Una primera aproximación a la Estadística Bayesiana},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Una primera aproximación a la Estadística Bayesiana}
\author{true \and true}
\date{2022-11-03}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{contexto}{%
\chapter{Contexto}\label{contexto}}

El curso ``Una primera aproximación a la Estadística Bayesiana'', con una duración de 10 horas, está ofertado a alumnado de doctorado con una formación científica en el ámbito BIO.

El curso se desarrollará íntegramente online a través de videoconferencia síncrona, durante un total de 10 horas, seccionadas en 4 sesiones de dos horas y media cada una de ellas, los días 8, 10, 15 y 17 de noviembre de 2022, de 16 a 18:30h.

Se presentarán los contenidos a través de ejemplos prácticos programados en R, para que el estudiantado pueda ir generando resultados y comentando las interpretaciones derivadas del análisis.

La evaluación es continua basada en la interacción con el profesorado durante las sesiones de trabajo.

\hypertarget{objetivos-de-aprendizaje}{%
\section{Objetivos de aprendizaje}\label{objetivos-de-aprendizaje}}

\begin{itemize}
\tightlist
\item
  Conocer los conceptos básicos en el planteamiento bayesiano de la Estadística.
\item
  Identificar la relevancia de la información previa y de expertos, y la proporcionada por los datos.
\item
  Conocer los procedimientos básicos para conjugar la información disponible.
\item
  Aplicar los conocimientos básicos en problemas sencillos.
\item
  Descubrir las dificultades computacionales en la inferencia bayesiana.
\end{itemize}

\hypertarget{contenidos-propuestos}{%
\section{Contenidos propuestos}\label{contenidos-propuestos}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  De probabilidad va la historia: la relevancia de las probabilidades condicionadas y el teorema de Bayes.
\item
  La jerga base: incertidumbre, a priori, a posteriori y verosímil.
\item
  Manos en la masa 1: ¿con qué probabilidad ocurrió?
\item
  Manos en la masa 2: ¿con qué abundancia ocurrió?
\item
  Curioseando para saber más: manuales y software.
\end{enumerate}

\hypertarget{contenidos-definitivos}{%
\section{Contenidos definitivos}\label{contenidos-definitivos}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  SESIÓN 1: Probabilidad y la aproximación bayesiana. Bayes y una proporción. Bayes y dos proporciones.
\item
  SESIÓN 2: INLA y la regresión lineal
\item
  SESIÓN 3: INLA y los modelos de ANOVA y ANCOVA
\item
  SESIÓN 4: INLA y el modelo lineal generalizado. Modelos jerárquicos.
\end{enumerate}

\hypertarget{inla}{%
\section{INLA}\label{inla}}

INLA es una librería de R que aproxima la inferencia Bayesiana para
modelos gausianos latentes (LGM). Sus siglas provienen de Integrated
Nested Laplace Approximation (INLA), que es un método para aproximar las
inferencias bayesianas a través de la aproximación de Laplace.

Aunque la metodología INLA se ha desarrollado sobre modelos que se
pueden expresar como campos aleatorios markovianos gausianos (*Gaussian
Markov random fields, GMRF), es viable para una gran familia de modelos
habituales en la práctica estadística.

Disponemos de referencias múltiples y documentación de esta librería en
la web \href{https://www.r-inla.org}{r-inla.org}, y en particular en el
manual de referencia de Gómez-Rubio (2021) titulado \href{https://becarioprecario.bitbucket.io/inla-gitbook/index.html}{Bayesian inference
with
INLA},
también publicado por \href{https://www.routledge.com/Bayesian-inference-with-INLA/Gomez-Rubio/p/book/9781138039872}{Chapman \& Hall-CRC
Press}.

\hypertarget{instalaciuxf3n}{%
\subsection{Instalación}\label{instalaciuxf3n}}

Para instalar la librería INLA hemos de ejecutar, desde R, el comando

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"INLA"}\NormalTok{, }\AttributeTok{repos=}\FunctionTok{c}\NormalTok{(}\FunctionTok{getOption}\NormalTok{(}\StringTok{"repos"}\NormalTok{), }
                \AttributeTok{INLA=}\StringTok{"https://inla.r{-}inla{-}download.org/R/stable"}\NormalTok{), }
                \AttributeTok{dep=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# y a continuación la cargamos con:}
\FunctionTok{library}\NormalTok{(INLA)}
\end{Highlighting}
\end{Shaded}

Para instalar actualizaciones, basta con ejecutar

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{options}\NormalTok{(}\AttributeTok{repos =} \FunctionTok{c}\NormalTok{(}\FunctionTok{getOption}\NormalTok{(}\StringTok{"repos"}\NormalTok{), }
                  \AttributeTok{INLA=}\StringTok{"https://inla.r{-}inla{-}download.org/R/testing"}\NormalTok{))}
\FunctionTok{update.packages}\NormalTok{(}\StringTok{"INLA"}\NormalTok{, }\AttributeTok{dep=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Las descargas y documentación completa sobre INLA está disponible en
\href{http://www.r-inla.org/home}{R-INLA home}.

Ya desde R, para pedir ayuda sobre funciones en INLA, basta usar el
comando \texttt{inla.doc()}, especificando dentro y entrecomillada, la
función/objeto sobre el que se solicita ayuda. Por ejemplo,
\texttt{inla.doc("ar1")} o \texttt{inla.doc("loggamma")}.

También utilizaremos una librería accesoria de INLA, \texttt{brinla}, desarrollada por \href{https://rdrr.io/github/julianfaraway/brinla/}{Faraway, Yue y Wan, 2022}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"remotes"}\NormalTok{)}
\NormalTok{remotes}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"julianfaraway/brinla"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fundamentos}{%
\subsection{Fundamentos}\label{fundamentos}}

INLA está basado en la resolución de integrales vía la aproximación de
Laplace, que aproxima el integrando a través de una expansión de Taylor
de segundo grado que permite calcular la integral analíticamente.
\begin{eqnarray*}
I_n&=&\int_x exp[nf(x)]dx \\
&\approx& \int_x exp[n(f(x_0)+1/2 (x-x_0)^2 f''(x_0))] dx \\
&=& exp[nf(x_0)] \cdot \sqrt{\frac{2\pi}{-n f''(x_0)}}
\end{eqnarray*}

Evita así los largos tiempos de simulación de las cadenas de Markov
Monte Carlo. Cuando las distribuciones a integrar son Gausianas, Laplace
da órdenes buenos de aproximación. Y este es el principio que usa para
modelizar la mayoría de los modelos habituales, que se integran dentro
de la amplia clase de los modelos gausianos latentes, en los que se
aplica INLA.

INLA se ha aplicado en mapeo estadístico, modelos de cohorte
multidimensionales, modelos de asociación espacial, genética, análisis
medioambientales, salud y epidemiología, dinámicas de infecciones,
estudios agronómicos, meta-análisis, impacto del cambio climático y
muchos más ámbitos (Rue et al, 2017).

\hypertarget{inlabasics}{%
\chapter{Regresión lineal}\label{inlabasics}}

\hypertarget{introducciuxf3n}{%
\section{Introducción}\label{introducciuxf3n}}

Una vez presentados los fundamentos de INLA vamos a utilizarlo para trabajar progresivamente desde los modelos más sencillos a los más sofisticados. Empezamos aquí con el modelo de regresión lineal simple, para continuar generalizando con el de regresión lineal múltiple.

Vamos a empezar a trabajar con INLA modelizando y ajustando un problema
sencillo de regresión lineal simple. La base de datos Davis (en la librería \texttt{carData}) contiene 200 registros de 5 variables relacionadas con un estudio sobre habituación de hombres y mujeres a la realización de ejercicio físico de forma regular. Las variables que se registraron son sexo, peso y altura (reales y reportados). Vamos a indagar la relación entre el peso real y el reportado a través de un análisis de regresión lineal simple.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"carData"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(Davis)}
\CommentTok{\#\textgreater{}  sex         weight          height          repwt       }
\CommentTok{\#\textgreater{}  F:112   Min.   : 39.0   Min.   : 57.0   Min.   : 41.00  }
\CommentTok{\#\textgreater{}  M: 88   1st Qu.: 55.0   1st Qu.:164.0   1st Qu.: 55.00  }
\CommentTok{\#\textgreater{}          Median : 63.0   Median :169.5   Median : 63.00  }
\CommentTok{\#\textgreater{}          Mean   : 65.8   Mean   :170.0   Mean   : 65.62  }
\CommentTok{\#\textgreater{}          3rd Qu.: 74.0   3rd Qu.:177.2   3rd Qu.: 73.50  }
\CommentTok{\#\textgreater{}          Max.   :166.0   Max.   :197.0   Max.   :124.00  }
\CommentTok{\#\textgreater{}                                          NA\textquotesingle{}s   :17      }
\CommentTok{\#\textgreater{}      repht      }
\CommentTok{\#\textgreater{}  Min.   :148.0  }
\CommentTok{\#\textgreater{}  1st Qu.:160.5  }
\CommentTok{\#\textgreater{}  Median :168.0  }
\CommentTok{\#\textgreater{}  Mean   :168.5  }
\CommentTok{\#\textgreater{}  3rd Qu.:175.0  }
\CommentTok{\#\textgreater{}  Max.   :200.0  }
\CommentTok{\#\textgreater{}  NA\textquotesingle{}s   :17}
\FunctionTok{plot}\NormalTok{(weight }\SpecialCharTok{\textasciitilde{}}\NormalTok{ repwt, }\AttributeTok{data=}\NormalTok{Davis)}
\end{Highlighting}
\end{Shaded}

\includegraphics{01-regresion_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Excluimos el valor outlier y los NA}
\NormalTok{davis}\OtherTok{=}\NormalTok{Davis }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(weight}\SpecialCharTok{\textless{}}\DecValTok{160}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\FunctionTok{which}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(repwt)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{variables-y-relaciones}{%
\section{Variables y relaciones}\label{variables-y-relaciones}}

Entendemos como variable respuesta \(y=weight\), de tipo numérico
(continua), y como variable explicativa o covariable, \texttt{repwt}, que pretendemos relacionar con un modelo de regresión lineal.

La especificación de respuesta \(y\) y predictores \(x_1,x_2,...\), en INLA se registra en una fórmula del tipo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ x\_1 }\SpecialCharTok{+}\NormalTok{ x\_2 }\SpecialCharTok{+}\NormalTok{...}
\end{Highlighting}
\end{Shaded}

en la que podemos prescindir del \(1\) que identifica la interceptación, pues el ajuste, por defecto, siempre se resolverá con su estimación, salvo que en su lugar se escriba un `-1'.

En nuestro problema tendríamos pues,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ weight }\SpecialCharTok{\textasciitilde{}}\NormalTok{ repwt}
\end{Highlighting}
\end{Shaded}

A continuación es procedente elegir el modelo sobre la respuesta, o lo
que es lo mismo, la verosimilitud.

\hypertarget{verosimilitud}{%
\section{Verosimilitud}\label{verosimilitud}}

En principio es razonable asumir normalidad en la respuesta, además de independencia entre todas las observaciones. Así, el modelo propuesto para la respuesta es:

\[(y_i|\theta,\beta,\sigma^2) \sim N(\theta+\beta x_i,\sigma^2), i=1,...,n\]

donde \(y=weight\) y \(x=repwt\), e \(i=1,...,n\) es un subíndice que identifica a cada uno de los registros disponibles en el banco de datos. \(\theta\) es la interceptación de la recta de regresión y \(\beta\) el coeficiente que explica la relación lineal entre \(s\) e \(y\). Veamos cómo especificar este modelo con INLA.

En INLA el vector \((\theta,\beta)\) identifica los \textbf{efectos latentes}, en cuya inferencia posterior estamos interesados. El modelo, o lo que es lo mismo, la verosimilitud, depende también de un parámetro de dispersión \(\sigma^2\) sobre el que también querremos inferir.

La función \texttt{name(inla.models())} proporciona un listado de todos los
tipos de modelos posibles para los datos (\emph{likelihood}), parámetros
(\emph{prior}), hiperparámetros (\emph{latent}), \ldots{} Es más, el listado completo
de todas las distribuciones disponibles para cada uno de los tipos de
modelos lo obtenemos con el comando \texttt{inla.list.models()}

En particular, si ejecutamos \texttt{names(inla.models()\$likelihood)} obtenemos
todas las distribuciones disponibles para modelizar los datos. La
distribución \texttt{gaussian} identifica la distribución normal que buscamos para resolver nuestro problema. Para obtener información sobre cómo está parametrizada y cuáles son los
hiperparámetros por defecto, basta consultar la documentación \emph{Gaussian} con el comando:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# documentación (parametrización y valores por defecto)}
\FunctionTok{inla.doc}\NormalTok{(}\StringTok{"gaussian"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para ajustar un modelo sencillo en INLA hay que echar mano de la función \texttt{inla}, en la que introducimos en primer lugar la \texttt{formula}, con la relación entre las variables, a continuación el modelo, en el argumento \texttt{family}, y después el banco de datos sobre el que trabajamos. Si no especificamos el argumento \texttt{family}, la función \texttt{inla}interpreta por defecto la opción \texttt{gaussian}, esto es, normalidad para los datos, de modo que podríamos excluir dicha especificación cuando modelizamos datos normales.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Asumiendo datos normales}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{, data)}
\CommentTok{\# equivalente a}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula, data)}
\end{Highlighting}
\end{Shaded}

Adelantamos pues un paso más en nuestro problema, añadiendo la verosimilitud normal y la base de datos. Haciendo acopio de lo que hemos visto antes, bastaría con ejecutar:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ajuste del modelo}
\NormalTok{formula }\OtherTok{=}\NormalTok{ weight }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\SpecialCharTok{+}\NormalTok{ repwt}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{davis)}
\end{Highlighting}
\end{Shaded}

\hypertarget{paruxe1metros-e-hiperparuxe1metros}{%
\section{Parámetros e hiperparámetros}\label{paruxe1metros-e-hiperparuxe1metros}}

Por defecto INLA asume unas distribuciones difusas sobre los efectos latentes \(\theta,\beta\) y la varianza \(\sigma^2\). Veamos cuáles son esas distribuciones, y cómo modificarlas si tenemos información previa.

Pensando en el significado de los parámetros (reconocidos como \emph{hyperpar} o hiperparámetros) que aparecen en la verosimilitud, es lógico asumir, ante ausencia de información:

\begin{itemize}
\tightlist
\item
  para los efectos latentes \(\theta,\beta\) distribuciones normales independientes difusas y centradas en el cero
\item
  para la varianza \(\sigma^2\) es habitual asumir una gamma inversa, también difusa (con media y varianza grandes) si no tenemos información previa.
\end{itemize}

Vamos en primer lugar con el parámetro \(\sigma^2\) en la verosimilitud.

En INLA, en lugar de asignar distribuciones a priori sobre las
varianzas, se hace sobre el logaritmo de las precisiones, para facilitar
el cálculo del máximo de la log-posterior (obtenida de la
log-verosimilitud y la log-prior). Así, asumir una gamma inversa difusa
\(GaI(\alpha,\beta)\) para la varianza es equivalente a una Gamma difusa
\(Ga(\alpha,\beta)\) para la precisión \(\tau=1/\sigma^2\), y una
log-gamma difusa \(Log-Gamma(\alpha,\beta)\) para la log-precisión
\(log(\tau)\).

Por defecto, como ya verificamos en la documentación de la verosimilitud gausiana, (con \texttt{inla.doc("gaussian")}), la distribución a priori por defecto sobre la log-precisión (\(\theta_1\) en la ayuda) es la log-gamma difusa \(LogGa(1,5\cdot 10^{-5})\), lo que da un valor esperado para la precisión \(\tau\) de 20000 y una varianza de \(4\cdot 10^8\).

Para modificar la distribución a priori de un parámetro podemos utilizar cualquiera de las distribuciones que ofrece INLA en su listado \texttt{names(inla.models()\$prior)} (siempre buscando coherencia con la información sobre el parámetro en cuestión).

Para definir una prior para los parámetros o hiperparámetros en INLA hay
que definir los siguientes argumentos:

\begin{itemize}
\tightlist
\item
  prior, el nombre de la distribución a priori (alguna de las opciones de \texttt{names(inla.models()\$prior)})
\item
  param, los valores de los parámetros de la prior
\item
  initial, el valor inicial para el hiperparámetro
\item
  fixed, variable booleana para decir si el hiperparámetro es fijo o aleatorio.
\end{itemize}

La modificación la haremos con el argumento \texttt{control.family=list(hyper=list(...))} en la función \texttt{inla}, al que le proporcionaremos una lista con el nombre de los parámetros (el \emph{short name} con el que los identifica INLA en la documentación), que apunta a una lista con la distribución (\emph{prior}) y los parámetros (\emph{param}) a utilizar.

En nuestro problema, si tenemos información previa sobre la precisión del modelo,
podemos modificarla con la sintaxis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec.info }\OtherTok{=} \FunctionTok{list}\NormalTok{(}\AttributeTok{prior=}\StringTok{"loggamma"}\NormalTok{, }\AttributeTok{param =}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\FloatTok{0.001}\NormalTok{))}
\NormalTok{fit2}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{davis,}
      \AttributeTok{control.family =} \FunctionTok{list}\NormalTok{(}\AttributeTok{hyper =} \FunctionTok{list}\NormalTok{(}\AttributeTok{prec =}\NormalTok{ prec.info)))}
\end{Highlighting}
\end{Shaded}

Si nos conformamos con la previa por defecto de INLA, el modelo que estamos asumiendo en nuestro problema de regresión lineal simple será:

\begin{eqnarray*}
(y_i|\theta,\beta,\sigma^2) &\sim & N(\theta+\beta x_i,\sigma^2), i=1,...,n \\
\tau=1/\sigma^2 & \sim & Ga(1,0.00005)
\end{eqnarray*}

\hypertarget{efectos-fijos}{%
\section{Efectos fijos}\label{efectos-fijos}}

Una variable explicativa entra en el modelo como \textbf{efecto fijo} cuando
se piensa que afecta a todas las observaciones del mismo modo (de un
modo lineal), y que su efecto es de interés primario en el estudio.

En un modelo de regresión lineal todos los efectos latentes, interceptación y coeficientes de covariables, son efectos fijos. Por defecto en INLA y ante ausencia de información, las priors para los efectos fijos, esto es, (\(\theta,\beta\) en nuestro caso), son gausianas centradas en cero y con varianzas grandes. Así la interceptación \(\beta\) tiene una prior gausiana con media y precisión igual a cero (una distribución plana objetiva, que no integra 1), y los coeficientes \(\beta\) también tienen una prior gausiana con media cero y precisión igual a 0.001. Estos valores por defecto se pueden consultar con el comando \texttt{inla.set.control.fixed.default()}, que da la siguiente información:

\begin{itemize}
\tightlist
\item
  \emph{mean=0} y \emph{mean.intercept=0} son las medias de la distribución normal para los coeficientes \(\beta\) y la interceptación \(\theta\) respectivamente
\item
  \emph{prec=0.001} y \emph{prec.intercept=0} son las precisiones respectivas de las normales para \(\beta\) y \(\theta\).
\end{itemize}

Con todo, los parámetros de las priors sobre los efectos fijos se pueden modificar a través del argumento \texttt{control.fixed=list(...)} en la función \texttt{inla}, utilizando siempre los nombres que atribuye INLA a los diferentes parámetros e hiperparámetros (\emph{short name}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ weight }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\SpecialCharTok{+}\NormalTok{ repwt}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{davis,}
         \AttributeTok{control.fixed=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FloatTok{0.0001}\NormalTok{,}\AttributeTok{prec.intercept=}\FloatTok{0.01}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Volvemos sobre nuestro ejemplo, y asumiendo las a priori por defecto de INLA tendremos:
\begin{eqnarray*}
(y_i|\theta,\beta,\sigma^2) & \sim & N(\theta+\beta x_i,\sigma^2), i=1,...,n \\
\theta & \sim & N(0,\infty) \\
\beta & \sim & N(0,1000) \\
\tau=1/\sigma^2 & \sim & Ga(1,0.00005)
\end{eqnarray*}

\hypertarget{resultados}{%
\section{Resultados}\label{resultados}}

Para controlar qué resultados ha de mostrar INLA tras realizar un ajuste, hemos de especificar los ajustes del argumento \texttt{control.results} de la función \texttt{inla}.

Para mostrar una descriptiva de los resultados del ajuste obtenido con \texttt{fit=inla(...)},
utilizamos la sintaxis siguiente:

\begin{itemize}
\tightlist
\item
  \texttt{summary(fit)} proporciona una descriptiva del ajuste
\item
  \texttt{names(fit\$marginals.fixed)} lista los nombres de todos los efectos fijos
\item
  \texttt{fit\$summary.fixed} resume la inferencia posterior sobre los efectos fijos
\item
  \texttt{names(fit\$marginals.hyperpar)} lista los nombres de todos los hiperparámetros
\item
  \texttt{fit\$summary.hyperpar} da un resumen de la inferencia posterior de
  los parámetros e hiperparámetros
\item
  \texttt{fit\$summary.fitted.values} resume la inferencia posterior sobre los valores ajustados
\item
  \texttt{fit\$mlik} da la estimación de la log-verosimilitud marginal, útil para evaluar y comparar modelos.
\end{itemize}

Veamos los resultados para nuestro problema de regresión.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ajuste del modelo }
\NormalTok{formula }\OtherTok{=}\NormalTok{ weight }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\SpecialCharTok{+}\NormalTok{ repwt}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{davis)}
\FunctionTok{summary}\NormalTok{(fit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{}    c("inla.core(formula = formula, family = family, }
\CommentTok{\#\textgreater{}    contrasts = contrasts, ", " data = data, quantiles = }
\CommentTok{\#\textgreater{}    quantiles, E = E, offset = offset, ", " scale = }
\CommentTok{\#\textgreater{}    scale, weights = weights, Ntrials = Ntrials, strata = }
\CommentTok{\#\textgreater{}    strata, ", " lp.scale = lp.scale, link.covariates = }
\CommentTok{\#\textgreater{}    link.covariates, verbose = verbose, ", " lincomb = }
\CommentTok{\#\textgreater{}    lincomb, selection = selection, control.compute = }
\CommentTok{\#\textgreater{}    control.compute, ", " control.predictor = }
\CommentTok{\#\textgreater{}    control.predictor, control.family = control.family, }
\CommentTok{\#\textgreater{}    ", " control.inla = control.inla, control.fixed = }
\CommentTok{\#\textgreater{}    control.fixed, ", " control.mode = control.mode, }
\CommentTok{\#\textgreater{}    control.expert = control.expert, ", " control.hazard }
\CommentTok{\#\textgreater{}    = control.hazard, control.lincomb = control.lincomb, }
\CommentTok{\#\textgreater{}    ", " control.update = control.update, }
\CommentTok{\#\textgreater{}    control.lp.scale = control.lp.scale, ", " }
\CommentTok{\#\textgreater{}    control.pardiso = control.pardiso, only.hyperparam = }
\CommentTok{\#\textgreater{}    only.hyperparam, ", " inla.call = inla.call, inla.arg }
\CommentTok{\#\textgreater{}    = inla.arg, num.threads = num.threads, ", " }
\CommentTok{\#\textgreater{}    blas.num.threads = blas.num.threads, keep = keep, }
\CommentTok{\#\textgreater{}    working.directory = working.directory, ", " silent = }
\CommentTok{\#\textgreater{}    silent, inla.mode = inla.mode, safe = FALSE, debug = }
\CommentTok{\#\textgreater{}    debug, ", " .parent.frame = .parent.frame)") }
\CommentTok{\#\textgreater{} Time used:}
\CommentTok{\#\textgreater{}     Pre = 2.35, Running = 0.512, Post = 0.018, Total = 2.88 }
\CommentTok{\#\textgreater{} Fixed effects:}
\CommentTok{\#\textgreater{}              mean    sd 0.025quant 0.5quant 0.975quant mode}
\CommentTok{\#\textgreater{} (Intercept) 2.734 0.814      1.135    2.734      4.333   NA}
\CommentTok{\#\textgreater{} repwt       0.958 0.012      0.935    0.958      0.982   NA}
\CommentTok{\#\textgreater{}             kld}
\CommentTok{\#\textgreater{} (Intercept)   0}
\CommentTok{\#\textgreater{} repwt         0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model hyperparameters:}
\CommentTok{\#\textgreater{}                                          mean    sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.199 0.021}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.161    0.198}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.242   NA}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Marginal log{-}Likelihood:  {-}426.73 }
\CommentTok{\#\textgreater{}  is computed }
\CommentTok{\#\textgreater{} Posterior summaries for the linear predictor and the fitted values are computed}
\CommentTok{\#\textgreater{} (Posterior marginals needs also \textquotesingle{}control.compute=list(return.marginals.predictor=TRUE)\textquotesingle{})}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{mlik}
\CommentTok{\#\textgreater{}                                            [,1]}
\CommentTok{\#\textgreater{} log marginal{-}likelihood (integration) {-}426.7325}
\CommentTok{\#\textgreater{} log marginal{-}likelihood (Gaussian)    {-}426.7339}
\end{Highlighting}
\end{Shaded}

Obtenemos pues la salida con un descriptivo de la distribución posterior para los efectos fijos interceptación, \(\theta\), y el coeficiente del regresor \texttt{repwt}, \(\beta\), con la media, desviación típica y cuantiles con los que podemos evaluar la región creíble al 95\%.

También muestra a continuación una tabla con los descriptivos de la distribución posterior para la precisión \(\tau=1/\sigma^2\) de los datos.

Si queremos obtener los nombres con los que INLA reconoce los efectos fijos (interceptación y coeficiente del regresor) e hiperparámetros (precisión de los datos), llamamos a

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)}
\CommentTok{\#\textgreater{} [1] "(Intercept)" "repwt"}
\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar)}
\CommentTok{\#\textgreater{} [1] "Precision for the Gaussian observations"}
\end{Highlighting}
\end{Shaded}

Y para describir la marginal posterior sobre cada uno de los datos ajustados:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fitted.values)}
\CommentTok{\#\textgreater{}                          mean        sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} fitted.Predictor.001 76.52862 0.2162777   76.10404 76.52862}
\CommentTok{\#\textgreater{} fitted.Predictor.002 51.61089 0.2441583   51.13157 51.61089}
\CommentTok{\#\textgreater{} fitted.Predictor.003 54.48601 0.2190148   54.05606 54.48601}
\CommentTok{\#\textgreater{} fitted.Predictor.004 69.82000 0.1750418   69.47637 69.82000}
\CommentTok{\#\textgreater{} fitted.Predictor.005 59.27789 0.1856080   58.91351 59.27789}
\CommentTok{\#\textgreater{} fitted.Predictor.006 75.57025 0.2087749   75.16039 75.57025}
\CommentTok{\#\textgreater{}                      0.975quant mode}
\CommentTok{\#\textgreater{} fitted.Predictor.001   76.95321   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.002   52.09021   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.003   54.91597   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.004   70.16364   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.005   59.64226   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.006   75.98011   NA}
\end{Highlighting}
\end{Shaded}

Si queremos hacer un \textbf{análisis de sensibilidad} sobre las distribuciones a priori, reajustamos el modelo con otras priors y comparamos los resultados.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ajuste del modelo }
\NormalTok{formula }\OtherTok{=}\NormalTok{ weight }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\SpecialCharTok{+}\NormalTok{ repwt}
\NormalTok{fit2}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{davis,}
         \AttributeTok{control.fixed =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean.intercept =} \DecValTok{100}\NormalTok{, }
                                 \AttributeTok{prec.intercept =} \DecValTok{10}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{),}
                                 \AttributeTok{mean =} \DecValTok{0}\NormalTok{, }
                                 \AttributeTok{prec =} \DecValTok{1}\NormalTok{), }
            \AttributeTok{control.family =} \FunctionTok{list}\NormalTok{(}\AttributeTok{hyper =} \FunctionTok{list}\NormalTok{(}
              \AttributeTok{prec =} \FunctionTok{list}\NormalTok{(}\AttributeTok{prior=}\StringTok{"loggamma"}\NormalTok{, }\AttributeTok{param =}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\FloatTok{0.001}\NormalTok{)))))}
\NormalTok{fit2}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                  mean         sd 0.025quant  0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 3.3859342 0.81577662  1.7941226 3.3824734}
\CommentTok{\#\textgreater{} repwt       0.9488563 0.01215735  0.9248445 0.9489068}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)  4.9973585   NA 2.204325e{-}09}
\CommentTok{\#\textgreater{} repwt        0.9725817   NA 2.141045e{-}09}
\NormalTok{fit2}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                              mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.1983981}
\CommentTok{\#\textgreater{}                                                 sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.02084352}
\CommentTok{\#\textgreater{}                                         0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.1602208}
\CommentTok{\#\textgreater{}                                          0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.1976839}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.2410992   NA}
\end{Highlighting}
\end{Shaded}

\hypertarget{distribuciones-posteriores}{%
\section{Distribuciones posteriores}\label{distribuciones-posteriores}}

Para obtener la distribución marginal de los valores ajustados y predichos necesitamos incorporar a la función \texttt{inla} el argumento \texttt{control.compute=list(return.marginals.predictor=TRUE)}.

Tras conseguir un ajuste con \texttt{inla}, podemos acceder a todas las distribuciones marginales posteriores y predictivas a través de:

\begin{itemize}
\item
  \texttt{fit\$marginals.fixed} da las distribuciones posteriores marginales de los efectos fijos
\item
  \texttt{fit\$marginals.fixed\$x} da la distribución del efecto fijo \texttt{x} (\texttt{x} el nombre del efecto), y también se puede seleccionar con su ordinal en el conjunto de efectos fijos
  \texttt{fit\$marginals.fixed{[}{[}i{]}{]}}
\item
\begin{verbatim}
`fit.marginals.hyperpar` da las distribuciones posteriores marginales de los parámetros e hiperparámetros
\end{verbatim}
\item
  \texttt{fit\$marginals.fitted.values} da las distribuciones posteriores marginales para los valores ajustados
\end{itemize}

Con estas distribuciones, reconocidas como \texttt{marginal}, podemos hacer cálculos y gráficos de interés a través de estas funciones que operan sobre las distribuciones y que podemos consultar con \texttt{?inla.marginal}:

\begin{itemize}
\tightlist
\item
  \texttt{inla.dmarginal(x,\ marginal,\ ...)} da la densidad en x
\item
  \texttt{inla.pmarginal(q,\ marginal,\ ...)} da las probabilidades o función de distribución
\item
  \texttt{inla.qmarginal(p,\ marginal,...)} da los cuantiles
\item
  \texttt{inla.rmarginal(n,\ marginal)} permite obtener \(n\) simulaciones
\item
  \texttt{inla.hpdmarginal(p,\ marginal,...)} da la región HPD
\item
  \texttt{inla.smarginal(marginal,\ ...)} da un suavizado con splines de la distribución marginal
\item
  \texttt{inla.emarginal(fun,\ marginal,\ ...)} calcula el valor esperado de una función
\item
  \texttt{inla.mmarginal(marginal,...)} calcula la moda posterior
\item
  \texttt{inla.tmarginal(fun,\ marginal,...)} transforma la distribución marginal de una función del parámetro
\item
  \texttt{inla.zmarginal(marginal,...)} calcula descriptivos de la marginal.
\end{itemize}

Veamos algunos ejemplos sobre nuestro problema. Vamos a mostrar a continuación, en un único gráfico, las distribuciones posteriores de los efectos fijos y el parámetro de dispersión de los datos \$\sigma*, con líneas verticales que marquen el valor esperado posterior (en azul) y el HPD95\% en rojo.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library(gridExtra)}
\CommentTok{\# library(ggplot2)}

\NormalTok{g}\OtherTok{=}\FunctionTok{list}\NormalTok{() }\CommentTok{\# lista en que almacenamos los gráficos con d.posteriores}
\CommentTok{\# Efectos fijos}
\NormalTok{names.fixed}\OtherTok{=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)}
\NormalTok{n.fixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(names.fixed)}
\NormalTok{names}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(theta),}\FunctionTok{expression}\NormalTok{(beta))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n.fixed)\{}
\NormalTok{ g[[i]] }\OtherTok{=} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]])) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\NormalTok{names[i],}\AttributeTok{y=}\StringTok{""}\NormalTok{)}\SpecialCharTok{+}
   \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}
\NormalTok{\}}


\CommentTok{\# Parámetros}
\NormalTok{g[[}\DecValTok{3}\NormalTok{]]}\OtherTok{=} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]])) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(tau),}\AttributeTok{y=}\StringTok{""}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]]),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]]),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}

\CommentTok{\# Transformamos la posterior en tau para obtener la posterior de sigma}
\NormalTok{sigma.post}\OtherTok{=}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]])}
\CommentTok{\# y la pintamos}
\NormalTok{g[[}\DecValTok{4}\NormalTok{]]}\OtherTok{=} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(sigma.post)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(sigma),}\AttributeTok{y=}\StringTok{""}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,sigma.post),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,sigma.post),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(gridExtra)}
\FunctionTok{grid.arrange}\NormalTok{(g[[}\DecValTok{1}\NormalTok{]],g[[}\DecValTok{2}\NormalTok{]],g[[}\DecValTok{3}\NormalTok{]],g[[}\DecValTok{4}\NormalTok{]],}\AttributeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{01-regresion_files/figure-latex/unnamed-chunk-14-1.pdf}

\hypertarget{simulaciuxf3n-de-la-posterior}{%
\section{Simulación de la posterior}\label{simulaciuxf3n-de-la-posterior}}

Cuando queremos inferir sobre funciones de los efectos latentes e hiperparámetros que no proporciona por defecto \texttt{INLA}, podemos recurrir a simular de las distribuciones posteriores de los efectos involucrados, y con ellas evaluar la función que nos interesa para conseguir una muestra de su distribución posterior.
Para ello es preciso que al ajustar el modelo con \texttt{inla} hayamos incluido el argumento \texttt{control.compute=list(config=TRUE)}.

Para obtener simulaciones utilizamos las funciones:

\begin{itemize}
\tightlist
\item
  \texttt{inla.posterior.sample(n,\ fit,selection)}, para simular los efectos latentes, donde \(n\) es el número de simulaciones pretendido, \texttt{fit} es el ajuste obtenido con \texttt{inla} y \texttt{selection} es una lista con el nombre de las componentes a simular.\\
\item
  \texttt{inla.hyperpar.sample(n,fit,improve.marginals=TRUE)} para simular de parámetros e hiperparámetros.
\end{itemize}

Para describir las distribuciones de los nuevos parámetros que queremos evaluar con dichas simulaciones, utilizaremos:

\begin{itemize}
\tightlist
\item
  \texttt{inla.posterior.sample()} para funciones sobre los efectos fijos
\item
  \texttt{inla.hyperpar.sample()} para funciones sobre los hiperparámetros
\end{itemize}

Imaginemos que queremos obtener la distribución posterior de \((\theta+\beta)\). Hemos de simular pues, de las distribuciones posteriores de \(\theta\) y de \(\beta\), para luego sumar las simulaciones y obtener una muestra posterior de \(\theta+\beta\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ davis,}
  \AttributeTok{control.compute =} \FunctionTok{list}\NormalTok{(}\AttributeTok{config =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{sims }\OtherTok{=} \FunctionTok{inla.posterior.sample}\NormalTok{(}\DecValTok{100}\NormalTok{, fit, }\AttributeTok{selection =} \FunctionTok{list}\NormalTok{(}\StringTok{"(Intercept)"}\OtherTok{=}\DecValTok{1}\NormalTok{,}\AttributeTok{repwt =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Esto nos devuelve una lista de la dimensión del número de simulaciones, y en cada uno de los elementos tenemos: los valores simulados de los hiperparámetros (\texttt{hyper}), de los efectos latentes (\texttt{latent})

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(sims)}
\CommentTok{\#\textgreater{} [1] 100}
\FunctionTok{names}\NormalTok{(sims[[}\DecValTok{1}\NormalTok{]])}
\CommentTok{\#\textgreater{} [1] "hyperpar" "latent"   "logdens"}
\NormalTok{sims[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{hyperpar}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations }
\CommentTok{\#\textgreater{}                               0.2514044}
\NormalTok{sims[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{latent}
\CommentTok{\#\textgreater{}                sample:1}
\CommentTok{\#\textgreater{} (Intercept):1 2.9201273}
\CommentTok{\#\textgreater{} repwt:1       0.9577521}
\end{Highlighting}
\end{Shaded}

y la log-densidad de la posterior en esos valores (\texttt{logdens})

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ sims[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{logdens}
\CommentTok{\#\textgreater{} $hyperpar}
\CommentTok{\#\textgreater{} [1] 0.1424985}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $latent}
\CommentTok{\#\textgreater{} [1] 1008.068}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $joint}
\CommentTok{\#\textgreater{} [1] 1008.21}
\end{Highlighting}
\end{Shaded}

Ahora con la función \texttt{inla.posterior.sample.eval}, dado que nuestra función depende de efectos fijos (latentes), \(\theta+\beta\), evaluamos dicha suma, aproximamos los descriptivos de la posterior, y la graficamos con un histograma:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta\_beta}\OtherTok{=}\FunctionTok{inla.posterior.sample.eval}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(...) \{(Intercept)}\SpecialCharTok{+}\NormalTok{repwt\},sims)}
\NormalTok{theta\_beta}\OtherTok{=}\FunctionTok{as.vector}\NormalTok{(theta\_beta)}
\FunctionTok{summary}\NormalTok{(theta\_beta)}
\CommentTok{\#\textgreater{}    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. }
\CommentTok{\#\textgreater{}  0.9381  3.2327  3.8525  3.8418  4.4880  5.5453}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{tb=}\NormalTok{theta\_beta),}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{tb))}\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{stat=}\StringTok{"density"}\NormalTok{)}
\CommentTok{\#\textgreater{} Warning: Ignoring unknown parameters: binwidth, bins, pad}
\end{Highlighting}
\end{Shaded}

\includegraphics{01-regresion_files/figure-latex/unnamed-chunk-18-1.pdf}

\hypertarget{regresiuxf3n-lineal-muxfaltiple-con-inla}{%
\section{Regresión lineal múltiple con INLA}\label{regresiuxf3n-lineal-muxfaltiple-con-inla}}

Vemos a continuación cómo se trabaja la regresión múltiple con INLA, simplemente añadiendo más predictores.

El modelo de regresión asume una distribución normal para los datos, datos los efectos latentes (todos los relacionados con el valor esperado o predictor lineal) y el resto de parámetros o hiperparámetros del modelo (en nuestro caso la varianza de los datos).

Si tenemos \(n\) observaciones
\[ (y_i|\mu_i,\sigma^2) \sim N(\mu_i,\sigma^2), \ \ i=1,...n\]
donde \(\mu_i\) representa la media y \(\sigma^2\) la varianza de los datos.
\[E(y_i|\mu_i,\sigma^2)=\mu_i, \ Var(y_i|\mu_i,\sigma^2)=\sigma^2\]
Si tenemos varios regresores \(x_1,x_2,...,x_J\), la media \(\mu_i\) se relaciona linealmente con un predictor lineal \(\eta_i\) que se construye a partir de una combinación lineal de los predictores:
\[\eta_i=\theta+ \sum_{j=1}^J \beta_j x_{ij}\]
En el modelo de regresión la media de los datos \(\mu\) coincide con el predictor lineal \(\eta\), \(\mu_i=\eta_i, i=1,...,n\).

Nos queda a continuación especificar las distribuciones a priori sobre el vector de efectos latentes, en nuestro caso efectos fijos, \((\theta,\beta_1,...,\beta_J)\), y sobre el parámetro de dispersión o hiperparámetro \(\sigma^2\).

Cuando no tenemos información previa especificamos distribuciones difusas (vagas) sobre los parámetros. En INLA por defecto tendremos:

\begin{eqnarray*}
\theta &\sim& N(0,\sigma_{\theta}^2)  \\
\beta_j &\sim& N(0,\sigma_{\beta}^2) \\
log(\tau=1/\sigma^2) &\sim& Log-Ga(1,0.00005)
\end{eqnarray*}
con \(\sigma_{theta}^2=\infty\) y \(\sigma_{\beta}=1000\).

Ejemplificamos el análisis de regresión lineal múltiple sobre la base de datos \texttt{usair}, en la librería \texttt{brinla}. Esta BD contiene datos recopilados para investigar los factores determinantes de la polución, utilizando el nivel de SO2 como variable dependiente y las restantes como variables explicativas potenciales. Las relaciones entre las variables que incluye se muestra en la Figura \ref{fig:regmul01} a continuación.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(usair, }\AttributeTok{package =} \StringTok{"brinla"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(GGally)}
\NormalTok{pairs.chart }\OtherTok{\textless{}{-}} \FunctionTok{ggpairs}\NormalTok{(usair, }\AttributeTok{lower =} \FunctionTok{list}\NormalTok{(}\AttributeTok{continuous =} \StringTok{"cor"}\NormalTok{), }
                       \AttributeTok{upper =} \FunctionTok{list}\NormalTok{(}\AttributeTok{continuous =} \StringTok{"points"}\NormalTok{, }\AttributeTok{combo =} \StringTok{"dot"}\NormalTok{))}
\NormalTok{ggplot2}\SpecialCharTok{::}\FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{6}\NormalTok{)) }
\CommentTok{\#\textgreater{} List of 1}
\CommentTok{\#\textgreater{}  $ axis.text:List of 11}
\CommentTok{\#\textgreater{}   ..$ family       : NULL}
\CommentTok{\#\textgreater{}   ..$ face         : NULL}
\CommentTok{\#\textgreater{}   ..$ colour       : NULL}
\CommentTok{\#\textgreater{}   ..$ size         : num 6}
\CommentTok{\#\textgreater{}   ..$ hjust        : NULL}
\CommentTok{\#\textgreater{}   ..$ vjust        : NULL}
\CommentTok{\#\textgreater{}   ..$ angle        : NULL}
\CommentTok{\#\textgreater{}   ..$ lineheight   : NULL}
\CommentTok{\#\textgreater{}   ..$ margin       : NULL}
\CommentTok{\#\textgreater{}   ..$ debug        : NULL}
\CommentTok{\#\textgreater{}   ..$ inherit.blank: logi FALSE}
\CommentTok{\#\textgreater{}   ..{-} attr(*, "class")= chr [1:2] "element\_text" "element"}
\CommentTok{\#\textgreater{}  {-} attr(*, "class")= chr [1:2] "theme" "gg"}
\CommentTok{\#\textgreater{}  {-} attr(*, "complete")= logi FALSE}
\CommentTok{\#\textgreater{}  {-} attr(*, "validate")= logi TRUE}
\NormalTok{pairs.chart}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{01-regresion_files/figure-latex/regmul01-1.pdf}
\caption{\label{fig:regmul01}Relaciones entre variables en la base de datos usair(brinla).}
\end{figure}

Apreciamos ya en el gráfico una correlación positiva muy alta entre las variables \texttt{pop} y \texttt{manuf}, y relevante para \texttt{negtemp} y \texttt{days} y también para \texttt{precip} y \texttt{days}, lo que posteriormente condicionará la selección de variables.

Cuando trabajamos con más de una variable predictora en regresión lineal (realmente en cualquier modelo) surge un problema adicional, que es la \textbf{selección de variables}, o selección del mejor modelo de predicción. Esto se resuelve en INLA utilizando diversos criterios de selección entre los que destacamos:

\begin{itemize}
\tightlist
\item
  la verosimilitud marginal (valor de la log-verosimilitud): \texttt{mlik}; al cambiarle el signo tendremos \(-loglikelihood\)
\item
  el criterio de información de la deviance (DIC): \texttt{dic}
\item
  el criterio de información bayesiana ampliado (WAIC): \texttt{waic}.
\end{itemize}

El procedimiento a utilizar para la selección del modelo (de variables) es el siguiente:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ajustar todos los modelos resultantes de todas las combinaciones posibles de predictoras,
\item
  calcular los índices de selección para cada uno de ellos
\item
  proceder con la selección en base a dichos valores.
\end{enumerate}

Siempre se prefieren modelos con los valores más bajos para estos criterios y se descartan los que proporcionan valores más altos. Cuando no es el mismo modelo el que proporciona el valor mínimo en estos criterios, habremos de optar por alguno de ellos.

Por defecto, al ajustar un modelo con \texttt{inla}, nos devuelve la log-verosimilitud (accesible con \texttt{fit\$mlik} si el ajuste se guardó en el objeto \texttt{fit}). Para obtener las otras medidas de selección, hemos de incluir como argumento de la función \texttt{inla}, la opción \texttt{control.compute\ =\ list(dic\ =\ TRUE,\ waic\ =\ TRUE))}. Los valores por defecto de \texttt{control.compute} los podemos consultar ejecutando el comando \texttt{inla.set.control.compute.default()}.

Vayamos pues con el ajuste del modelo de regresión con todas las variables. Recordemos que si no especificamos el argumento \texttt{family}, interpreta por defecto la opción \texttt{gaussian}, esto es, normalidad para los datos. Así ajustamos el modelo y obtenemos las siguientes inferencias sobre los efectos fijos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{\textless{}{-}}\NormalTok{  SO2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ negtemp }\SpecialCharTok{+}\NormalTok{ manuf }\SpecialCharTok{+}\NormalTok{ wind }\SpecialCharTok{+}\NormalTok{ precip }\SpecialCharTok{+}\NormalTok{ days}
\NormalTok{fit}\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ usair, }\AttributeTok{control.compute =} \FunctionTok{list}\NormalTok{(}\AttributeTok{dic =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic =} \ConstantTok{TRUE}\NormalTok{))}
\CommentTok{\#summary(fit)}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                mean     sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 135.490 49.850     37.178  135.497    233.760}
\CommentTok{\#\textgreater{} negtemp       1.769  0.634      0.518    1.769      3.019}
\CommentTok{\#\textgreater{} manuf         0.026  0.005      0.017    0.026      0.035}
\CommentTok{\#\textgreater{} wind         {-}3.723  1.934     {-}7.536   {-}3.723      0.092}
\CommentTok{\#\textgreater{} precip        0.625  0.387     {-}0.139    0.625      1.388}
\CommentTok{\#\textgreater{} days         {-}0.057  0.174     {-}0.400   {-}0.057      0.287}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} negtemp       NA   0}
\CommentTok{\#\textgreater{} manuf         NA   0}
\CommentTok{\#\textgreater{} wind          NA   0}
\CommentTok{\#\textgreater{} precip        NA   0}
\CommentTok{\#\textgreater{} days          NA   0}
\end{Highlighting}
\end{Shaded}

La inferencia posterior sobre la desviación típica de los datos, \(\sigma\), la resolvemos con sus descriptivos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma.post}\OtherTok{=} \FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{                           fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]])}
\FunctionTok{inla.zmarginal}\NormalTok{(sigma.post)}
\CommentTok{\#\textgreater{} Mean            15.6706 }
\CommentTok{\#\textgreater{} Stdev           1.85534 }
\CommentTok{\#\textgreater{} Quantile  0.025 12.5293 }
\CommentTok{\#\textgreater{} Quantile  0.25  14.347 }
\CommentTok{\#\textgreater{} Quantile  0.5   15.4919 }
\CommentTok{\#\textgreater{} Quantile  0.75  16.7975 }
\CommentTok{\#\textgreater{} Quantile  0.975 19.817}
\end{Highlighting}
\end{Shaded}

Para seleccionar las variables relevantes seguimos el procedimiento descrito anteriormente. Añadimos también el ajuste del modelo de regresión frecuentista, para el que calculamos como criterio de bondad de ajuste el AIC.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# variables en la bd}
\NormalTok{vars}\OtherTok{=}\FunctionTok{names}\NormalTok{(usair)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{] }\CommentTok{\# variables predictoras (excluye v.dpte)}
\NormalTok{nvars}\OtherTok{=}\FunctionTok{length}\NormalTok{(vars) }\CommentTok{\# nº variables predictoras}
\CommentTok{\# Selección de variables. truco para concatenar todos los modelos posibles en una fórmula}
\NormalTok{listcombo }\OtherTok{\textless{}{-}} \FunctionTok{unlist}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nvars,}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{combn}\NormalTok{(nvars, x, }\AttributeTok{simplify=}\ConstantTok{FALSE}\NormalTok{)),}\AttributeTok{recursive=}\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{predterms }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(listcombo, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{paste}\NormalTok{(vars[x],}\AttributeTok{collapse=}\StringTok{"+"}\NormalTok{))}
\NormalTok{nmodels }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(listcombo)}
\NormalTok{coefm }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\FunctionTok{length}\NormalTok{(listcombo),}\DecValTok{4}\NormalTok{,}\AttributeTok{dimnames=}\FunctionTok{list}\NormalTok{(predterms,}\FunctionTok{c}\NormalTok{(}\StringTok{"AIC"}\NormalTok{,}\StringTok{"DIC"}\NormalTok{,}\StringTok{"WAIC"}\NormalTok{,}\StringTok{"MLIK"}\NormalTok{)))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nmodels)\{}
\NormalTok{  formula }\OtherTok{\textless{}{-}} \FunctionTok{as.formula}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"SO2 \textasciitilde{} "}\NormalTok{,predterms[[i]]))}
  \CommentTok{\# modelo frecuentista}
\NormalTok{  lmi }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(formula, }\AttributeTok{data=}\NormalTok{usair)}
  \CommentTok{\# modelo bayesiano}
\NormalTok{  result }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data=}\NormalTok{usair, }\AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{dic=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic=}\ConstantTok{TRUE}\NormalTok{))}
\NormalTok{  coefm[i,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{AIC}\NormalTok{(lmi)}
\NormalTok{  coefm[i,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ result}\SpecialCharTok{$}\NormalTok{dic}\SpecialCharTok{$}\NormalTok{dic}
\NormalTok{  coefm[i,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ result}\SpecialCharTok{$}\NormalTok{waic}\SpecialCharTok{$}\NormalTok{waic}
\NormalTok{  coefm[i,}\DecValTok{4}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{result}\SpecialCharTok{$}\NormalTok{mlik[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Ya solo resta comparar los resultados, respecto de cada uno de los criterios, para seleccionar con qué variables nos quedamos, y por lo tanto con qué modelo de predicción. Basta con encontrar el modelo que proporciona el mínimo valor en cada uno de los criterios.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gana.aic }\OtherTok{=}\NormalTok{ predterms[}\FunctionTok{which.min}\NormalTok{(coefm[,}\DecValTok{1}\NormalTok{])]}
\NormalTok{gana.dic }\OtherTok{=}\NormalTok{ predterms[}\FunctionTok{which.min}\NormalTok{(coefm[,}\DecValTok{2}\NormalTok{])]}
\NormalTok{gana.waic }\OtherTok{=}\NormalTok{ predterms[}\FunctionTok{which.min}\NormalTok{(coefm[,}\DecValTok{3}\NormalTok{])]}
\NormalTok{gana.mlik }\OtherTok{=}\NormalTok{ predterms[}\FunctionTok{which.min}\NormalTok{(coefm[,}\DecValTok{4}\NormalTok{])]}
\NormalTok{gana.aic;gana.dic}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] "negtemp+manuf+pop+wind+precip"}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] "negtemp+manuf+pop+wind+precip"}
\NormalTok{gana.waic;gana.mlik}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] "negtemp+manuf+pop+wind+precip"}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] "manuf"}
\end{Highlighting}
\end{Shaded}

Concluimos pues que, tanto el criterio AIC en el modelo de regresión frecuentista, como los criterios DIC y WAIC en el modelo de regresión bayesiano, proporcionan el mejor ajuste. Este mejor modelo incluye como predictores las variables `negtemp+manuf+pop+wind+precip'. Reajustamos el modelo con estas variables para derivar las inferencias y predicciones.

Las inferencias sobre los efectos fijos y la precisión de los datos se muestran a continuación.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{SO2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ negtemp}\SpecialCharTok{+}\NormalTok{manuf}\SpecialCharTok{+}\NormalTok{pop}\SpecialCharTok{+}\NormalTok{wind}\SpecialCharTok{+}\NormalTok{precip}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data=}\NormalTok{usair, }\AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{dic=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic=}\ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                     mean          sd   0.025quant}
\CommentTok{\#\textgreater{} (Intercept) 100.01549484 30.15083880 40.555055784}
\CommentTok{\#\textgreater{} negtemp       1.12026612  0.41444673  0.302988558}
\CommentTok{\#\textgreater{} manuf         0.06489651  0.01549632  0.034341608}
\CommentTok{\#\textgreater{} pop          {-}0.03934787  0.01488967 {-}0.068708294}
\CommentTok{\#\textgreater{} wind         {-}3.07258456  1.75727508 {-}6.536740141}
\CommentTok{\#\textgreater{} precip        0.41922295  0.21555728 {-}0.005830357}
\CommentTok{\#\textgreater{}                 0.5quant    0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept) 100.01906558 159.455494342   NA 1.152499e{-}08}
\CommentTok{\#\textgreater{} negtemp       1.12029301   1.937389819   NA 1.155082e{-}08}
\CommentTok{\#\textgreater{} manuf         0.06489625   0.095452868   NA 1.156335e{-}08}
\CommentTok{\#\textgreater{} pop          {-}0.03934751  {-}0.009989461   NA 1.156286e{-}08}
\CommentTok{\#\textgreater{} wind         {-}3.07283892   0.393027080   NA 1.150245e{-}08}
\CommentTok{\#\textgreater{} precip        0.41922935   0.844239641   NA 1.156060e{-}08}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                                mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.005073499}
\CommentTok{\#\textgreater{}                                                  sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.001196977}
\CommentTok{\#\textgreater{}                                          0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.003032416}
\CommentTok{\#\textgreater{}                                            0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.004968958}
\CommentTok{\#\textgreater{}                                          0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.007512641   NA}
\end{Highlighting}
\end{Shaded}

Y en la Figura \ref{fig:regmul02} se muestran las distribuciones posteriores de todos los efectos latentes (efectos fijos) en el modelo: interceptación y coeficientes de los regresores.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nfixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{names.fixed)}
\NormalTok{g}\OtherTok{=}\FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nfixed)\{}
\NormalTok{  g[[i]]}\OtherTok{=}\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]])) }\SpecialCharTok{+} 
    \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{names.fixed[i],}\AttributeTok{y=}\StringTok{""}\NormalTok{)}\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]),}
               \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]),}
               \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}
\NormalTok{\}}
\FunctionTok{grid.arrange}\NormalTok{(g[[}\DecValTok{1}\NormalTok{]],g[[}\DecValTok{2}\NormalTok{]],g[[}\DecValTok{3}\NormalTok{]],g[[}\DecValTok{4}\NormalTok{]],g[[}\DecValTok{5}\NormalTok{]],g[[}\DecValTok{6}\NormalTok{]],}\AttributeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{01-regresion_files/figure-latex/regmul02-1.pdf}
\caption{\label{fig:regmul02}Distribuciones posteriores de los efectos latentes.}
\end{figure}

Por último, si queremos predecir nuevas observaciones con la \textbf{distribución predictiva a posteriori}, y ciertos valores de las variables explicativas, utilizamos el argumento \texttt{control.predictor}en la función \texttt{inla}, especificando en una lista los valores a predecir. Veamos cómo hacerlo con \texttt{inla}, ajustando un modelo sobre un \texttt{data.frame} combinado, en el que añadimos tantas filas como predicciones queremos conseguir, con los valores deseados para los predictores (y valores faltantes en la respuesta), y especificamos los valores a predecir en un vector indicador, a través del argumento \texttt{control.predictor(list(link=vector.indicador))}. Las predicciones se obtienen después, con el resumen de los datos ajustados \texttt{fitted.values}. Recordemos que para poder mostrar las distribuciones predictivas, hemos de añadir en \texttt{inla} el argumento \texttt{control.compute=list(return.marginals.predictor=TRUE)}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Predicción con INLA}
\DocumentationTok{\#\# valores de los predictores en los que predecir: 3 escenarios}
\NormalTok{formula}\OtherTok{=}\NormalTok{SO2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ negtemp}\SpecialCharTok{+}\NormalTok{manuf}\SpecialCharTok{+}\NormalTok{pop}\SpecialCharTok{+}\NormalTok{wind}\SpecialCharTok{+}\NormalTok{precip}
\NormalTok{new.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{negtemp =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{50}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{60}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{40}\NormalTok{), }
                       \AttributeTok{manuf =} \FunctionTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{400}\NormalTok{), }
                       \AttributeTok{pop =} \FunctionTok{c}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{300}\NormalTok{), }
                       \AttributeTok{wind =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{), }
                       \AttributeTok{precip =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{20}\NormalTok{),}
                       \AttributeTok{days=}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{))}

\DocumentationTok{\#\# añadimos los tres escenarios de predicción a la bd original, }
\DocumentationTok{\#\# dejando como faltantes los valores a predecir de la v.dpte}
\NormalTok{usair.combinado }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(usair, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{SO2=}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{),new.data))}
\DocumentationTok{\#\# creamos un vector con NA\textquotesingle{}s para observaciones y 1\textquotesingle{}s para predicciones}
\NormalTok{usair.indicador }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(usair)), }\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(new.data)))}
\DocumentationTok{\#\# reajustamos el modelo añadiendo la opción de predicción de datos}
\NormalTok{fit.pred }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ usair.combinado, }
                 \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{),}
                 \AttributeTok{control.predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{link =}\NormalTok{ usair.indicador))}
\DocumentationTok{\#\# y describimos los valores ajustados para los tres escenarios añadidos}
\NormalTok{fit.pred}\SpecialCharTok{$}\NormalTok{summary.fitted.values[(}\FunctionTok{nrow}\NormalTok{(usair)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(usair.combinado),]}
\CommentTok{\#\textgreater{}                         mean       sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} fitted.Predictor.42 31.62397 8.209857   15.43620 31.62473}
\CommentTok{\#\textgreater{} fitted.Predictor.43 26.42298 5.477699   15.62271 26.42334}
\CommentTok{\#\textgreater{} fitted.Predictor.44 53.16307 7.096415   39.17095 53.16362}
\CommentTok{\#\textgreater{}                     0.975quant mode}
\CommentTok{\#\textgreater{} fitted.Predictor.42   47.80712   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.43   37.22103   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.44   67.15178   NA}
\end{Highlighting}
\end{Shaded}

Así graficamos en la Figura \ref{fig:regmul03} la distribución predictiva del nivel de SO2 para una combinación dada de valores de las variables predictivas, negtem=-50, manuf=150, pop=200, wind=6 y precip=10.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred}\OtherTok{=}\NormalTok{fit.pred}\SpecialCharTok{$}\NormalTok{marginals.fitted.values[[}\DecValTok{42}\NormalTok{]]}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(pred)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(eta),}\AttributeTok{y=}\StringTok{""}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,pred),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,pred),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{01-regresion_files/figure-latex/regmul03-1.pdf}
\caption{\label{fig:regmul03}Distribución predictiva a posteriori de SO2 para una configuración dada de los predictores.}
\end{figure}

\hypertarget{conclusiones}{%
\section{Conclusiones}\label{conclusiones}}

En este tema hemos trabajado con el ajuste con INLA de modelos lineales de regresión, esto es, con efectos fijos. En posteriores temas trabajaremos modelos más sofisticados en los que incluiremos los efectos aleatorios, generalizaremos el modelo lineal y entenderemos el planteamiento de modelos a través de modelos jerárquicos bayesianos.

\hypertarget{anova}{%
\chapter{Modelo de ANOVA}\label{anova}}

\hypertarget{introducciuxf3n-1}{%
\section{Introducción}\label{introducciuxf3n-1}}

El modelo de ANOVA se plantea para comparar poblaciones normales, especialmente cuando son más de dos las poblaciones a comparar. Las poblaciones a comparar se identifican a través de una variable clasificadora (de tipo categórico) que actúa como predictora para estimar respuestas medias supuestamente distintas a comparar.

\hypertarget{el-modelo-de-anova}{%
\section{El modelo de ANOVA}\label{el-modelo-de-anova}}

Consideremos una variable respuesta \(Y\) que se distribuye normal, y que viene afectada por una variable de clasificación \(A\) con \(a\) niveles de respuesta distintos (uno por cada una de las poblaciones a comparar). Supongamos que tenemos \(n_i\) observaciones de la respuesta para cada uno de los niveles de respuesta de la variable clasificadora, \(i=1,...,a\). El modelo de ANOVA se plantea asumiendo que en cada nivel o subpoblación, esperamos una valor distinto para la respuesta,
\[(y_{ij}|\mu_i,\sigma^2) \sim N(\mu_i,\sigma^2)\]
de modo que
\[E(y_{ij}|\mu_i,\sigma^2)=\mu_i; \ Var(y_{ij}|\mu_i,\sigma^2)=\sigma^2, \ \ i=1,...,a; \ j=1,...,n_i\]
La formulación habitual de este modelo se suele dar en términos de un efecto global y común a todas las observaciones, \(\theta\), y un efecto diferencial respecto del primer nivel del factor de clasificación \(A\), \(\alpha_i\), con los que se construye la media (identificada generalmente por \(\mu\)) o predictor lineal (identificada generalmente por \(\eta\)) y que en el modelo lineal coinciden:
\[\mu_{ij}=\eta_{ij}=\theta + \alpha_i\]
donde \(\alpha_i=E(y_{ij}|\mu,\sigma^2)-E(y_{1j}|\mu,\sigma^2), i\geq 1\), esto es, \(\alpha=1=0\).

En la modelización bayesiana es preciso añadir distribuciones a priori para cada uno de los parámetros del modelo: los efectos fijos \(\theta,\alpha_i\), y la varianza \(\sigma^2\) de los datos. Ante ausencia de información, se asumirán distribuciones difusas:

\begin{eqnarray*}
(Y_{ij}|\mu_i,\sigma^2) & \sim & N(\mu_i,\sigma^2) \\
&& \mu_i = \theta + \alpha_i, i=1,...,a \\
\theta & \sim & N(0,\sigma_{\theta}^2), \ \sigma_{\theta}^2=0 \\
\alpha_i & \sim & N(0,1000), i\geq 1\\
\tau=1/\sigma^2 & \sim & Ga(1,0.00005)
\end{eqnarray*}

\hypertarget{anova-de-una-vuxeda}{%
\section{Anova de una vía}\label{anova-de-una-vuxeda}}

Vamos a ilustrar el análisis ANOVA en INLA a través de la base de datos \texttt{coagulation}, en la librería \href{https://cran.r-project.org/web/packages/faraway/faraway.pdf}{\texttt{faraway}}, referidos a un estudio de tiempos de coagulación de la sangre en 24 animales a los que aleatoriamente se les asignó una de entre tres dietas distintas (variable clasificadora \texttt{diet}). Posteriormente, para estudiar el efecto de dichas dietas en la coagulación, se tomaron muestras de los tiempos de coagulación (en la variable \texttt{coag}, que es la respuesta).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(coagulation, }\AttributeTok{package=}\StringTok{"faraway"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(coagulation)}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    24 obs. of  2 variables:}
\CommentTok{\#\textgreater{}  $ coag: num  62 60 63 59 63 67 71 64 65 66 ...}
\CommentTok{\#\textgreater{}  $ diet: Factor w/ 4 levels "A","B","C","D": 1 1 1 1 2 2 2 2 2 2 ...}
\FunctionTok{ggplot}\NormalTok{(coagulation,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{diet,}\AttributeTok{y=}\NormalTok{coag))}\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/unnamed-chunk-2-1.pdf}

Estamos planteando un modelo de Anova como el propuesto en la sección anterior, donde \(\alpha_i\) identifica el efecto diferencial sobre la respuesta con la dieta A, para el resto de las dietas B y C. Los parámetros del modelo son, como en regresión, los efectos fijos \((\theta,\alpha_i)\) y la varianza \(\sigma^2\), para los que asumimos las priors difusas que por defecto propone INLA. Ajustamos el modelo y obtenemos las inferencias a posteriori

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{coag }\SpecialCharTok{\textasciitilde{}}\NormalTok{ diet}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{coagulation,}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fijos}\OtherTok{=}\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{);fijos}
\CommentTok{\#\textgreater{}               mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 61.016 1.173     58.698   61.016     63.339}
\CommentTok{\#\textgreater{} dietB        4.979 1.514      1.980    4.980      7.973}
\CommentTok{\#\textgreater{} dietC        6.977 1.514      3.978    6.978      9.971}
\CommentTok{\#\textgreater{} dietD       {-}0.016 1.437     {-}2.861   {-}0.016      2.824}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} dietB         NA   0}
\CommentTok{\#\textgreater{} dietC         NA   0}
\CommentTok{\#\textgreater{} dietD         NA   0}
\NormalTok{tau}\OtherTok{=}\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar,}\DecValTok{3}\NormalTok{);tau}
\CommentTok{\#\textgreater{}                                          mean   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.197 0.06}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.099     0.19}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.323   NA}
\NormalTok{medias}\OtherTok{=}\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.linear.predictor,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Atendiendo a los descriptivos de la distribución posterior para los efectos fijos, concluimos:

\begin{itemize}
\tightlist
\item
  El tiempo esperado de coagulación para los animales que han seguido la dieta A es de 61.016(58.698,63.339).
\item
  Los animales que han seguido la dieta B tienen un tiempo de coagulación esperado superior en 4.979 unidades a los de la dieta A, y dicha diferencia es \emph{significativamente distinta de cero} en el contexto bayesiano, dado que su HPD no incluye al cero, (1.98,7.973).
\item
  Una conclusión similar se deriva para la dieta C, que da un tiempo de coagulación esperado superior en 6.977 unidades a los de la dieta A, y un HPD (3.978,9.971).
\item
  Las diferencias en los tiempos de coagulación de seguir una dieta D frente a la dieta A no son relevantes. De hecho, la diferencia entre ellos es de -0.016 y el intervalo HPD contiene al cero, (-2.861,2.824).
\end{itemize}

Pintamos a continuación en la Figura \ref{fig:anova01} la distribución posterior de las medias \(\mu_i\) (o predictores lineales) para cada una de las dietas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dietas}\OtherTok{=}\FunctionTok{levels}\NormalTok{(coagulation}\SpecialCharTok{$}\NormalTok{diet)}
\NormalTok{pred}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(dietas))\{}
\NormalTok{index}\OtherTok{=}\FunctionTok{which}\NormalTok{(coagulation}\SpecialCharTok{$}\NormalTok{diet}\SpecialCharTok{==}\NormalTok{dietas[i])[}\DecValTok{1}\NormalTok{]}
\CommentTok{\# distrib. posterior}
\NormalTok{post}\OtherTok{=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{marginals.fitted.values[[index]]}
\CommentTok{\# media}
\NormalTok{e}\OtherTok{=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fitted.values[index,}\DecValTok{1}\NormalTok{]}
\NormalTok{hpd.low}\OtherTok{=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fitted.values[index,}\DecValTok{3}\NormalTok{]}
\NormalTok{hpd.up}\OtherTok{=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fitted.values[index,}\DecValTok{5}\NormalTok{]}
\NormalTok{pred}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(pred,}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{dieta=}\NormalTok{dietas[i],}
\NormalTok{                           post,}\AttributeTok{e=}\NormalTok{e,}
                           \AttributeTok{hpd.low=}\NormalTok{hpd.low,}\AttributeTok{hpd.up=}\NormalTok{hpd.up))}
\NormalTok{\}}

\FunctionTok{ggplot}\NormalTok{(pred, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{y)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{dieta))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Tiempo medio de coagulación:"}\NormalTok{,mu)),}
       \AttributeTok{y=}\StringTok{"D.Posterior"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/anova01-1.pdf}
\caption{\label{fig:anova01}Distribución posterior del tiempo medio de coagulación para las 4 dietas.}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(pred, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{y)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{dieta))}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{e,}\AttributeTok{color=}\NormalTok{dieta),}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{hpd.low,}\AttributeTok{color=}\NormalTok{dieta),}\AttributeTok{linetype=}\StringTok{"dotted"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{hpd.up,}\AttributeTok{color=}\NormalTok{dieta),}\AttributeTok{linetype=}\StringTok{"dotted"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(dieta))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Tiempo medio de coagulación:"}\NormalTok{,mu)),}
       \AttributeTok{y=}\StringTok{"D.Posterior"}\NormalTok{,}\AttributeTok{title=}\StringTok{"D.Posterior, medias y HPD95\%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/anova02-1.pdf}
\caption{\label{fig:anova02}Distribuciones posteriores, medias y HPD}
\end{figure}

Como ya hacíamos en regresión, podemos inferir sobre la desviación típica de los datos, \(\sigma\), transformando la distribución para la precisión \(\tau\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma.post}\OtherTok{=}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]])}
\CommentTok{\# y la pintamos}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(sigma.post)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(sigma),}\AttributeTok{y=}\StringTok{"D.Posterior"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,sigma.post),}
             \AttributeTok{linetype=}\StringTok{"dotted"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) x,sigma.post),}
             \AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Valor esperado}
\NormalTok{sigma.e}\OtherTok{=}\FunctionTok{round}\NormalTok{(}\FunctionTok{inla.emarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]]),}\DecValTok{4}\NormalTok{)}
\CommentTok{\# HPD95\%}
\NormalTok{sigma.hpd}\OtherTok{=}\FunctionTok{round}\NormalTok{(}\FunctionTok{inla.hpdmarginal}\NormalTok{(}\FloatTok{0.95}\NormalTok{,sigma.post),}\DecValTok{3}\NormalTok{)}
\FunctionTok{paste}\NormalTok{(}\StringTok{"E(sigma.post)="}\NormalTok{,sigma.e,}\StringTok{"HPD95\%=("}\NormalTok{,sigma.hpd[}\DecValTok{1}\NormalTok{],}\StringTok{","}\NormalTok{,sigma.hpd[}\DecValTok{2}\NormalTok{],}\StringTok{")"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] "E(sigma.post)= 2.3368 HPD95\%=( 1.687 , 3.064 )"}
\end{Highlighting}
\end{Shaded}

\hypertarget{anova-de-varias-vuxedas}{%
\section{Anova de varias vías}\label{anova-de-varias-vuxedas}}

Generalmente, y en especial cuando trabajamos con experimentación, son varios los factores que controlamos para investigar el efecto que producen en una respuesta continua. Hablamos de modelos de Anova de varias vías.

Utilizamos la base de datos \texttt{butterfat} en la librería \href{https://cran.r-project.org/web/packages/faraway/faraway.pdf}{\texttt{faraway}} para ilustrar el ajuste con INLA de un modelo de Anova de varias vías. Esta base de datos contiene 100 registros del contenido en grasa láctea, \texttt{Butterfat}, para muestras aleatorias de 20 vacas (10 de ellas de 2 años y 10 maduras, con más de 4 años -en la variable \texttt{Age}) de cada una de cinco razas (en la variable \texttt{Breed}).

El objetivo es investigar las diferencias en materia grasa entre razas y edad, con el fin último de identificar cuáles producen más materia grasa y cuáles menos. Veamos los datos en la Figura \ref{fig:butterfat1}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(butterfat,}\AttributeTok{package=}\StringTok{"faraway"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(butterfat)}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    100 obs. of  3 variables:}
\CommentTok{\#\textgreater{}  $ Butterfat: num  3.74 4.01 3.77 3.78 4.1 4.06 4.27 3.94 4.11 4.25 ...}
\CommentTok{\#\textgreater{}  $ Breed    : Factor w/ 5 levels "Ayrshire","Canadian",..: 1 1 1 1 1 1 1 1 1 1 ...}
\CommentTok{\#\textgreater{}  $ Age      : Factor w/ 2 levels "2year","Mature": 2 1 2 1 2 1 2 1 2 1 ...}
\FunctionTok{ggplot}\NormalTok{(butterfat,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Breed,}\AttributeTok{y=}\NormalTok{Butterfat))}\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{Age))}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/butterfat1-1.pdf}
\caption{\label{fig:butterfat1}Base de datos butterfat, en la librería Faraway}
\end{figure}

A la vista del gráfico, apreciamos que por lo general, en la mayoría de las razas, las vacas más jóvenes tienen menor contenido en materia grasa que las más viejas. Sin embargo, tal afirmación no parece tan clara en las razas \emph{Guernsey} y \emph{Holstein-Fresian}, de modo que para modelizar nuestros datos vamos a considerar a priori, la posibilidad de interacciones entre los factores de clasificación \texttt{Breed} y \texttt{Age}.

Cuando nos enfrentamos a varios factores de clasificación, cabe la posibilidad de que interaccionen entre ellos, esto es, que en algunos niveles de un factor actúen de forma diferente a los otros cuando se combinan con los niveles de algún otro factor. El orden de una interacción viene dado por el número de factores de clasificación que involucra, de modo que hablamos de interacciones de orden 2 si consideramos la interacción entre dos factores, de orden 3 si consideramos la interacción entre tres factores, etc. Generalmente trabajamos con interacciones de orden bajo, dada la complejidad de las conclusiones en interacciones de orden alto. Por otro lado, siempre es importante tener en cuenta de cuántos datos disponemos para conocer a priori la posibilidad de estimar con fiabilidad los distintos efectos de interacción (una interacción de dos factores con \(n_1\) y \(n_2\) niveles de clasificación respectivamente, revierte en la estimación de \((n_1-1)\times(n_2-1)\) efectos de interacción).

Así, en nuestro problema si estamos planteando la posibilidad de que haya interacciones entre los dos factores de clasificación, estamos asumiendo un modelo de tipo siguiente, asumiendo normalidad en la respuesta:

\[(y_{ijk}|\eta_{ij},\sigma^2) \sim N(\eta_{ij},\sigma^2)\]
con
\[\eta_{ij}=\theta+ \alpha_i + \beta_j + \alpha\beta_{ij}\]
donde \(\alpha_i\) es el efecto diferencial (respecto del primer nivel) que aporta el nivel \(i\) de la variable \texttt{Breed}, \(\beta_j\) el efecto asociado a la variable \texttt{Age}, y \(\alpha\beta\) la correspondiente interacción entre ellas. En \emph{R} una interacción de orden 2 entre dos variables \(f_1\) y \(f_2\) se especifica con \(f_1:f_2\); los efectos principales y la interacción también se pueden especificar con \(f_1+f_2+f_1:f_2=f_1*f_2=(f_1+f_2)\)\^{}2.

Veamos cómo ajustar con INLA este modelo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{Butterfat }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Breed }\SpecialCharTok{*}\NormalTok{ Age}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{data=}\NormalTok{butterfat,}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{dic =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                                        mean        sd}
\CommentTok{\#\textgreater{} (Intercept)                      3.96605050 0.1314191}
\CommentTok{\#\textgreater{} BreedCanadian                    0.52193553 0.1858571}
\CommentTok{\#\textgreater{} BreedGuernsey                    0.93293190 0.1858571}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian           {-}0.30304829 0.1858571}
\CommentTok{\#\textgreater{} BreedJersey                      1.16693161 0.1858571}
\CommentTok{\#\textgreater{} AgeMature                        0.18793906 0.1858497}
\CommentTok{\#\textgreater{} BreedCanadian:AgeMature         {-}0.28692013 0.2628364}
\CommentTok{\#\textgreater{} BreedGuernsey:AgeMature         {-}0.08591997 0.2628364}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian:AgeMature {-}0.17493825 0.2628364}
\CommentTok{\#\textgreater{} BreedJersey:AgeMature            0.13107657 0.2628364}
\CommentTok{\#\textgreater{}                                 0.025quant    0.5quant}
\CommentTok{\#\textgreater{} (Intercept)                      3.7077533  3.96604997}
\CommentTok{\#\textgreater{} BreedCanadian                    0.1566392  0.52193621}
\CommentTok{\#\textgreater{} BreedGuernsey                    0.5676355  0.93293262}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian           {-}0.6683441 {-}0.30304778}
\CommentTok{\#\textgreater{} BreedJersey                      0.8016352  1.16693233}
\CommentTok{\#\textgreater{} AgeMature                       {-}0.1773425  0.18793970}
\CommentTok{\#\textgreater{} BreedCanadian:AgeMature         {-}0.8035116 {-}0.28692097}
\CommentTok{\#\textgreater{} BreedGuernsey:AgeMature         {-}0.6025115 {-}0.08592082}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian:AgeMature {-}0.6915303 {-}0.17493890}
\CommentTok{\#\textgreater{} BreedJersey:AgeMature           {-}0.3855150  0.13107577}
\CommentTok{\#\textgreater{}                                 0.975quant mode}
\CommentTok{\#\textgreater{} (Intercept)                     4.22435069   NA}
\CommentTok{\#\textgreater{} BreedCanadian                   0.88722796   NA}
\CommentTok{\#\textgreater{} BreedGuernsey                   1.29822422   NA}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian           0.06224463   NA}
\CommentTok{\#\textgreater{} BreedJersey                     1.53222392   NA}
\CommentTok{\#\textgreater{} AgeMature                       0.55321697   NA}
\CommentTok{\#\textgreater{} BreedCanadian:AgeMature         0.22967617   NA}
\CommentTok{\#\textgreater{} BreedGuernsey:AgeMature         0.43067633   NA}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian:AgeMature 0.34165750   NA}
\CommentTok{\#\textgreater{} BreedJersey:AgeMature           0.64767277   NA}
\CommentTok{\#\textgreater{}                                          kld}
\CommentTok{\#\textgreater{} (Intercept)                     2.743621e{-}09}
\CommentTok{\#\textgreater{} BreedCanadian                   2.743955e{-}09}
\CommentTok{\#\textgreater{} BreedGuernsey                   2.743953e{-}09}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian           2.743954e{-}09}
\CommentTok{\#\textgreater{} BreedJersey                     2.743957e{-}09}
\CommentTok{\#\textgreater{} AgeMature                       2.743117e{-}09}
\CommentTok{\#\textgreater{} BreedCanadian:AgeMature         2.743536e{-}09}
\CommentTok{\#\textgreater{} BreedGuernsey:AgeMature         2.743536e{-}09}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian:AgeMature 2.743535e{-}09}
\CommentTok{\#\textgreater{} BreedJersey:AgeMature           2.743536e{-}09}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{dic}\SpecialCharTok{$}\NormalTok{dic}
\CommentTok{\#\textgreater{} [1] 120.486}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{waic}\SpecialCharTok{$}\NormalTok{waic}
\CommentTok{\#\textgreater{} [1] 121.7376}
\end{Highlighting}
\end{Shaded}

Observamos en la inferencia posterior para los efectos fijos, que todas las HPD asociadas a los efectos de interacción contienen al cero, lo que descarta la relevancia de la interacción a la hora de predecir la respuesta. Reajustamos pues el modelo eliminando la interacción, y comprobamos que efectivamente al eliminarla conseguimos reducir los valores del DIC y WAIC que usamos habitualmente para la selección de variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{Butterfat }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Breed }\SpecialCharTok{+}\NormalTok{ Age}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{data=}\NormalTok{butterfat,}
         \AttributeTok{control.predictor=}\FunctionTok{list}\NormalTok{(}\AttributeTok{compute=}\ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{,}
                              \AttributeTok{dic =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                             mean         sd  0.025quant}
\CommentTok{\#\textgreater{} (Intercept)            4.0077184 0.10124855  3.80873711}
\CommentTok{\#\textgreater{} BreedCanadian          0.3784787 0.13071130  0.12159375}
\CommentTok{\#\textgreater{} BreedGuernsey          0.8899744 0.13071130  0.63308926}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian {-}0.3905147 0.13071130 {-}0.64739949}
\CommentTok{\#\textgreater{} BreedJersey            1.2324714 0.13071130  0.97558625}
\CommentTok{\#\textgreater{} AgeMature              0.1045993 0.08267006 {-}0.05787061}
\CommentTok{\#\textgreater{}                         0.5quant 0.975quant mode}
\CommentTok{\#\textgreater{} (Intercept)            4.0077182  4.2067007   NA}
\CommentTok{\#\textgreater{} BreedCanadian          0.3784790  0.6353625   NA}
\CommentTok{\#\textgreater{} BreedGuernsey          0.8899746  1.1468580   NA}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian {-}0.3905145 {-}0.1336307   NA}
\CommentTok{\#\textgreater{} BreedJersey            1.2324717  1.4893550   NA}
\CommentTok{\#\textgreater{} AgeMature              0.1045993  0.2670691   NA}
\CommentTok{\#\textgreater{}                                kld}
\CommentTok{\#\textgreater{} (Intercept)           2.524841e{-}09}
\CommentTok{\#\textgreater{} BreedCanadian         2.524864e{-}09}
\CommentTok{\#\textgreater{} BreedGuernsey         2.524860e{-}09}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian 2.524862e{-}09}
\CommentTok{\#\textgreater{} BreedJersey           2.524862e{-}09}
\CommentTok{\#\textgreater{} AgeMature             2.525095e{-}09}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{waic}\SpecialCharTok{$}\NormalTok{waic}
\CommentTok{\#\textgreater{} [1] 116.3439}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{dic}\SpecialCharTok{$}\NormalTok{dic}
\CommentTok{\#\textgreater{} [1] 115.3808}
\end{Highlighting}
\end{Shaded}

Observamos ya a partir del modelo ajustado, que el efecto de la edad no es relevante (su HPD incluye al cero), pero sin embargo sí que hay diferencias debido a las razas.

Reajustamos de nuevo el modelo, excluyendo la variable \texttt{Age}, y verificamos la reducción (ligera) del DIC/WAIC, lo cual justifica usar este modelo para la predicción.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula}\OtherTok{=}\NormalTok{Butterfat }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Breed }
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{data=}\NormalTok{butterfat,}
         \AttributeTok{control.predictor=}\FunctionTok{list}\NormalTok{(}\AttributeTok{compute=}\ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{,}
                              \AttributeTok{dic =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                             mean         sd 0.025quant}
\CommentTok{\#\textgreater{} (Intercept)            4.0600181 0.09271686  3.8778080}
\CommentTok{\#\textgreater{} BreedCanadian          0.3784786 0.13112173  0.1207927}
\CommentTok{\#\textgreater{} BreedGuernsey          0.8899742 0.13112173  0.6322881}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian {-}0.3905148 0.13112173 {-}0.6482005}
\CommentTok{\#\textgreater{} BreedJersey            1.2324713 0.13112173  0.9747851}
\CommentTok{\#\textgreater{}                         0.5quant 0.975quant mode}
\CommentTok{\#\textgreater{} (Intercept)            4.0600180  4.2422293   NA}
\CommentTok{\#\textgreater{} BreedCanadian          0.3784788  0.6361633   NA}
\CommentTok{\#\textgreater{} BreedGuernsey          0.8899745  1.1476588   NA}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian {-}0.3905146 {-}0.1328299   NA}
\CommentTok{\#\textgreater{} BreedJersey            1.2324715  1.4901558   NA}
\CommentTok{\#\textgreater{}                                kld}
\CommentTok{\#\textgreater{} (Intercept)           2.471631e{-}09}
\CommentTok{\#\textgreater{} BreedCanadian         2.471474e{-}09}
\CommentTok{\#\textgreater{} BreedGuernsey         2.471475e{-}09}
\CommentTok{\#\textgreater{} BreedHolstein{-}Fresian 2.471474e{-}09}
\CommentTok{\#\textgreater{} BreedJersey           2.471469e{-}09}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{waic}\SpecialCharTok{$}\NormalTok{waic}
\CommentTok{\#\textgreater{} [1] 115.9279}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{dic}\SpecialCharTok{$}\NormalTok{dic}
\CommentTok{\#\textgreater{} [1] 115.0094}
\end{Highlighting}
\end{Shaded}

Procederíamos igual que en el modelo de Anova de una vía para la representación de las distribuciones posteriores sobre las medias o predictores lineales en cada una de las razas. Igualmente representaremos la distribución posterior del parámetro de dispersión de los datos \(\sigma\).

\hypertarget{anuxe1lisis-de-ancova}{%
\section{Análisis de ANCOVA}\label{anuxe1lisis-de-ancova}}

En ocasiones tenemos una variable respuesta de tipo numérico, y como posibles predictores variables de tipo numérico y también variables clasificadoras o factores. Surge entonces la posibilidad de que los predictores numéricos afecten a la respuesta de modo distinto en diferentes niveles de clasificación de los factores; hablamos entonces de interacción entre covariables y factores. Veamos un ejemplo para comprender cómo funcionan estos modelos y cómo se ajustan con INLA.

Consideramos los datos de Galton sobre la regresión de las alturas de los hijos sobre la de los padres (Fte: \href{http://www.randomservices.org/random/}{Galton's Height Data}). Tenemos la estatura del padre, de la madre y del hijo/a, identificado/a por su sexo.
Vamos a formular un modelo de regresión de la estatura de los hijos en función de la de sus padres y su género.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.dir}\OtherTok{=}\StringTok{"\textasciitilde{}/Dropbox/ESTADISTICA/BAYESIAN/VARIOS/"}
\NormalTok{datos}\OtherTok{\textless{}{-}}\FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file=}\FunctionTok{paste0}\NormalTok{(my.dir,}\StringTok{"Galton.txt"}\NormalTok{),}\AttributeTok{header=}\ConstantTok{TRUE}\NormalTok{,}\AttributeTok{dec=}\StringTok{"."}\NormalTok{, }\AttributeTok{sep=}\StringTok{""}\NormalTok{)}
\FunctionTok{str}\NormalTok{(datos)}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    898 obs. of  6 variables:}
\CommentTok{\#\textgreater{}  $ Family: chr  "1" "1" "1" "1" ...}
\CommentTok{\#\textgreater{}  $ Father: num  78.5 78.5 78.5 78.5 75.5 75.5 75.5 75.5 75 75 ...}
\CommentTok{\#\textgreater{}  $ Mother: num  67 67 67 67 66.5 66.5 66.5 66.5 64 64 ...}
\CommentTok{\#\textgreater{}  $ Gender: chr  "M" "F" "F" "F" ...}
\CommentTok{\#\textgreater{}  $ Height: num  73.2 69.2 69 69 73.5 72.5 65.5 65.5 71 68 ...}
\CommentTok{\#\textgreater{}  $ Kids  : int  4 4 4 4 4 4 4 4 2 2 ...}
\end{Highlighting}
\end{Shaded}

Asumimos pues como respuesta la variable \texttt{y=Height}, como regresores las variables \(x_1=\)\texttt{Father} y \(x_2=\)\texttt{Mother} con las estaturas del padre y la madre respectivamente, y con factor de clasificación la variable \(G=\)\texttt{Gender}, con niveles M/F. En principio cabrían posibles interacciones entre los regresores y los factores de clasificación, por lo que planteamos el modelo:

\[(y_{ij}|\eta_{ij},\sigma^2) \sim N(\eta_{ij},\sigma^2)\]
con el predictor lineal
\[\eta_{ij}=\mu_{ij}=\beta_0+(\beta_1 + \alpha_{1M}) x_{1j} + (\beta_2+ \alpha_{2M}) x_{2j} + \alpha_M;\ \  j =1,...,n_i; i=M,F\]
donde \(\alpha_M\) es el efecto diferencial global de los hombres frente a las mujeres al predecir la estatura, y \(\alpha_{1M},\alpha_{2M}\) los efectos diferenciales que afectan a los regresores.

Asumimos una distribución vaga sobre \(\beta_0, \beta_1\) y \(\tau=1/\sigma^2\) y ajustamos el modelo Gausiano en INLA:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ Height }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\SpecialCharTok{+}\NormalTok{(Father}\SpecialCharTok{+}\NormalTok{Mother)}\SpecialCharTok{*}\NormalTok{Gender}
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{datos)}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                  mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept)    16.652 3.887      9.028   16.652     24.276}
\CommentTok{\#\textgreater{} Father          0.400 0.039      0.324    0.400      0.477}
\CommentTok{\#\textgreater{} Mother          0.307 0.045      0.218    0.307      0.396}
\CommentTok{\#\textgreater{} GenderM         2.707 5.427     {-}7.939    2.707     13.353}
\CommentTok{\#\textgreater{} Father:GenderM  0.012 0.058     {-}0.103    0.012      0.126}
\CommentTok{\#\textgreater{} Mother:GenderM  0.027 0.062     {-}0.096    0.027      0.149}
\CommentTok{\#\textgreater{}                mode kld}
\CommentTok{\#\textgreater{} (Intercept)      NA   0}
\CommentTok{\#\textgreater{} Father           NA   0}
\CommentTok{\#\textgreater{} Mother           NA   0}
\CommentTok{\#\textgreater{} GenderM          NA   0}
\CommentTok{\#\textgreater{} Father:GenderM   NA   0}
\CommentTok{\#\textgreater{} Mother:GenderM   NA   0}
\end{Highlighting}
\end{Shaded}

Observamos que ninguna de las interacciones tienen un efecto a considerar (su HPD posterior incluye al cero), de modo que las descartamos y reajustamos el modelo sin ellas.

\[\eta_{ij}=\mu_{ij}=\beta_0+ \beta_1  x_{1j} + \beta_2 x_{2j} + \alpha_M;\ \  j =1,...,n_i; i=M,F.\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ Height }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Father}\SpecialCharTok{+}\NormalTok{Mother}\SpecialCharTok{+}\NormalTok{Gender}
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{datos,}
        \AttributeTok{control.predictor=}\FunctionTok{list}\NormalTok{(}\AttributeTok{compute=}\ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{,}
                              \AttributeTok{dic =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{waic =} \ConstantTok{TRUE}\NormalTok{))}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}               mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 15.345 2.747      9.957   15.345     20.733}
\CommentTok{\#\textgreater{} Father       0.406 0.029      0.349    0.406      0.463}
\CommentTok{\#\textgreater{} Mother       0.321 0.031      0.260    0.321      0.383}
\CommentTok{\#\textgreater{} GenderM      5.226 0.144      4.943    5.226      5.508}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} Father        NA   0}
\CommentTok{\#\textgreater{} Mother        NA   0}
\CommentTok{\#\textgreater{} GenderM       NA   0}
\end{Highlighting}
\end{Shaded}

Ahora todos los efectos fijos son relevantes para predecir la estatura de los hijos. Utilizamos este modelo para derivar las inferencias.

Representamos a continuación en la Figura \ref(fig:galton1) las distribuciones posteriores de los efectos fijos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fixed}\OtherTok{=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)}
\NormalTok{g}\OtherTok{=}\FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(fixed))\{}
\NormalTok{  g[[i]]}\OtherTok{=}\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]),}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
    \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}\SpecialCharTok{$}\NormalTok{mean[i],}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed[i,}\DecValTok{3}\NormalTok{],}\AttributeTok{linetype=}\StringTok{"dotted"}\NormalTok{)}\SpecialCharTok{+}
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed[i,}\DecValTok{5}\NormalTok{],}\AttributeTok{linetype=}\StringTok{"dotted"}\NormalTok{)}\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\NormalTok{fixed[i],}\AttributeTok{y=}\StringTok{"D.posterior"}\NormalTok{)}
\NormalTok{\}}
\FunctionTok{grid.arrange}\NormalTok{(g[[}\DecValTok{1}\NormalTok{]],g[[}\DecValTok{2}\NormalTok{]],g[[}\DecValTok{3}\NormalTok{]],g[[}\DecValTok{4}\NormalTok{]],}\AttributeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/galton1-1.pdf}
\caption{\label{fig:galton1}Distribución posterior de los efectos fijos}
\end{figure}

En media observamos que la estatura de los hombres es 5.23 unidades superior a la de las mujeres.

Con estas distribuciones podemos calcular cualquier probabilidad, como por ejemplo,la probabilidad de que la estatura de un hombre, sean como sean sus ancestros, supere en 5 unidades a la de una mujer:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{inla.pmarginal}\NormalTok{(}\DecValTok{5}\NormalTok{,fit}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"GenderM"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.941422}
\end{Highlighting}
\end{Shaded}

Podemos acceder a las distribuciones posteriores de la estatura esperada de un sujeto y posicionar las estaturas de sus padres, que se muestran en la Figura \ref{fig:galton2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# la predicción del predictor lineal para cada sujeto es:}
\NormalTok{pred}\OtherTok{\textless{}{-}}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{marginals.linear.predictor}
\CommentTok{\# que en este caso coincide con los valores ajustados}
\NormalTok{fitted}\OtherTok{\textless{}{-}}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{marginals.fitted.values}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(pred}\SpecialCharTok{$}\NormalTok{Predictor}\FloatTok{.1}\NormalTok{),}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Estatura media del sujeto 1"}\NormalTok{,}\AttributeTok{y=}\StringTok{"D.posterior"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fitted.values}\SpecialCharTok{$}\NormalTok{mean[}\DecValTok{1}\NormalTok{],}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{datos}\SpecialCharTok{$}\NormalTok{Father[}\DecValTok{1}\NormalTok{],}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"blue"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{datos}\SpecialCharTok{$}\NormalTok{Mother[}\DecValTok{1}\NormalTok{],}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}\AttributeTok{color=}\StringTok{"pink"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{,}\AttributeTok{x=}\NormalTok{datos}\SpecialCharTok{$}\NormalTok{Mother[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\DecValTok{1}\NormalTok{,}\AttributeTok{y=}\DecValTok{1}\NormalTok{,}\AttributeTok{label=}\StringTok{"Madre"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{,}\AttributeTok{x=}\NormalTok{datos}\SpecialCharTok{$}\NormalTok{Father[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\AttributeTok{y=}\DecValTok{1}\NormalTok{,}\AttributeTok{label=}\StringTok{"Padre"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/galton2-1.pdf}
\caption{\label{fig:galton2}Predicción de la estatura del primer sujeto en la muestra}
\end{figure}

Podemos ir más allá, prediciendo la estatura de un sujeto, sea hombre o mujer, cuando su padre mide 1.75m (68.9 pulgadas) y su madre 1.70m (66.9 pulgadas). Expresamos los resultados en centímetros.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new.data}\OtherTok{=}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Father=}\FunctionTok{c}\NormalTok{(}\FloatTok{68.9}\NormalTok{,}\FloatTok{68.9}\NormalTok{),}
                    \AttributeTok{Mother=}\FunctionTok{c}\NormalTok{(}\FloatTok{66.9}\NormalTok{,}\FloatTok{66.9}\NormalTok{),}
                    \AttributeTok{Gender=}\FunctionTok{c}\NormalTok{(}\StringTok{"M"}\NormalTok{,}\StringTok{"F"}\NormalTok{),}
                    \AttributeTok{Height=}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{))}
\NormalTok{datos.combinado }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(datos, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Family=}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{),new.data,}\AttributeTok{Kids=}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{,}\ConstantTok{NA}\NormalTok{)))}

\DocumentationTok{\#\# creamos un vector con NA\textquotesingle{}s para observaciones y 1\textquotesingle{}s para predicciones}
\NormalTok{datos.indicador }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(datos)), }\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(new.data)))}
\DocumentationTok{\#\# reajustamos el modelo añadiendo la opción de predicción de datos}
\NormalTok{fit.pred }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{data =}\NormalTok{ datos.combinado, }
                 \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{return.marginals.predictor=}\ConstantTok{TRUE}\NormalTok{),}
                 \AttributeTok{control.predictor =} \FunctionTok{list}\NormalTok{(}\AttributeTok{link =}\NormalTok{ datos.indicador))}
\DocumentationTok{\#\# y describimos los valores ajustados para los escenarios añadidos}
\FunctionTok{round}\NormalTok{(fit.pred}\SpecialCharTok{$}\NormalTok{summary.fitted.values[(}\FunctionTok{nrow}\NormalTok{(datos)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(datos.combinado),]}\SpecialCharTok{*}\FloatTok{2.54}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{}                       mean  sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} fitted.Predictor.899 177.9 0.3      177.3    177.9}
\CommentTok{\#\textgreater{} fitted.Predictor.900 164.7 0.3      164.0    164.7}
\CommentTok{\#\textgreater{}                      0.975quant mode}
\CommentTok{\#\textgreater{} fitted.Predictor.899      178.6   NA}
\CommentTok{\#\textgreater{} fitted.Predictor.900      165.3   NA}
\end{Highlighting}
\end{Shaded}

También graficar las distribuciones predictivas y probabilidades (Figura \ref{fig:galton3}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Distribuciones predictivas}
\NormalTok{pred.M}\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(fit.pred}\SpecialCharTok{$}\NormalTok{marginals.fitted.values[[(}\FunctionTok{nrow}\NormalTok{(datos)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)]])}\SpecialCharTok{*}\FloatTok{2.54}
\NormalTok{pred.F}\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(fit.pred}\SpecialCharTok{$}\NormalTok{marginals.fitted.values[[(}\FunctionTok{nrow}\NormalTok{(datos)}\SpecialCharTok{+}\DecValTok{2}\NormalTok{)]])}\SpecialCharTok{*}\FloatTok{2.54}
\NormalTok{d.pred}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(pred.M,pred.F)}
\CommentTok{\# atributo Gender}
\NormalTok{d.pred}\SpecialCharTok{$}\NormalTok{Gender}\OtherTok{=}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"M"}\NormalTok{,}\StringTok{"F"}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(pred.M),}\FunctionTok{nrow}\NormalTok{(pred.F)))}
\CommentTok{\# objetivo de estatura}
\NormalTok{d.pred}\SpecialCharTok{$}\NormalTok{obj}\OtherTok{=}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{178}\NormalTok{,}\DecValTok{165}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(pred.M),}\FunctionTok{nrow}\NormalTok{(pred.F)))}

\FunctionTok{ggplot}\NormalTok{(d.pred,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{obj),}\AttributeTok{linetype=}\StringTok{"dashed"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(Gender),}\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Estatura"}\NormalTok{,}\AttributeTok{y=}\StringTok{"D.posterior"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/galton3-1.pdf}
Y calcular probabilidades, como la probabilidad de que dicho sujeto supere el 1.65m si es mujer, o el 1.78m si es hombre.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# cálculo de probabilidades}
\NormalTok{p165F}\OtherTok{=}\FunctionTok{round}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{inla.pmarginal}\NormalTok{(}\DecValTok{165}\NormalTok{,pred.F),}\DecValTok{2}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Pr(estatura\textgreater{}165|mujer,padre=175,madre=170)="}\NormalTok{,p165F))}
\CommentTok{\#\textgreater{} Pr(estatura\textgreater{}165|mujer,padre=175,madre=170)= 0.16}
\FunctionTok{cat}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{p178M}\OtherTok{=}\FunctionTok{round}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{inla.pmarginal}\NormalTok{(}\DecValTok{178}\NormalTok{,pred.M),}\DecValTok{2}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Pr(estatura\textgreater{}178|hombre,padre=175,madre=170)="}\NormalTok{,p178M))}
\CommentTok{\#\textgreater{} Pr(estatura\textgreater{}178|hombre,padre=175,madre=170)= 0.42}
\end{Highlighting}
\end{Shaded}

Podríamos también, modificar las especificaciones a priori sobre los parámetros \(\beta_0\) y \(\beta_1\) mediante el comando \texttt{control.fixed}. Por ejemplo, queremos asumir a priori \(\beta_0\sim N(0,10^4)\) y \(\beta_1\sim N(0,100)\) y ver cómo afecta a las inferencias.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\OtherTok{\textless{}{-}}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{datos,}
                   \AttributeTok{control.fixed=}\FunctionTok{list}\NormalTok{(}\AttributeTok{mean=}\DecValTok{0}\NormalTok{,}\AttributeTok{prec=}\FloatTok{0.01}\NormalTok{,}
                   \AttributeTok{mean.intercept=}\DecValTok{0}\NormalTok{, }\AttributeTok{prec.intercept=}\FloatTok{0.0001}\NormalTok{))}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}               mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 15.335 2.745      9.950   15.335     20.721}
\CommentTok{\#\textgreater{} Father       0.406 0.029      0.349    0.406      0.463}
\CommentTok{\#\textgreater{} Mother       0.322 0.031      0.260    0.322      0.383}
\CommentTok{\#\textgreater{} GenderM      5.225 0.144      4.942    5.225      5.507}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} Father        NA   0}
\CommentTok{\#\textgreater{} Mother        NA   0}
\CommentTok{\#\textgreater{} GenderM       NA   0}
\end{Highlighting}
\end{Shaded}

Si queremos especificar medias a priori diferentes para los coeficientes de los distintos regresores, hemos de especificarlos con listas.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{datos,}
                   \AttributeTok{control.fixed=}\FunctionTok{list}\NormalTok{(}\AttributeTok{mean=}\FunctionTok{list}\NormalTok{(}\AttributeTok{Father=}\FloatTok{0.2}\NormalTok{,}\AttributeTok{Mother=}\FloatTok{0.1}\NormalTok{)))}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.fixed,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}               mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 15.345 2.747      9.957   15.345     20.734}
\CommentTok{\#\textgreater{} Father       0.406 0.029      0.349    0.406      0.463}
\CommentTok{\#\textgreater{} Mother       0.321 0.031      0.260    0.321      0.383}
\CommentTok{\#\textgreater{} GenderM      5.226 0.144      4.943    5.226      5.508}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} Father        NA   0}
\CommentTok{\#\textgreater{} Mother        NA   0}
\CommentTok{\#\textgreater{} GenderM       NA   0}
\end{Highlighting}
\end{Shaded}

Si queremos modificar la especificación de la prior en \(\sigma^2\), o lo que es equivalente, en la precisión \(\tau\), con la distribución \(log(\tau) \sim N(0,1)\) en lugar de \(\tau \sim Ga(1,10^{-5})\), vemos cómo afecta a la inferencia posterior sobre la precisión.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_n }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data=}\NormalTok{datos,}
                   \AttributeTok{control.family=}\FunctionTok{list}\NormalTok{(}\AttributeTok{hyper=}\FunctionTok{list}\NormalTok{(}
                     \AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prior=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)))))}
\CommentTok{\# con el modelo log{-}gamma para precisión}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                                          mean   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.216 0.01}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.197    0.216}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.236   NA}
\CommentTok{\# con el modelo normal para precisión}
\FunctionTok{round}\NormalTok{(fit\_n}\SpecialCharTok{$}\NormalTok{summary.hyperpar,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                                          mean   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.216 0.01}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.197    0.216}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.237   NA}
\end{Highlighting}
\end{Shaded}

Cuando tenemos información previa disponible sobre la variación de los datos, será generalmente más intuitivo expresarla en términos de la desviación estándar \(\sigma\). Bastará con conseguir la equivalencia en la escala de \(log(\tau)\) para incluirla en el modelo. Por ejemplo, si sabemos que la desviación típica está entre 2 y 14, \(\sigma \sim Unif(2,14)\), podemos calcular una prior para la log-precisión del siguiente modo:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  simular una muestra de \(\sigma \sim Unif(2,14)\)
\item
  transformar a precisiones
\item
  calcular los parámetros de la Gamma para la precisión, a partir de su media y varianza
\end{enumerate}

Hacemos los cálculos y graficamos la prior en la Figura \ref{fig:galton4}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# parámetros para sigma\textasciitilde{}Un(a1,b1)}
\NormalTok{a1}\OtherTok{\textless{}{-}}\DecValTok{2}
\NormalTok{b1}\OtherTok{\textless{}{-}}\DecValTok{14}
\CommentTok{\# simulamos sigma de una distribución Unif(a1,b1)}
\NormalTok{sigma}\OtherTok{\textless{}{-}}\FunctionTok{runif}\NormalTok{(}\AttributeTok{n=}\DecValTok{10000}\NormalTok{,}\AttributeTok{min=}\NormalTok{a1,}\AttributeTok{max=}\NormalTok{b1)}
\CommentTok{\# obtenemos la precisión}
\NormalTok{tau}\OtherTok{\textless{}{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\# Calculamos los parámetros alpha,beta de una distrib. Gamma para la precisión}
\CommentTok{\# mean=alpha/beta; var=alpha/beta\^{}2}
\NormalTok{beta}\OtherTok{=} \FunctionTok{mean}\NormalTok{(tau)}\SpecialCharTok{/}\FunctionTok{var}\NormalTok{(tau)}
\NormalTok{alpha}\OtherTok{\textless{}{-}}\FunctionTok{mean}\NormalTok{(tau)}\SpecialCharTok{*}\NormalTok{beta}
\CommentTok{\# dibujamos los valores de la precisión}
\NormalTok{tau.seq}\OtherTok{=}\FunctionTok{sort}\NormalTok{(tau)}
  \CommentTok{\# seq(min(tau),max(tau),length=1000)}
\NormalTok{prior}\OtherTok{=}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{tau=}\NormalTok{tau.seq,}\AttributeTok{dprior=}\FunctionTok{dgamma}\NormalTok{(tau.seq,alpha,beta))}
\FunctionTok{ggplot}\NormalTok{(prior, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{tau))}\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{..density..),}\AttributeTok{color=}\StringTok{"grey"}\NormalTok{,}\AttributeTok{fill=}\StringTok{"white"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{dprior))}
\CommentTok{\#\textgreater{} \textasciigrave{}stat\_bin()\textasciigrave{} using \textasciigrave{}bins = 30\textasciigrave{}. Pick better value with}
\CommentTok{\#\textgreater{} \textasciigrave{}binwidth\textasciigrave{}.}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/galton4-1.pdf}
\caption{\label{fig:galton4}Distribución a prior para tau con sigma \textasciitilde{} Uniforme(2,14)}
\end{figure}

Utilicemos pues esos parámetros para especificar la prior sobre \(\tau\) en INLA:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{datos,}
                   \AttributeTok{control.family=}\FunctionTok{list}\NormalTok{(}\AttributeTok{hyper=}\FunctionTok{list}\NormalTok{(}
                     \AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prior=}\StringTok{"loggamma"}\NormalTok{,}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(alpha,beta)))))}
\FunctionTok{round}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar,}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                                          mean   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.214 0.01}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.195    0.214}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.234   NA}
\end{Highlighting}
\end{Shaded}

\hypertarget{efectos-aleatorios}{%
\section{Efectos aleatorios}\label{efectos-aleatorios}}

Desde una perspectiva frecuentista un modelo básico de Anova podría ser un modelo de efectos fijos, pero también de efectos aleatorios. Así por ejemplo el tratamiento dado en un ensayo clínico importa para comparar y diferenciar el efecto que provoca sobre un paciente; tratamiento en entonces es un efecto fijo, de interés primario. En otro ejemplo, se han aplicado varios fertilizantes a cultivos en fincas distintas; el interés primario será comparar los fertilizantes, pero no las fincas, por lo que fertilizante será un efecto fijo; sin embargo, el factor finca sólo tiene interés por cuanto aporta variabilidad en la respuesta, y no para comparar las fincas, por lo que se considerará como un efecto aleatorio.

Una variable predictiva, numérica o categórica, entra en el modelo como \textbf{efecto fijo} cuando se piensa que afecta a todas las observaciones del mismo modo (de un modo lineal), y que su efecto es de interés primario en el estudio.
En un contexto bayesiano un efecto fijo tendrá un coeficiente asociado al que se le asigna a menudo una distribución a priori vaga (mínimo informativa), como una gausiana con media cero y varianza (conocida) grande. En cualquier caso, la distribución a priori que se asume para los efectos fijos es siempre una distribución conocida.

Un \textbf{efecto aleatorio} identifica a variables de tipo categórico que no son de interés primario en la investigación, pero que se considera que añaden incertidumbre y por lo tanto variabilidad a la respuesta. La modelización habitual de los efectos aleatorios es una prior gausiana con media cero y una precisión desconocida, para la que será preciso asignar una distribución a priori. La distribución a priori de los efectos aleatorios tiene parámetros desconocidos, llamados \textbf{hiperparámetros}, a los que hay que asignar asimismo una distribución a priori.

Puesto que no salimos del modelo lineal, seguiremos asumiendo una respuesta normal, \emph{gaussian}, con media igual a un predictor lineal \(\eta=\theta+ Z u\), donde \(Z\) es la correspondiente matriz de diseño para los efectos aleatorios \(z_1, z_2,...\). Se asume además una varianza desconocida \(\sigma^2\).

En INLA la fórmula de predicción de una respuesta \(y\) a partir de un conjunto de efectos aleatorios z1,z2,\ldots{} se especifica como:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}  \SpecialCharTok{+} \FunctionTok{f}\NormalTok{(z1, }\AttributeTok{model=}\StringTok{""}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(z2,}\AttributeTok{model=}\StringTok{""}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

donde la función \(f()\) especifica la relación entre el predictor lineal de la respuesta y los efectos aleatorios \(z\). El tipo de relación asumida se incluye en el argumento \texttt{model} o modelo latente, que tiene como posibilidades \texttt{names(inla.models()\$latent)}, si bien en el modelo lineal la opción habitual es \texttt{model="iid"}, que asume efectos aleatorios independientes e idénticamente distribuidos. La función \(f()\) tiene muchos argumentos, que se pueden consultar con el comando \texttt{?f}.

Veamos cómo ajustar un modelo de efectos aleatorios a partir de un ejemplo sencillo. Comenzamos con la base de datos \texttt{broccoli} en la librería \href{https://cran.r-project.org/web/packages/faraway/faraway.pdf}{\texttt{faraway}}. Varios cultivadores suministran brócoli a una planta de procesamiento de alimentos. La planta da instrucciones a los cultivadores para que empaquen el brócoli en cajas de tamaño estándar. Debe haber 18 racimos de brócoli por caja y cada racimo debe pesar entre 1,33 y 1,5 libras. Debido a que los productores utilizan diferentes variedades, métodos de cultivo, etc., hay cierta variación en el peso de los racimos. El responsable de la planta seleccionó 3 cultivadores al azar y luego 4 cajas al azar suministradas por estos cultivadores. Se seleccionaron 3 racimos de brocoli de cada caja.

La variable de interés es el peso del racimo de brócoli, en la variable \texttt{wt}. Sin embargo, dado cómo se ha seleccionado la muestra, el objetivo no es ni la comparación entre cultivadores (\texttt{grower}), ni entre cajas (\texttt{box}) ni entre racimos (\texttt{cluster}). Sin embargo, de manera lógica intuimos que habrá variabilidad también entre cajas (efecto aleatorio \texttt{box}) y también entre cultivadores (efecto aleatorio \texttt{grower}), lo que nos conduce a un modelo en el que todos los predictores, \texttt{box} y \texttt{grower} intervienen como efectos aleatorios; la variable \texttt{cluster} la aprovechamos a modo de repeticiones de medidas en una misma caja de un mismo cultivador.

La base de datos cuenta con 36 registros (3 observaciones en cada combinación \texttt{grower-box}.

\[(y_{ijk}|\eta_{ij},\sigma^2 ) \sim N(\eta_{ijk},\sigma^2)\]

con \[\eta_{ijk} = \theta + \alpha_i^G + \beta_j^B; \ \  i=2,3; j=2,3,4; k=1,2,3\]
donde \(\alpha^G\) representa el efecto aleatorio asociado al cultivador y \(\beta^B\) a la caja.

Así el vector de efectos latentes está compuesto por el efecto fijo de interceptación \(theta\) y los efectos aleatorios \(u=(\alpha_2^G,\alpha_3^G,\beta_2^B,\beta_3^B,\beta_4^B)\).

El siguiente paso es especificar una distribución a priori sobre los parámetros. INLA por defecto asigna una prior difusa sobre la interceptación \(\theta\) y también sobre la precisión de los datos \(\tau=1/\sigma^2\). Dado que los \(\alpha_i^G\) representan el efecto diferencial asociado al cultivador, es razonable asumir independencia entre todos estos parámetros y una distribución idéntica, centrada en el cero (ante ausencia de información) y con una varianza desconocida. Del mismo modo, se asume que los \(\beta_j^B\) son a priori independientes e idénticamente distribuidos (iid) con una normal centrada en el cero (ante ausencia de información) y con varianza desconocida.

\begin{eqnarray*}
\theta &\sim & N(0,\sigma_{\theta}^2), \ \sigma_{\theta}^2=\infty \\
log(\tau) &\sim & Log-Ga(1,5\cdot 10^{-5})\\
\alpha_i^G & \sim_{iid} & N(0,\sigma_{G}^2), i=2,3 \\
\beta_j^B & \sim_{iid} & N(0,\sigma_{B}^2), j=2,3,4
\end{eqnarray*}

Surgen pues, dos nuevos parámetros en las a priori, o hiperparámetros, \(\sigma_{G}^2\) y \(\sigma_{B}^2\), a los que también habrá que asignar una distribución a priori. Dado que se trata de varianzas, por defecto INLA asume gammas inversas difusas, o lo que es lo mismo, log-gammas difusas para las precisiones

\begin{eqnarray*}
\tau_{G}=1/\sigma_{G}^2 &\sim & Ga(1,5\cdot 10^{-5}) \\
\tau_{B}=1/\sigma_{B}^2 &\sim & Ga(1,5\cdot 10^{-5})
\end{eqnarray*}

Surgen pues, tres niveles de especificación del modelo: datos, parámetros e hiperparámetros, que generan un modelo jerárquico, y sobre el que hablaremos más adelante.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(broccoli, }\AttributeTok{package=}\StringTok{"faraway"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(broccoli)}
\CommentTok{\#\textgreater{} \textquotesingle{}data.frame\textquotesingle{}:    36 obs. of  4 variables:}
\CommentTok{\#\textgreater{}  $ wt     : num  352 369 383 339 367 328 376 359 388 365 ...}
\CommentTok{\#\textgreater{}  $ grower : Factor w/ 3 levels "1","2","3": 1 1 1 2 2 2 3 3 3 1 ...}
\CommentTok{\#\textgreater{}  $ box    : Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 2 ...}
\CommentTok{\#\textgreater{}  $ cluster: Factor w/ 3 levels "1","2","3": 1 2 3 1 2 3 1 2 3 1 ...}
\NormalTok{formula }\OtherTok{=}\NormalTok{ wt }\SpecialCharTok{\textasciitilde{}} \FunctionTok{f}\NormalTok{(grower,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{)}\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(box,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{)}
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{broccoli,}
           \AttributeTok{control.compute =} \FunctionTok{list}\NormalTok{(}\AttributeTok{dic=}\ConstantTok{TRUE}\NormalTok{,}\AttributeTok{waic=}\ConstantTok{TRUE}\NormalTok{))  }
\FunctionTok{summary}\NormalTok{(fit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{}    c("inla.core(formula = formula, family = family, }
\CommentTok{\#\textgreater{}    contrasts = contrasts, ", " data = data, quantiles = }
\CommentTok{\#\textgreater{}    quantiles, E = E, offset = offset, ", " scale = }
\CommentTok{\#\textgreater{}    scale, weights = weights, Ntrials = Ntrials, strata = }
\CommentTok{\#\textgreater{}    strata, ", " lp.scale = lp.scale, link.covariates = }
\CommentTok{\#\textgreater{}    link.covariates, verbose = verbose, ", " lincomb = }
\CommentTok{\#\textgreater{}    lincomb, selection = selection, control.compute = }
\CommentTok{\#\textgreater{}    control.compute, ", " control.predictor = }
\CommentTok{\#\textgreater{}    control.predictor, control.family = control.family, }
\CommentTok{\#\textgreater{}    ", " control.inla = control.inla, control.fixed = }
\CommentTok{\#\textgreater{}    control.fixed, ", " control.mode = control.mode, }
\CommentTok{\#\textgreater{}    control.expert = control.expert, ", " control.hazard }
\CommentTok{\#\textgreater{}    = control.hazard, control.lincomb = control.lincomb, }
\CommentTok{\#\textgreater{}    ", " control.update = control.update, }
\CommentTok{\#\textgreater{}    control.lp.scale = control.lp.scale, ", " }
\CommentTok{\#\textgreater{}    control.pardiso = control.pardiso, only.hyperparam = }
\CommentTok{\#\textgreater{}    only.hyperparam, ", " inla.call = inla.call, inla.arg }
\CommentTok{\#\textgreater{}    = inla.arg, num.threads = num.threads, ", " }
\CommentTok{\#\textgreater{}    blas.num.threads = blas.num.threads, keep = keep, }
\CommentTok{\#\textgreater{}    working.directory = working.directory, ", " silent = }
\CommentTok{\#\textgreater{}    silent, inla.mode = inla.mode, safe = FALSE, debug = }
\CommentTok{\#\textgreater{}    debug, ", " .parent.frame = .parent.frame)") }
\CommentTok{\#\textgreater{} Time used:}
\CommentTok{\#\textgreater{}     Pre = 2.56, Running = 0.238, Post = 0.0176, Total = 2.81 }
\CommentTok{\#\textgreater{} Fixed effects:}
\CommentTok{\#\textgreater{}                mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) 358.167 2.734    352.778  358.167    363.555}
\CommentTok{\#\textgreater{}             mode kld}
\CommentTok{\#\textgreater{} (Intercept)   NA   0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Random effects:}
\CommentTok{\#\textgreater{}   Name     Model}
\CommentTok{\#\textgreater{}     grower IID model}
\CommentTok{\#\textgreater{}    box IID model}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model hyperparameters:}
\CommentTok{\#\textgreater{}                                             mean       sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 4.00e{-}03 1.00e{-}03}
\CommentTok{\#\textgreater{} Precision for grower                    1.55e+04 1.56e+04}
\CommentTok{\#\textgreater{} Precision for box                       2.11e+04 2.23e+04}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations      0.002 4.00e{-}03}
\CommentTok{\#\textgreater{} Precision for grower                      1765.697 1.09e+04}
\CommentTok{\#\textgreater{} Precision for box                         2122.090 1.44e+04}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   6.00e{-}03   NA}
\CommentTok{\#\textgreater{} Precision for grower                      5.70e+04   NA}
\CommentTok{\#\textgreater{} Precision for box                         8.04e+04   NA}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Deviance Information Criterion (DIC) ...............: 307.75}
\CommentTok{\#\textgreater{} Deviance Information Criterion (DIC, saturated) ....: 26089.22}
\CommentTok{\#\textgreater{} Effective number of parameters .....................: 1.84}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Watanabe{-}Akaike information criterion (WAIC) ...: 307.66}
\CommentTok{\#\textgreater{} Effective number of parameters .................: 1.67}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Marginal log{-}Likelihood:  {-}166.64 }
\CommentTok{\#\textgreater{}  is computed }
\CommentTok{\#\textgreater{} Posterior summaries for the linear predictor and the fitted values are computed}
\CommentTok{\#\textgreater{} (Posterior marginals needs also \textquotesingle{}control.compute=list(return.marginals.predictor=TRUE)\textquotesingle{})}
\end{Highlighting}
\end{Shaded}

Cuando queremos mostrar los resultados a posteriori sobre los efectos aleatorios a partir de un ajuste \texttt{fit} con \texttt{inla}, tenemos las siguientes opciones:

\begin{itemize}
\tightlist
\item
  \texttt{fit\$summary.random} resume la inferencia posterior sobre los efectos
  aleatorios
\item
  \texttt{names(fit\$marginals.random)} lista los nombre de todos los efectos aleatorios
\item
  \texttt{fit\$marginals.random} da las distribuciones posteriores marginales de los efectos aleatorios
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.random}
\CommentTok{\#\textgreater{} $grower}
\CommentTok{\#\textgreater{}   ID          mean         sd  0.025quant      0.5quant}
\CommentTok{\#\textgreater{} 1  1  1.492374e{-}06 0.01130853 {-}0.02439995  8.736887e{-}07}
\CommentTok{\#\textgreater{} 2  2 {-}1.044657e{-}05 0.01130854 {-}0.02442924 {-}6.115819e{-}06}
\CommentTok{\#\textgreater{} 3  3  8.954184e{-}06 0.01130853 {-}0.02438167  5.242123e{-}06}
\CommentTok{\#\textgreater{}   0.975quant mode          kld}
\CommentTok{\#\textgreater{} 1 0.02440727   NA 0.0001310971}
\CommentTok{\#\textgreater{} 2 0.02437801   NA 0.0001310977}
\CommentTok{\#\textgreater{} 3 0.02442558   NA 0.0001310975}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $box}
\CommentTok{\#\textgreater{}   ID          mean         sd  0.025quant      0.5quant}
\CommentTok{\#\textgreater{} 1  1  1.634571e{-}05 0.01047978 {-}0.02247619  9.734234e{-}06}
\CommentTok{\#\textgreater{} 2  2 {-}9.371546e{-}06 0.01047977 {-}0.02254043 {-}5.580916e{-}06}
\CommentTok{\#\textgreater{} 3  3 {-}4.140913e{-}06 0.01047977 {-}0.02252735 {-}2.465972e{-}06}
\CommentTok{\#\textgreater{} 4  4 {-}2.833264e{-}06 0.01047977 {-}0.02252408 {-}1.687243e{-}06}
\CommentTok{\#\textgreater{}   0.975quant mode          kld}
\CommentTok{\#\textgreater{} 1 0.02255789   NA 0.0001322533}
\CommentTok{\#\textgreater{} 2 0.02249359   NA 0.0001322526}
\CommentTok{\#\textgreater{} 3 0.02250665   NA 0.0001322523}
\CommentTok{\#\textgreater{} 4 0.02250992   NA 0.0001322523}
\end{Highlighting}
\end{Shaded}

Más que la inferencia sobre los efectos aleatorios, es importante la que se hace sobre las varianzas asociadas:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                                 mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 3.831722e{-}03}
\CommentTok{\#\textgreater{} Precision for grower                    1.547070e+04}
\CommentTok{\#\textgreater{} Precision for box                       2.106179e+04}
\CommentTok{\#\textgreater{}                                                   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 8.988398e{-}04}
\CommentTok{\#\textgreater{} Precision for grower                    1.562618e+04}
\CommentTok{\#\textgreater{} Precision for box                       2.234736e+04}
\CommentTok{\#\textgreater{}                                           0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 2.271079e{-}03}
\CommentTok{\#\textgreater{} Precision for grower                    1.765697e+03}
\CommentTok{\#\textgreater{} Precision for box                       2.122090e+03}
\CommentTok{\#\textgreater{}                                             0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 3.767080e{-}03}
\CommentTok{\#\textgreater{} Precision for grower                    1.087754e+04}
\CommentTok{\#\textgreater{} Precision for box                       1.440273e+04}
\CommentTok{\#\textgreater{}                                           0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 5.782886e{-}03   NA}
\CommentTok{\#\textgreater{} Precision for grower                    5.702135e+04   NA}
\CommentTok{\#\textgreater{} Precision for box                       8.039870e+04   NA}
\end{Highlighting}
\end{Shaded}

Vemos que tanto la precisión asociada al efecto aleatorio caja (\texttt{box}), como al efecto cultivador, \texttt{grower}, son muy grandes, lo que implica varianzas muy pequeñas que posiblemente nos permita prescindir de dichos efectos aleatorios para ajustar un mejor modelo.Cuando transformamos a escala de desviaciones estándar, tenemos la distribución posterior para los tres tipo de error (en la Figura \ref{fig:brocoli2}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nombres}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\StringTok{"sigma"}\NormalTok{,}\StringTok{"grower"}\NormalTok{,}\StringTok{"box"}\NormalTok{)}
\NormalTok{sigma.post}\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]]))}
\NormalTok{sigma.grower.post }\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{2}\NormalTok{]]))}
\NormalTok{sigma.box.post }\OtherTok{=} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{3}\NormalTok{]]))}

\NormalTok{sigma}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(sigma.post,sigma.grower.post,sigma.box.post)}
\NormalTok{sigma}\SpecialCharTok{$}\NormalTok{efecto}\OtherTok{=}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"sigma"}\NormalTok{,}\StringTok{"grower"}\NormalTok{,}\StringTok{"box"}\NormalTok{),}
                 \FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(sigma.post),}\FunctionTok{nrow}\NormalTok{(sigma.grower.post),}\FunctionTok{nrow}\NormalTok{(sigma.box.post))) }

\FunctionTok{ggplot}\NormalTok{(sigma,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{efecto)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(sigma),}\AttributeTok{y=}\StringTok{"D.Posterior"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(efecto),}\AttributeTok{scales =} \StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/brocoli2-1.pdf}
\caption{\label{fig:brocoli2}Distribución posterior de la desviación típica para las tres fuentes de error: datos, caja y cultivador}
\end{figure}

No obstante, antes de tomar una decisión sobre la exclusión de los efectos aleatorios, vamos a hacer una aproximación del porcentaje de varianza explicada por cada una de estas fuentes de variación. Utilizando simulaciones de las distribuciones posteriores de \(\sigma^2, \sigma_{G}^2\) y \(\sigma_{B}^2\) vamos a calcular la contribución a la varianza del efecto cultivador, \$ \sigma\emph{\{G\}\textsuperscript{2/(\sigma}2 + \sigma}\{G\}\^{}2)\$ y la contribución a la varianza del efecto caja, \$ \sigma\emph{\{B\}\textsuperscript{2/(\sigma}2 + \sigma}\{B\}\^{}2)\$, y calcular con ellas un porcentaje promedio.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n}\OtherTok{=}\DecValTok{1000}
\NormalTok{tau}\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{inla.hyperpar.sample}\NormalTok{(n,fit,}\AttributeTok{improve.marginals=}\ConstantTok{TRUE}\NormalTok{))}
\NormalTok{sigma2}\OtherTok{=}\FunctionTok{apply}\NormalTok{(tau,}\DecValTok{2}\NormalTok{,}\ControlFlowTok{function}\NormalTok{(x) }\DecValTok{1}\SpecialCharTok{/}\NormalTok{x)}
\FunctionTok{colnames}\NormalTok{(sigma2)}\OtherTok{=}\FunctionTok{c}\NormalTok{(}\StringTok{"sigma2d"}\NormalTok{,}\StringTok{"sigma2G"}\NormalTok{,}\StringTok{"sigma2B"}\NormalTok{)}
\CommentTok{\# contribución a la varianza de grower}
\NormalTok{cG}\OtherTok{=}\NormalTok{ sigma2[,}\DecValTok{2}\NormalTok{]}\SpecialCharTok{/}\FunctionTok{apply}\NormalTok{(sigma2,}\DecValTok{1}\NormalTok{,sum)}
\CommentTok{\# contribución a la varianza de grower}
\NormalTok{cB}\OtherTok{=}\NormalTok{ sigma2[,}\DecValTok{3}\NormalTok{]}\SpecialCharTok{/}\FunctionTok{apply}\NormalTok{(sigma2,}\DecValTok{1}\NormalTok{,sum)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Contribución media de grower a la varianza:"}\NormalTok{,}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(cG)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{6}\NormalTok{),}\StringTok{"por 100"}\NormalTok{,}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{))}
\CommentTok{\#\textgreater{} Contribución media de grower a la varianza: 5.1e{-}05 por 100}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Contribución media de box a la varianza:"}\NormalTok{,}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(cB)}\SpecialCharTok{*}\DecValTok{100}\NormalTok{,}\DecValTok{6}\NormalTok{),}\StringTok{"por 100"}\NormalTok{))}
\CommentTok{\#\textgreater{} Contribución media de box a la varianza: 4.5e{-}05 por 100}
\end{Highlighting}
\end{Shaded}

Ante estos resultados, y dados los valores del DIC (307.7519675) y del WAIC (307.6586291), se justifica la opción de prescindir de los efectos \texttt{grower} y \texttt{box} como efectos aleatorios y ajustar el modelo con un único efecto fijo global.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ wt }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}
\NormalTok{fit }\OtherTok{=} \FunctionTok{inla}\NormalTok{(formula, }\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{broccoli,}
           \AttributeTok{control.compute =} \FunctionTok{list}\NormalTok{(}\AttributeTok{dic=}\ConstantTok{TRUE}\NormalTok{,}\AttributeTok{waic=}\ConstantTok{TRUE}\NormalTok{))  }
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                 mean       sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 358.1667 2.793582   352.6576 358.1667}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)   363.6758   NA 1.090747e{-}08}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                                mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.003790063}
\CommentTok{\#\textgreater{}                                                   sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.0008736111}
\CommentTok{\#\textgreater{}                                          0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.002286081}
\CommentTok{\#\textgreater{}                                            0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.003715627}
\CommentTok{\#\textgreater{}                                          0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.005654613   NA}
\end{Highlighting}
\end{Shaded}

Vemos que la variación en los indicadores DIC (308.1460381) y WAIC (307.8947917) es despreciable para este nuevo modelo.

Inferimos a continuación con las posteriores para la media global y la varianza de los datos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta.post }\OtherTok{=} \FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[}\DecValTok{1}\NormalTok{]])}
\NormalTok{sigma.post}\OtherTok{=}\FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(tau) tau}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
\NormalTok{  fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[}\DecValTok{1}\NormalTok{]]))}

\NormalTok{posterior}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(theta.post,sigma.post)}
\NormalTok{posterior}\SpecialCharTok{$}\NormalTok{efecto}\OtherTok{=}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{,}\StringTok{"sigma"}\NormalTok{),}
                     \FunctionTok{c}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(theta.post),}\FunctionTok{nrow}\NormalTok{(sigma.post)))}
\FunctionTok{ggplot}\NormalTok{(posterior,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{efecto)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{""}\NormalTok{,}\AttributeTok{y=}\StringTok{"D.Posterior"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(efecto),}\AttributeTok{scales =} \StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/unnamed-chunk-24-1.pdf}

\hypertarget{modelos-mixtos}{%
\section{Modelos mixtos}\label{modelos-mixtos}}

En ocasiones cuando ajustamos un modelo lineal tendremos algunos factores de clasificación que operan como efectos fijos y otros que operan como efectos aleatorios. Estaremos ante \textbf{modelos lineales mixtos}. Siendo estrictos, realmente el modelo con solo efectos aleatorios ya es un modelo mixto, puesto que incluye como efecto fijo una interceptación global.

En un modelo lineal mixto seguimos asumiendo una respuesta normal, \emph{gaussian}, con media igual a un predictor lineal \(\eta=X\beta + Z u\), donde \(X\) es una matriz de diseño con los efectos fijos \(x_1,x_2,...\), y \(Z\) la correspondiente para los efectos aleatorios \(z_1, z_2,...\). Se asume además una varianza desconocida que puede ser distinta para distintos niveles de los predictores, y que en general se suele expresar a través de una matriz de covarianzas \(\Sigma\), \((y|\eta,\Sigma) \sim N(\eta,\Sigma)\).

En INLA la fórmula de predicción de una respuesta \(y\) a partir de un conjunto de efectos fijos x1,x2,\ldots, y un conjunto de efectos aleatorios z1,z2,\ldots{} se especifica como:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula }\OtherTok{=}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2  }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(z1, }\AttributeTok{model=}\StringTok{""}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(z2,}\AttributeTok{model=}\StringTok{""}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

De nuevo mencionar que la opción más habitual para los efectos aleatorios en un modelo lineal es \texttt{model="iid"}.

Veamos cómo resolver las inferencias con la base de datos \texttt{penicillin} en la librería (\texttt{faraway}{]}(\url{https://cran.r-project.org/web/packages/faraway/faraway.pdf}). Se recogen datos de la producción de penicilina (\texttt{yield}) para cuatro procesos de fabricación distintos (\texttt{treat}) y con varias mezclas de la materia prima, que son bastante variables. El objetivo es investigar las diferencias entre los procesos de fabricación, pero teniendo en cuenta la variabilidad extra que podrían introducir las mezclas. Es decir, estamos pensando en un modelo lineal para predecir \texttt{yield}, en el que \texttt{treat} interviene como efecto fijo y \texttt{blend} como efecto aleatorio.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(penicillin,}\AttributeTok{package=}\StringTok{"faraway"}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{(penicillin,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{treat,}\AttributeTok{y=}\NormalTok{yield))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{blend))}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/unnamed-chunk-26-1.pdf}
Modelizamos pues con INLA:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penicillin}\SpecialCharTok{$}\NormalTok{treat }\OtherTok{=} \FunctionTok{relevel}\NormalTok{(penicillin}\SpecialCharTok{$}\NormalTok{treat,}\StringTok{"D"}\NormalTok{)}
\NormalTok{prec.prior}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{param =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.001}\NormalTok{))))}
\NormalTok{  formula }\OtherTok{=}\NormalTok{ yield }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{+}\NormalTok{ treat }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(blend,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper=}\NormalTok{prec.prior)}
\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{penicillin,}
         \AttributeTok{control.predictor=}\FunctionTok{list}\NormalTok{(}\AttributeTok{compute=}\ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{control.compute=}\FunctionTok{list}\NormalTok{(}\AttributeTok{dic=}\ConstantTok{TRUE}\NormalTok{,}\AttributeTok{waic=}\ConstantTok{TRUE}\NormalTok{))}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}            mean       sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} treatD 85.51299 2.383184   80.74987 85.53106   90.17464}
\CommentTok{\#\textgreater{} treatA 83.52432 2.383016   78.76269 83.54196   88.18683}
\CommentTok{\#\textgreater{} treatB 84.51865 2.383099   79.75628 84.53651   89.18073}
\CommentTok{\#\textgreater{} treatC 88.49600 2.383442   83.73063 88.51470   93.15637}
\CommentTok{\#\textgreater{}        mode          kld}
\CommentTok{\#\textgreater{} treatD   NA 2.457502e{-}08}
\CommentTok{\#\textgreater{} treatA   NA 2.447486e{-}08}
\CommentTok{\#\textgreater{} treatB   NA 2.452448e{-}08}
\CommentTok{\#\textgreater{} treatC   NA 2.472949e{-}08}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.random}
\CommentTok{\#\textgreater{} $blend}
\CommentTok{\#\textgreater{}       ID          mean         sd  0.025quant      0.5quant}
\CommentTok{\#\textgreater{} 1 Blend1  1.594697e{-}04 0.01274530 {-}0.02672789  8.430042e{-}05}
\CommentTok{\#\textgreater{} 2 Blend2 {-}6.276773e{-}05 0.01274325 {-}0.02736032 {-}3.324530e{-}05}
\CommentTok{\#\textgreater{} 3 Blend3 {-}1.338306e{-}05 0.01274287 {-}0.02721817 {-}7.129237e{-}06}
\CommentTok{\#\textgreater{} 4 Blend4  6.069374e{-}05 0.01274320 {-}0.02700668  3.204153e{-}05}
\CommentTok{\#\textgreater{} 5 Blend5 {-}8.746062e{-}05 0.01274361 {-}0.02743175 {-}4.630681e{-}05}
\CommentTok{\#\textgreater{}   0.975quant mode         kld}
\CommentTok{\#\textgreater{} 1 0.02764182   NA 0.009996808}
\CommentTok{\#\textgreater{} 2 0.02700140   NA 0.009959472}
\CommentTok{\#\textgreater{} 3 0.02714209   NA 0.009952884}
\CommentTok{\#\textgreater{} 4 0.02735487   NA 0.009958947}
\CommentTok{\#\textgreater{} 5 0.02693139   NA 0.009965956}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                                mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.062132647}
\CommentTok{\#\textgreater{} Precision for blend                     0.004159303}
\CommentTok{\#\textgreater{}                                                 sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.02359525}
\CommentTok{\#\textgreater{} Precision for blend                     0.02345196}
\CommentTok{\#\textgreater{}                                           0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.0263688200}
\CommentTok{\#\textgreater{} Precision for blend                     0.0000938719}
\CommentTok{\#\textgreater{}                                             0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.0587500392}
\CommentTok{\#\textgreater{} Precision for blend                     0.0008409634}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.1178322   NA}
\CommentTok{\#\textgreater{} Precision for blend                      0.0272079   NA}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{dic}\SpecialCharTok{$}\NormalTok{dic; fit}\SpecialCharTok{$}\NormalTok{waic}\SpecialCharTok{$}\NormalTok{waic}
\CommentTok{\#\textgreater{} [1] 128.3473}
\CommentTok{\#\textgreater{} [1] 131.1274}
\end{Highlighting}
\end{Shaded}

Representamos en la figura \ref{fig:penicillin2} las distribuciones posteriores de los efectos fijos y de los efectos aleatorios.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fixed}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{)\{}
\NormalTok{  fixed}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(fixed,}\FunctionTok{as.data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]]))}
\NormalTok{\}}
\NormalTok{fixed}
\CommentTok{\#\textgreater{}            x            y}
\CommentTok{\#\textgreater{} 1   74.33659 2.030611e{-}05}
\CommentTok{\#\textgreater{} 2   75.78705 1.357323e{-}04}
\CommentTok{\#\textgreater{} 3   77.62177 1.164368e{-}03}
\CommentTok{\#\textgreater{} 4   79.76863 9.779470e{-}03}
\CommentTok{\#\textgreater{} 5   80.74987 2.220118e{-}02}
\CommentTok{\#\textgreater{} 6   81.56739 4.037222e{-}02}
\CommentTok{\#\textgreater{} 7   82.48144 7.096317e{-}02}
\CommentTok{\#\textgreater{} 8   83.08280 9.613228e{-}02}
\CommentTok{\#\textgreater{} 9   83.55309 1.170101e{-}01}
\CommentTok{\#\textgreater{} 10  83.95194 1.341712e{-}01}
\CommentTok{\#\textgreater{} 11  84.30699 1.479577e{-}01}
\CommentTok{\#\textgreater{} 12  84.63378 1.585861e{-}01}
\CommentTok{\#\textgreater{} 13  84.78980 1.627630e{-}01}
\CommentTok{\#\textgreater{} 14  84.94221 1.661987e{-}01}
\CommentTok{\#\textgreater{} 15  85.09186 1.689024e{-}01}
\CommentTok{\#\textgreater{} 16  85.23944 1.708801e{-}01}
\CommentTok{\#\textgreater{} 17  85.29804 1.714690e{-}01}
\CommentTok{\#\textgreater{} 18  85.35646 1.719426e{-}01}
\CommentTok{\#\textgreater{} 19  85.38562 1.721363e{-}01}
\CommentTok{\#\textgreater{} 20  85.41475 1.723011e{-}01}
\CommentTok{\#\textgreater{} 21  85.47294 1.725445e{-}01}
\CommentTok{\#\textgreater{} 22  85.53106 1.726726e{-}01}
\CommentTok{\#\textgreater{} 23  85.58916 1.726855e{-}01}
\CommentTok{\#\textgreater{} 24  85.64728 1.725830e{-}01}
\CommentTok{\#\textgreater{} 25  85.67635 1.724884e{-}01}
\CommentTok{\#\textgreater{} 26  85.70544 1.723650e{-}01}
\CommentTok{\#\textgreater{} 27  85.76370 1.720312e{-}01}
\CommentTok{\#\textgreater{} 28  85.82210 1.715812e{-}01}
\CommentTok{\#\textgreater{} 29  85.96892 1.699456e{-}01}
\CommentTok{\#\textgreater{} 30  86.11751 1.675737e{-}01}
\CommentTok{\#\textgreater{} 31  86.26853 1.644555e{-}01}
\CommentTok{\#\textgreater{} 32  86.42280 1.605787e{-}01}
\CommentTok{\#\textgreater{} 33  86.74485 1.504805e{-}01}
\CommentTok{\#\textgreater{} 34  87.09320 1.370977e{-}01}
\CommentTok{\#\textgreater{} 35  87.48262 1.201661e{-}01}
\CommentTok{\#\textgreater{} 36  87.93938 9.927727e{-}02}
\CommentTok{\#\textgreater{} 37  88.51993 7.375585e{-}02}
\CommentTok{\#\textgreater{} 38  89.39597 4.228720e{-}02}
\CommentTok{\#\textgreater{} 39  90.17464 2.336039e{-}02}
\CommentTok{\#\textgreater{} 40  91.10584 1.031342e{-}02}
\CommentTok{\#\textgreater{} 41  93.14554 1.219365e{-}03}
\CommentTok{\#\textgreater{} 42  94.91260 1.383652e{-}04}
\CommentTok{\#\textgreater{} 43  96.40410 1.813512e{-}05}
\CommentTok{\#\textgreater{} 44  72.35137 2.027775e{-}05}
\CommentTok{\#\textgreater{} 45  73.80241 1.357513e{-}04}
\CommentTok{\#\textgreater{} 46  75.63644 1.164949e{-}03}
\CommentTok{\#\textgreater{} 47  77.78206 9.785538e{-}03}
\CommentTok{\#\textgreater{} 48  78.76269 2.221485e{-}02}
\CommentTok{\#\textgreater{} 49  79.57972 4.039563e{-}02}
\CommentTok{\#\textgreater{} 50  80.49327 7.099902e{-}02}
\CommentTok{\#\textgreater{} 51  81.09435 9.617439e{-}02}
\CommentTok{\#\textgreater{} 52  81.56445 1.170543e{-}01}
\CommentTok{\#\textgreater{} 53  81.96316 1.342144e{-}01}
\CommentTok{\#\textgreater{} 54  82.31811 1.479975e{-}01}
\CommentTok{\#\textgreater{} 55  82.64481 1.586208e{-}01}
\CommentTok{\#\textgreater{} 56  82.80080 1.627947e{-}01}
\CommentTok{\#\textgreater{} 57  82.95319 1.662271e{-}01}
\CommentTok{\#\textgreater{} 58  83.10282 1.689272e{-}01}
\CommentTok{\#\textgreater{} 59  83.25037 1.709011e{-}01}
\CommentTok{\#\textgreater{} 60  83.30897 1.714885e{-}01}
\CommentTok{\#\textgreater{} 61  83.36738 1.719605e{-}01}
\CommentTok{\#\textgreater{} 62  83.39654 1.721533e{-}01}
\CommentTok{\#\textgreater{} 63  83.42567 1.723174e{-}01}
\CommentTok{\#\textgreater{} 64  83.48386 1.725592e{-}01}
\CommentTok{\#\textgreater{} 65  83.54196 1.726857e{-}01}
\CommentTok{\#\textgreater{} 66  83.60006 1.726969e{-}01}
\CommentTok{\#\textgreater{} 67  83.65818 1.725928e{-}01}
\CommentTok{\#\textgreater{} 68  83.68725 1.724974e{-}01}
\CommentTok{\#\textgreater{} 69  83.71634 1.723731e{-}01}
\CommentTok{\#\textgreater{} 70  83.77459 1.720376e{-}01}
\CommentTok{\#\textgreater{} 71  83.83299 1.715860e{-}01}
\CommentTok{\#\textgreater{} 72  83.97981 1.699462e{-}01}
\CommentTok{\#\textgreater{} 73  84.12839 1.675703e{-}01}
\CommentTok{\#\textgreater{} 74  84.27942 1.644481e{-}01}
\CommentTok{\#\textgreater{} 75  84.43370 1.605674e{-}01}
\CommentTok{\#\textgreater{} 76  84.75578 1.504621e{-}01}
\CommentTok{\#\textgreater{} 77  85.10418 1.370733e{-}01}
\CommentTok{\#\textgreater{} 78  85.49369 1.201373e{-}01}
\CommentTok{\#\textgreater{} 79  85.95057 9.924673e{-}02}
\CommentTok{\#\textgreater{} 80  86.53132 7.372720e{-}02}
\CommentTok{\#\textgreater{} 81  87.40775 4.226638e{-}02}
\CommentTok{\#\textgreater{} 82  88.18683 2.334728e{-}02}
\CommentTok{\#\textgreater{} 83  89.11857 1.030715e{-}02}
\CommentTok{\#\textgreater{} 84  91.15952 1.218668e{-}03}
\CommentTok{\#\textgreater{} 85  92.92745 1.383207e{-}04}
\CommentTok{\#\textgreater{} 86  94.41865 1.815604e{-}05}
\CommentTok{\#\textgreater{} 87  73.34399 2.029191e{-}05}
\CommentTok{\#\textgreater{} 88  74.79474 1.357418e{-}04}
\CommentTok{\#\textgreater{} 89  76.62911 1.164659e{-}03}
\CommentTok{\#\textgreater{} 90  78.77534 9.782508e{-}03}
\CommentTok{\#\textgreater{} 91  79.75628 2.220803e{-}02}
\CommentTok{\#\textgreater{} 92  80.57356 4.038394e{-}02}
\CommentTok{\#\textgreater{} 93  81.48736 7.098113e{-}02}
\CommentTok{\#\textgreater{} 94  82.08857 9.615338e{-}02}
\CommentTok{\#\textgreater{} 95  82.55878 1.170322e{-}01}
\CommentTok{\#\textgreater{} 96  82.95755 1.341928e{-}01}
\CommentTok{\#\textgreater{} 97  83.31255 1.479777e{-}01}
\CommentTok{\#\textgreater{} 98  83.63930 1.586035e{-}01}
\CommentTok{\#\textgreater{} 99  83.79530 1.627789e{-}01}
\CommentTok{\#\textgreater{} 100 83.94770 1.662130e{-}01}
\CommentTok{\#\textgreater{} 101 84.09734 1.689149e{-}01}
\CommentTok{\#\textgreater{} 102 84.24491 1.708907e{-}01}
\CommentTok{\#\textgreater{} 103 84.30351 1.714788e{-}01}
\CommentTok{\#\textgreater{} 104 84.36192 1.719516e{-}01}
\CommentTok{\#\textgreater{} 105 84.39108 1.721449e{-}01}
\CommentTok{\#\textgreater{} 106 84.42021 1.723093e{-}01}
\CommentTok{\#\textgreater{} 107 84.47840 1.725519e{-}01}
\CommentTok{\#\textgreater{} 108 84.53651 1.726792e{-}01}
\CommentTok{\#\textgreater{} 109 84.59461 1.726913e{-}01}
\CommentTok{\#\textgreater{} 110 84.65273 1.725880e{-}01}
\CommentTok{\#\textgreater{} 111 84.68180 1.724930e{-}01}
\CommentTok{\#\textgreater{} 112 84.71089 1.723691e{-}01}
\CommentTok{\#\textgreater{} 113 84.76914 1.720345e{-}01}
\CommentTok{\#\textgreater{} 114 84.82754 1.715836e{-}01}
\CommentTok{\#\textgreater{} 115 84.97437 1.699459e{-}01}
\CommentTok{\#\textgreater{} 116 85.12295 1.675720e{-}01}
\CommentTok{\#\textgreater{} 117 85.27398 1.644519e{-}01}
\CommentTok{\#\textgreater{} 118 85.42825 1.605731e{-}01}
\CommentTok{\#\textgreater{} 119 85.75032 1.504713e{-}01}
\CommentTok{\#\textgreater{} 120 86.09869 1.370856e{-}01}
\CommentTok{\#\textgreater{} 121 86.48815 1.201518e{-}01}
\CommentTok{\#\textgreater{} 122 86.94498 9.926203e{-}02}
\CommentTok{\#\textgreater{} 123 87.52562 7.374155e{-}02}
\CommentTok{\#\textgreater{} 124 88.40186 4.227681e{-}02}
\CommentTok{\#\textgreater{} 125 89.18073 2.335384e{-}02}
\CommentTok{\#\textgreater{} 126 90.11220 1.031029e{-}02}
\CommentTok{\#\textgreater{} 127 92.15253 1.219017e{-}03}
\CommentTok{\#\textgreater{} 128 93.92002 1.383430e{-}04}
\CommentTok{\#\textgreater{} 129 95.41137 1.814556e{-}05}
\CommentTok{\#\textgreater{} 130 77.31444 2.034869e{-}05}
\CommentTok{\#\textgreater{} 131 78.76401 1.357042e{-}04}
\CommentTok{\#\textgreater{} 132 80.59977 1.163500e{-}03}
\CommentTok{\#\textgreater{} 133 82.74847 9.770391e{-}03}
\CommentTok{\#\textgreater{} 134 83.73063 2.218069e{-}02}
\CommentTok{\#\textgreater{} 135 84.54889 4.033710e{-}02}
\CommentTok{\#\textgreater{} 136 85.46368 7.090934e{-}02}
\CommentTok{\#\textgreater{} 137 86.06546 9.606897e{-}02}
\CommentTok{\#\textgreater{} 138 86.53605 1.169436e{-}01}
\CommentTok{\#\textgreater{} 139 86.93510 1.341062e{-}01}
\CommentTok{\#\textgreater{} 140 87.29031 1.478976e{-}01}
\CommentTok{\#\textgreater{} 141 87.61722 1.585336e{-}01}
\CommentTok{\#\textgreater{} 142 87.77329 1.627150e{-}01}
\CommentTok{\#\textgreater{} 143 87.92574 1.661558e{-}01}
\CommentTok{\#\textgreater{} 144 88.07543 1.688648e{-}01}
\CommentTok{\#\textgreater{} 145 88.22304 1.708482e{-}01}
\CommentTok{\#\textgreater{} 146 88.28165 1.714394e{-}01}
\CommentTok{\#\textgreater{} 147 88.34008 1.719153e{-}01}
\CommentTok{\#\textgreater{} 148 88.36924 1.721102e{-}01}
\CommentTok{\#\textgreater{} 149 88.39838 1.722762e{-}01}
\CommentTok{\#\textgreater{} 150 88.45658 1.725220e{-}01}
\CommentTok{\#\textgreater{} 151 88.51470 1.726526e{-}01}
\CommentTok{\#\textgreater{} 152 88.57281 1.726679e{-}01}
\CommentTok{\#\textgreater{} 153 88.63093 1.725679e{-}01}
\CommentTok{\#\textgreater{} 154 88.66001 1.724746e{-}01}
\CommentTok{\#\textgreater{} 155 88.68910 1.723523e{-}01}
\CommentTok{\#\textgreater{} 156 88.74736 1.720210e{-}01}
\CommentTok{\#\textgreater{} 157 88.80576 1.715735e{-}01}
\CommentTok{\#\textgreater{} 158 88.95259 1.699441e{-}01}
\CommentTok{\#\textgreater{} 159 89.10117 1.675784e{-}01}
\CommentTok{\#\textgreater{} 160 89.25219 1.644662e{-}01}
\CommentTok{\#\textgreater{} 161 89.40645 1.605952e{-}01}
\CommentTok{\#\textgreater{} 162 89.72845 1.505078e{-}01}
\CommentTok{\#\textgreater{} 163 90.07673 1.371341e{-}01}
\CommentTok{\#\textgreater{} 164 90.46603 1.202089e{-}01}
\CommentTok{\#\textgreater{} 165 90.92261 9.932285e{-}02}
\CommentTok{\#\textgreater{} 166 91.50285 7.379869e{-}02}
\CommentTok{\#\textgreater{} 167 92.37832 4.231838e{-}02}
\CommentTok{\#\textgreater{} 168 93.15637 2.338006e{-}02}
\CommentTok{\#\textgreater{} 169 94.08675 1.032285e{-}02}
\CommentTok{\#\textgreater{} 170 96.12458 1.220413e{-}03}
\CommentTok{\#\textgreater{} 171 97.89032 1.384329e{-}04}
\CommentTok{\#\textgreater{} 172 99.38228 1.810403e{-}05}
\end{Highlighting}
\end{Shaded}

Veamos cómo resolver las inferencias a través de un ejemplo disponible en \href{https://www.r-bloggers.com/2019/09/bayesian-linear-mixed-models-random-intercepts-slopes-and-missing-data/}{R-bloggers}, proporcionado por \href{https://curran.web.unc.edu/}{Patrick Curran} y descargable desde \href{https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/blob/master/chapter\%205/Curran/CurranLong.sav}{Github}. Se refieren estos datos, a un estudio con 405 niños en los dos primeros años de la escuela infantil, medidos a lo largo de cuatro instantes equidistantes (no medidos todos en todos los sujetos) para registrar su progreso en lectura y en comportamiento antisocial. Nos centramos aquí exclusivamente en intentar predecir los progresos en lectura (variable \texttt{read}) a partir de su estimulación cognitiva en casa (\texttt{homecog}), teniendo en cuenta la existencia de medidas repetidas para cada sujeto (identificado como \texttt{id}) en los 4 instantes de medición (\texttt{occasion}).

Cargamos los datos y los inspeccionamos en la Figura \ref{fig:curran1}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# librería para leer archivos .sav}
\FunctionTok{library}\NormalTok{(haven)}
\NormalTok{my.dir}\OtherTok{=}\StringTok{"\textasciitilde{}/Dropbox/ESTADISTICA/BAYESIAN/VARIOS/"}
\NormalTok{curran\_dat }\OtherTok{=} \FunctionTok{read\_sav}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(my.dir,}\StringTok{"CurranLong.sav"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(id, occasion, read, homecog) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{complete.cases}\NormalTok{(.))}
\NormalTok{curran\_dat}\SpecialCharTok{$}\NormalTok{id}\OtherTok{=}\FunctionTok{as.factor}\NormalTok{(curran\_dat}\SpecialCharTok{$}\NormalTok{id)}
\CommentTok{\# \textquotesingle{}occasion\textquotesingle{} la convertimos en factor y la preservamos como numérica en \textquotesingle{}time\textquotesingle{}}
\NormalTok{curran\_dat}\SpecialCharTok{$}\NormalTok{time}\OtherTok{=}\NormalTok{curran\_dat}\SpecialCharTok{$}\NormalTok{occasion}
\NormalTok{curran\_dat}\SpecialCharTok{$}\NormalTok{occasion}\OtherTok{=}\FunctionTok{as.factor}\NormalTok{(curran\_dat}\SpecialCharTok{$}\NormalTok{occasion)}
\CommentTok{\# Relaciones}
\NormalTok{g1}\OtherTok{=}\FunctionTok{ggplot}\NormalTok{(curran\_dat, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{occasion,}\AttributeTok{y=}\NormalTok{read))}\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}
\NormalTok{g2}\OtherTok{=}\FunctionTok{ggplot}\NormalTok{(curran\_dat, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{homecog,}\AttributeTok{y=}\NormalTok{read))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(occasion))}
\FunctionTok{grid.arrange}\NormalTok{(g1,g2,}\AttributeTok{ncol=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/curran1-1.pdf}
\caption{\label{fig:curran1}Descripción de la BD CurranLong sobre desarrollo de las habilidades lectoras en niños.}
\end{figure}

Como base vamos a asumir normalidad en la respuesta de un sujeto \(i\) en un instante \(j\), y plantear un modelo lineal para obtener nuestras conclusiones.
\[( y_{ij}|\eta_{ij},\sigma^2 ) \sim N(\eta_{ij},\sigma^2);  \ i=1,...,450; j=1,2,3,4\]

A continuación, planteamos distintas alternativas de modelización que dan lugar a diversos predictores lineales. En los primeros modelos prescindimos de momento del efecto de la estimulación cognitiva.

\textbf{M0}. Solo estamos interesados en cuantificar el nivel general de habilidades lectoras, pero teniendo en cuenta posibles diferencias entre los niños. No nos interesan sin embargo, dichas diferencias. Pensamos pues en utilizar la variable \texttt{id} como efecto aleatorio y modelizar
\[\eta_{ij}=\eta_i=\theta + \alpha_i^{id}\]
con \(\alpha_i^{id} \sim N(0,\sigma_{\alpha}^2)\) y a priori \(\tau_{\alpha} \sim Ga(0.001,0.001)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec.prior}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{,}\FloatTok{0.001}\NormalTok{)))}
\NormalTok{formula0}\OtherTok{=}\NormalTok{ read }\SpecialCharTok{\textasciitilde{}} \FunctionTok{f}\NormalTok{(id,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper =}\NormalTok{ prec.prior) }
\NormalTok{fit0}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula0,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{curran\_dat)}
\NormalTok{fit}\OtherTok{=}\NormalTok{fit0}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                 mean         sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 4.114053 0.05109346   4.013248 4.114248}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)   4.213757   NA 1.440195e{-}09}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                              mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.4181767}
\CommentTok{\#\textgreater{} Precision for id                        3.7355177}
\CommentTok{\#\textgreater{}                                                 sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.01924267}
\CommentTok{\#\textgreater{} Precision for id                        1.07498923}
\CommentTok{\#\textgreater{}                                         0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.3809534}
\CommentTok{\#\textgreater{} Precision for id                         2.1867716}
\CommentTok{\#\textgreater{}                                          0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.4179702}
\CommentTok{\#\textgreater{} Precision for id                        3.5464628}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.4567565   NA}
\CommentTok{\#\textgreater{} Precision for id                         6.3647887   NA}

\NormalTok{nfixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed))}
\NormalTok{nhyp}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar))}
\NormalTok{res}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nfixed)\{}
\NormalTok{res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)[i],}
                          \AttributeTok{tipo=}\StringTok{"fixed"}\NormalTok{))}
\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nhyp)\{}
\NormalTok{  res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[j]],}
                           \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar)[j],}
                            \AttributeTok{tipo=}\StringTok{"prec"}\NormalTok{))}
\NormalTok{\}}
\FunctionTok{ggplot}\NormalTok{(res,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{id))}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(tipo),}\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position=}\StringTok{"top"}\NormalTok{,}
        \AttributeTok{legend.title=}\FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/curranm0-1.pdf}

La matriz de diseño \(Z\) asociada a los efectos aleatorios se obtiene con la función \texttt{model.matrix}, y la podemos utilizar para ajustar el modelo con \texttt{inla}. Para ello habremos de definir un nuevo índice para todos los registros de la base de datos, y aplicar sobre ellos la matriz de efectos aleatorios:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Z }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}\FunctionTok{model.matrix}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ id, }\AttributeTok{data =}\NormalTok{ curran\_dat), }\StringTok{"Matrix"}\NormalTok{)}
\CommentTok{\# índice nuevo}
\NormalTok{ID}\OtherTok{=}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(curran\_dat)}
\NormalTok{formula00}\OtherTok{=}\NormalTok{ read }\SpecialCharTok{\textasciitilde{}} \FunctionTok{f}\NormalTok{(ID,}\AttributeTok{model=}\StringTok{"z"}\NormalTok{,}\AttributeTok{Z=}\NormalTok{Z,}\AttributeTok{hyper =}\NormalTok{ prec.prior) }
\NormalTok{fit00}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula00,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{curran\_dat)}
\CommentTok{\#\textgreater{} Warning in inla.model.properties.generic(inla.trim.family(model), mm[names(mm) == : Model \textquotesingle{}z\textquotesingle{} in section \textquotesingle{}latent\textquotesingle{} is marked as \textquotesingle{}experimental\textquotesingle{}; changes may appear at any time.}
\CommentTok{\#\textgreater{}   Use this model with extra care!!! Further warnings are disabled.}
\NormalTok{fit00}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                              mean}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.4182615}
\CommentTok{\#\textgreater{} Precision for ID                        3.7319300}
\CommentTok{\#\textgreater{}                                                 sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.01928087}
\CommentTok{\#\textgreater{} Precision for ID                        1.07622200}
\CommentTok{\#\textgreater{}                                         0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.3809454}
\CommentTok{\#\textgreater{} Precision for ID                         2.1865180}
\CommentTok{\#\textgreater{}                                          0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 0.4180623}
\CommentTok{\#\textgreater{} Precision for ID                        3.5410230}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  0.4568972   NA}
\CommentTok{\#\textgreater{} Precision for ID                         6.3675389   NA}
\end{Highlighting}
\end{Shaded}

La diferencia entre ajustar los efectos aleatorios con ``iid'' o con ``z'' es que con la primera opción tendremos tantos efectos aleatorios como están definidos en el modelo. Sin embargo, la modelización con ``z'' producirá tantos efectos aleatorios como datos, con una única precisión/varianza asociada. Generalmente ambos modelos producen unas medias posterioris de los efectos aleatorios bastante parecidas.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# medias posteriori de los efectos aleatorias con model="iid"}
\NormalTok{random0}\OtherTok{=}\NormalTok{fit0}\SpecialCharTok{$}\NormalTok{summary.random}\SpecialCharTok{$}\NormalTok{id}\SpecialCharTok{$}\NormalTok{mean}
\CommentTok{\# medias posteriori de los efectos aleatorios con model="z"}
\NormalTok{random00}\OtherTok{=}\NormalTok{fit00}\SpecialCharTok{$}\NormalTok{summary.random}\SpecialCharTok{$}\NormalTok{ID}\SpecialCharTok{$}\NormalTok{mean}
\FunctionTok{plot}\NormalTok{(random00,random00,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{)}
\FunctionTok{points}\NormalTok{(random0,random0)}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/curranm0b-1.pdf}

\textbf{M1}. Dado que tenemos varias mediciones de un mismo sujeto, es razonable asumir que, por defecto, las habilidades cognitivas propias de un sujeto, \(\alpha_i^{id}\), influyen en sus habilidades lectoras.

\[\eta_{ij}=\theta + \alpha_i^{id}\]

Además, es de esperar que el tiempo que transcurre afecte de modo similar a la evolución de todos los sujetos (en la Figura \ref{fig:curran1} se apreciaba cierto crecimiento). Hablamos pues de un modelo en el que predecimos las habilidades lectoras con un efecto fijo común \(\theta\) afectado de cierta variación extra en función del sujeto \(i\) y del instante de medición \(j\).

\[\eta_{ij}=\theta + \alpha_i^{id} + \beta_j^{oc}\]
Si no nos interesa evaluar las habilidades cognitivas propias de cada sujeto, pero queremos reconocer de algún modo la variabilidad entre sujetos, \(\sigma_{\alpha}^2\), estamos pensando en unos efectos aleatorios para el sujeto, \texttt{id}, \(\alpha_i^{id} \sim N(0,\sigma_{\alpha}^2)\).

Si no nos interesa evaluar el efecto del tiempo sobre las habilidades lectoras, pero queremos reconocer la variabilidad entre los distintos periodos de tiempo, \(\sigma_{\beta}^2\), estamos pensando en unos efectos aleatorios asociados al tiempo, \texttt{occasion}, \(\beta_i^{oc} \sim N(0,\sigma_{\beta}^2)\).

Si asumimos una prior para las precisiones \(\tau_{\alpha}\) y \(\tau_{\beta}\) de media 1 y varianza 1000, podemos usar una \(Ga(0.001,0.001)\).

con
\begin{eqnarray*}
\text{Nivel II} && \\
\theta &\sim & N(0,100) \\
\alpha_i^{id} &\sim& N(0,\sigma_{\alpha}^2) \\
\beta_j^{oc} &\sim& N(0,\sigma_{\beta}) \\
\text{Nivel III} && \\
\tau_{\alpha}=1/\sigma_{\alpha}^2 &\sim& Ga(0.001,0.001) \\
\tau_{\beta}=1/\sigma_{\beta}^2 &\sim&Ga(0.001,0.001)
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec.prior}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{,}\FloatTok{0.001}\NormalTok{)))}
\NormalTok{formula1}\OtherTok{=}\NormalTok{ read }\SpecialCharTok{\textasciitilde{}} \FunctionTok{f}\NormalTok{(id,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper =}\NormalTok{ prec.prior) }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(occasion,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper =}\NormalTok{ prec.prior)}
\NormalTok{fit1}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula1,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{curran\_dat)}
\NormalTok{fit}\OtherTok{=}\NormalTok{fit1}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                 mean       sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 4.353434 0.889756    2.47961 4.353368}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)   6.227631   NA 0.0002595765}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                              mean        sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 2.4595751 0.1147768}
\CommentTok{\#\textgreater{} Precision for id                        1.2681469 0.1053370}
\CommentTok{\#\textgreater{} Precision for occasion                  0.4871471 0.3919959}
\CommentTok{\#\textgreater{}                                         0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 2.23998977}
\CommentTok{\#\textgreater{} Precision for id                        1.07269487}
\CommentTok{\#\textgreater{} Precision for occasion                  0.05849255}
\CommentTok{\#\textgreater{}                                          0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 2.4573888}
\CommentTok{\#\textgreater{} Precision for id                        1.2640450}
\CommentTok{\#\textgreater{} Precision for occasion                  0.3835039}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   2.692123   NA}
\CommentTok{\#\textgreater{} Precision for id                          1.487437   NA}
\CommentTok{\#\textgreater{} Precision for occasion                    1.509043   NA}

\NormalTok{nfixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed))}
\NormalTok{nhyp}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar))}
\NormalTok{res}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nfixed)\{}
\NormalTok{res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)[i],}
                          \AttributeTok{tipo=}\StringTok{"fixed"}\NormalTok{))}
\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nhyp)\{}
\NormalTok{  res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[j]],}
                           \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar)[j],}
                            \AttributeTok{tipo=}\StringTok{"prec"}\NormalTok{))}
\NormalTok{\}}
\FunctionTok{ggplot}\NormalTok{(res,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{id))}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(tipo),}\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position=}\StringTok{"top"}\NormalTok{,}
        \AttributeTok{legend.title=}\FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/curran2-1.pdf}

\begin{itemize}
\tightlist
\item
  \textbf{M2}. Por otro lado, y en base a la Figura \ref{fig:curran3} podríamos considerar el efecto del tiempo que transcurre desde el inicio del estudio (\texttt{t=time}), como una covariable numérica que afecta de modo lineal a las habilidades lectoras.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(curran\_dat, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{occasion,}\AttributeTok{y=}\NormalTok{read))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{group=}\NormalTok{id),}\AttributeTok{color=}\StringTok{"grey"}\NormalTok{,}\AttributeTok{size=}\FloatTok{0.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{02-anova_files/figure-latex/curran3-1.pdf}
\caption{\label{fig:curran3}Relación entre el tiempo y las habilidades lectoras para cada sujeto (líneas).}
\end{figure}

Podríamos seguir planteando un efecto aleatorio del sujeto sobre sus resultados lectores, y un efecto fijo asociado al tiempo transcurrido hasta el instante \(t_j=j\), esto es, una interceptación aleatoria y una pendiente fija.

\[\eta_{ij}=\theta + \alpha_i^{id} + \beta \cdot t_j \]
con
\begin{eqnarray*}
\text{Nivel II} && \\
\theta &\sim & N(0,100) \\
\beta &\sim& N(0,100) \\
\alpha_i^{id} &\sim& N(0,\sigma_{\alpha}^2) \\
\text{Nivel III} && \\
\tau_{\alpha}=1/\sigma_{\alpha}^2 &\sim& Ga(0.001,0.001) 
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec.prior}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{,}\FloatTok{0.001}\NormalTok{)))}
\NormalTok{formula2}\OtherTok{=}\NormalTok{ read }\SpecialCharTok{\textasciitilde{}}\NormalTok{ time }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(id,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper =}\NormalTok{ prec.prior) }
\NormalTok{fit2}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula2,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{curran\_dat)}
\NormalTok{fit}\OtherTok{=}\NormalTok{fit2}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                 mean         sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 2.703744 0.05265826   2.600420 2.703750}
\CommentTok{\#\textgreater{} time        1.101341 0.01758962   1.066827 1.101345}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)   2.807034   NA 1.185142e{-}11}
\CommentTok{\#\textgreater{} time          1.135834   NA 5.561966e{-}12}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                             mean        sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations 2.174407 0.1013782}
\CommentTok{\#\textgreater{} Precision for id                        1.285604 0.1091225}
\CommentTok{\#\textgreater{}                                         0.025quant 0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   1.980419 2.172490}
\CommentTok{\#\textgreater{} Precision for id                          1.083308 1.281299}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   2.379770   NA}
\CommentTok{\#\textgreater{} Precision for id                          1.512947   NA}

\NormalTok{nfixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed))}
\NormalTok{nhyp}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar))}
\NormalTok{res}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nfixed)\{}
\NormalTok{res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)[i],}
                          \AttributeTok{tipo=}\StringTok{"fixed"}\NormalTok{))}
\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nhyp)\{}
\NormalTok{  res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[j]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar)[j],}
                          \AttributeTok{tipo=}\StringTok{"prec"}\NormalTok{))}
\NormalTok{\}}
\FunctionTok{ggplot}\NormalTok{(res,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{id))}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(tipo),}\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position=}\StringTok{"top"}\NormalTok{,}
        \AttributeTok{legend.title=}\FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/curran4-1.pdf}

\begin{itemize}
\tightlist
\item
  \textbf{M3}. Siendo más estrictos al mirar la Figura \ref{fig:curran3}, podríamos pensar que, además de tener diferentes orígenes en las habilidades lectoras para cada sujeto (interceptaciones distintas), dado el efecto lineal ascendente del tiempo sobre las habilidades lectoras de los sujetos, no todos los sujetos evolucionan al mismo ritmo, esto es, no todas las rectas son paralelas. Tendríamos entonces efectos aleatorios asociados a los sujetos, y vinculados a las interceptaciones y a las pendientes de las rectas.
\end{itemize}

\[\eta_{ij}=\theta + \alpha_i^{id} + \beta \cdot t_j + \beta_{ij}\]

con
\begin{eqnarray*}
\text{Nivel II} && \\
\theta &\sim & N(0,100) \\
\beta &\sim& N(0,100) \\
\alpha_i^{id} &\sim& N(0,\sigma_{\alpha}^2) \\
\beta_{ij} &\sim & N(0,\sigma_{j})^2 \\
\text{Nivel III} && \\
\tau_{\alpha}=1/\sigma_{\alpha}^2 &\sim& Ga(0.001,0.001) \\
\tau_{j}=1/\sigma_{j}^2 &\sim&Ga(0.001,0.001)
\end{eqnarray*}

Además, dado que no disponemos de todas las mediciones temporales para todos los sujetos, tendremos que la variable tiempo (\texttt{time}) está anidada en la variable \texttt{id}. Este efecto de anidación que nos va a reportar la variabilidad que hay entre las pendientes distintas de los sujetos para cada instante de tiempo.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec.prior}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{prec=}\FunctionTok{list}\NormalTok{(}\AttributeTok{param=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{,}\FloatTok{0.001}\NormalTok{)))}
\NormalTok{Z }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}\FunctionTok{model.matrix}\NormalTok{( }\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ id}\SpecialCharTok{:}\NormalTok{time, }\AttributeTok{data =}\NormalTok{ curran\_dat), }\StringTok{"Matrix"}\NormalTok{)}
\NormalTok{ID}\OtherTok{=}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(curran\_dat)}
\NormalTok{formula3}\OtherTok{=}\NormalTok{ read }\SpecialCharTok{\textasciitilde{}}\NormalTok{ time }\SpecialCharTok{+} \FunctionTok{f}\NormalTok{(id,}\AttributeTok{model=}\StringTok{"iid"}\NormalTok{,}\AttributeTok{hyper=}\NormalTok{prec.prior)}\SpecialCharTok{+}
                        \FunctionTok{f}\NormalTok{(ID,}\AttributeTok{model=}\StringTok{"z"}\NormalTok{,}\AttributeTok{Z=}\NormalTok{Z,}\AttributeTok{hyper =}\NormalTok{ prec.prior) }
\NormalTok{fit3}\OtherTok{=}\FunctionTok{inla}\NormalTok{(formula3,}\AttributeTok{family=}\StringTok{"gaussian"}\NormalTok{,}\AttributeTok{data=}\NormalTok{curran\_dat)}
\NormalTok{fit}\OtherTok{=}\NormalTok{fit3}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.fixed}
\CommentTok{\#\textgreater{}                 mean         sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept) 2.695707 0.04697528   2.603547 2.695705}
\CommentTok{\#\textgreater{} time        1.120191 0.02267335   1.075918 1.120114}
\CommentTok{\#\textgreater{}             0.975quant mode          kld}
\CommentTok{\#\textgreater{} (Intercept)   2.787883   NA 3.994798e{-}11}
\CommentTok{\#\textgreater{} time          1.164903   NA 1.193638e{-}09}
\NormalTok{fit}\SpecialCharTok{$}\NormalTok{summary.hyperpar}
\CommentTok{\#\textgreater{}                                              mean        sd}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  3.016271 0.1690637}
\CommentTok{\#\textgreater{} Precision for id                         1.565002 0.1432518}
\CommentTok{\#\textgreater{} Precision for ID                        11.393950 1.7120438}
\CommentTok{\#\textgreater{}                                         0.025quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   2.695117}
\CommentTok{\#\textgreater{} Precision for id                          1.301779}
\CommentTok{\#\textgreater{} Precision for ID                          8.461430}
\CommentTok{\#\textgreater{}                                          0.5quant}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations  3.012269}
\CommentTok{\#\textgreater{} Precision for id                         1.558507}
\CommentTok{\#\textgreater{} Precision for ID                        11.241642}
\CommentTok{\#\textgreater{}                                         0.975quant mode}
\CommentTok{\#\textgreater{} Precision for the Gaussian observations   3.361027   NA}
\CommentTok{\#\textgreater{} Precision for id                          1.865692   NA}
\CommentTok{\#\textgreater{} Precision for ID                         15.189679   NA}

\NormalTok{nfixed}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed))}
\NormalTok{nhyp}\OtherTok{=}\FunctionTok{length}\NormalTok{(}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar))}
\NormalTok{res}\OtherTok{=}\ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nfixed)\{}
\NormalTok{res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed[[i]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.fixed)[i],}
                          \AttributeTok{tipo=}\StringTok{"fixed"}\NormalTok{))}
\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nhyp)\{}
\NormalTok{  res}\OtherTok{=}\FunctionTok{rbind}\NormalTok{(res,}\FunctionTok{data.frame}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar[[j]],}
                         \AttributeTok{id=}\FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{marginals.hyperpar)[j],}
                          \AttributeTok{tipo=}\StringTok{"prec"}\NormalTok{))}
\NormalTok{\}}
\FunctionTok{ggplot}\NormalTok{(res,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color=}\NormalTok{id))}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(tipo),}\AttributeTok{scales=}\StringTok{"free"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position=}\StringTok{"top"}\NormalTok{,}
        \AttributeTok{legend.title=}\FunctionTok{element\_blank}\NormalTok{(),}
        \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size=}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{02-anova_files/figure-latex/curran5-1.pdf}

\hypertarget{glm}{%
\chapter{Modelos lineales generalizados}\label{glm}}

Los modelos lineales generalizados (Generalized Linear Models or GLM), son una clase de modelos introducidos por Nelder y Wedderburn (1972) y McCullagh y Nelder (1989), con el objetivo de extender la regresión lineal al caso en el que la variable dependiente no se distribuye necesariamente según una normal, pero su distribución todavía pertenece a la familia exponencial. Trabajamos a continuación con dos de los GLM más comunes en epidemiología y ciencias sociales: la regresión logística y la de Poisson, mostrando cómo usar R-INLA.

Un modelo lineal general (MLG) está basado en asumir una relación lineal entre cierta transformación del valor esperado de la respuesta \(E(y_i)\) y los predictores disponibles, sean covariables, efectos fijos, efectos aleatorios, o incluso alguna función de estos.

Si \(y\) representa una respuesta observada, \(x_1,x_2,..\) una serie de covariables o efectos fijos, y \(z_1,z_2,...\) efectos aleatorios, el modelo lineal general asume cierto modelo probabilístico para \(y\) dentro de la familia Gausiana, dependiente de los predictores y ciertos parámetros desconocidos \(\theta\), que se especifica en un primer nivel de la modelización.

\[E(y_i|x,z,\theta)=\gamma_i=g(\eta_i)\]

\(\theta\) engloba todos los parámetros de la distribución de los datos, esto es, los involucrados en el predictor lineal, pero también otros como por ejemplo la varianza \(\sigma^2\) del modelo normal.

El predictor lineal \(\eta\) está relacionado linealmente con los predictores según:
\[\eta_i=\mu + \beta_1 x_{1i} +   \beta_2 x_{2i} +...+ z_{1i} + z_{2i}+...\]
relación que se suele representar en forma matricial como
\[\eta=X\beta + Z u\]
Los modelos lineales que conocemos (regresión, anova, ancova, glm,modelos mixtos, aditivos,\ldots) se engloban dentro del modelo lineal general.

Para obtener la distribución marginal de los valores ajustados y predichos necesitamos incorporar a la función \texttt{inla} el argumento \texttt{control.compute=list(return.marginals.predictor=TRUE)}
El argumento \texttt{control.predictor=list(compute=TRUE)} en la función \texttt{inla} permite obtener las distribuciones predictivas para el predictor lineal, que en estos casos es distinto a los valores ajustados, \texttt{fit\$summary.fitted}. Además:

\begin{itemize}
\tightlist
\item
  \texttt{fit\$summary.linear.predictor} resume la inferencia posterior sobre los
  predictores lineales (distintos a los fitted cuando hay una función \emph{link})
\item
  \texttt{fit\$marginals.linear.predictor} da las distribuciones posteriores marginales para los predictores lineales
\end{itemize}

\hypertarget{modelos-jeruxe1rquicos-bayesianos}{%
\subsection{Modelos jerárquicos bayesianos}\label{modelos-jeruxe1rquicos-bayesianos}}

Un modelo bayesiano se modeliza a través de un modelo jerárquico en el que en el nivel 1 se define la distribución asumida sobre la variable respuesta y que determina la verosimilitud. Esta variable depende de unos parámetros que definen los efectos fijos y aleatorios, y para los que hay que proporcionar la información previa disponible a través de una distribución a priori en el segundo nivel del modelo jerárquico. La distribución a priori para los efectos fijos generalmente será común a todos ellos, mientras que la distribución a priori para los efectos aleatorios estará vinculada a otros hiperparámetros para los que también será preciso especificar una distribución a priori en un tercer nivel de la modelización.

El argumento \texttt{control.predictor=list(compute=TRUE)} en la función \texttt{inla} permite obtener las distribuciones predictivas para el predictor lineal. Así para el modelo anterior tendremos

\begin{eqnarray*}
(I)& y | X, Z, \theta &\sim f(y|x,z,\theta) \\
&& E(y_i|x,z,\theta)=\gamma_i=g(\eta_i) \\
&& \eta=X\beta + Z u \\
(II)&  \beta &\sim N(0,\sigma_{\beta}), \text{ con un valor dado  para } \sigma_{\beta} \\
&& u_i|\mu,\sigma \sim_{iid}  N(\mu,{\sigma}) \\
(III)& \mu  &\sim N(0,\sigma_{\mu}), \text{ con un valor dado  para } \sigma_{\mu} \\
&& \sigma \sim  GaI(\alpha_{\sigma},\beta_{\sigma}), \text{ con un valor dado  para }\alpha_{\sigma} y \beta_{\sigma}.
\end{eqnarray*}

\hypertarget{regresiuxf3n-loguxedstica}{%
\section{Regresión logística}\label{regresiuxf3n-loguxedstica}}

La regresión logística es el modelo estándar para respuestas binarias (éxitos/fracasos). Tiene dos variaciones, en función de si la respuesta representa observaciones individuales (0/1) o conteos (de éxitos) en grupos de sujetos.
Si las observaciones son individualizadas, entonces
\[y_1,...,y_n \sim Ber(\pi_i), \ i=1,...,n\]
En el caso de que sean conteos en grupos,
\[y_1,...,y_n \sim Bin(n_i,\pi_i), \ i=1,...,n\]
siendo \(n_i\) el tamaño de cada uno de los \(n\) grupos disponibles, y \(\pi_i\) la probabilidad de éxito (output de interés).

La relación entre el predictor lineal \(\eta_i\) construido con los predictores disponibles \(x_i=(x_{i1},...x_{iM})\) y la probabilidad \(\pi_i\) se especifica a través de la función \emph{logit}:
\[\eta_i=logit(\pi_i)=log\left(\frac{\pi_i}{1-\pi_i}\right)=x_i\beta=\beta_0+\sum_{m=1}^M \beta_mx_{im}\]
de forma que
\[\pi_i=logit^{-1}(x_i\beta)=\frac{exp(x_i\beta)}{1-exp(x_i\beta)}\]
Una vez especificado el modelo, si no hay información previa disponible sobre los efectos (fijos) \({\beta_o,\beta_1,...\beta_M}\), se asumen distribuciones a priori independientes y normales con media cero y varianza muy grande.

\hypertarget{interpretaciuxf3n-de-los-coeficientes-en-la-regresiuxf3n-logit}{%
\subsection{Interpretación de los coeficientes en la regresión logit}\label{interpretaciuxf3n-de-los-coeficientes-en-la-regresiuxf3n-logit}}

Puesto que \(x_i\beta=\beta_0+\sum_{m=1}^M \beta_mx_{im}\),
- cuando todas las \(x\) son categóricas y su valor coincide con el nivel de referencias
- o cuando las \(x\) son continuas y su valor es cero,
el valor del predictor lineal \(\eta_i=\beta_0=logit(\pi_i)\). En consecuencia, el logit inverso de \(\beta_0\) se interpreta como la probabilidad de éxito \(\pi_i\) cuando los predictores están en su nivel de referencia o son cero.
\[logit^{-1}(\beta_0)=Pr(y=1|x=0).\]

En cuanto a la interpretación de cualquier coeficiente de regresión, como \(\beta_1\), echamos mano del concepto de odds y odds ratio. Los odds ratio, OR, representan el cociente de las posibilidades a favor de un evento \(E\) bajo condiciones A y de las posibilidades del mismo evento bajo condiciones B. Nos sirve para evaluar cuánto afecta a dicho evento el hecho de variar las condiciones de B a A.
\[OR(A,B)=\frac{Pr(E|A)/(1-Pr(E|A))}{Pr(E|B)/(1-Pr(E|B))}.\]

En el modelo logístico, nos interesa saber el efecto que tiene sobre la respuesta (sobre las probabilidad de éxito en este caso) el incremento de una unidad en la variable \(x\), y para ello consideramos los odds bajo \(x\) y los odds bajo \(x+1\), y en particular el logaritmo de los odds, log-odds:
\[log.odds(x+1)=\frac{P(y=1|x+1)}{P(y=0|x+1)}=\beta_0+\beta_1 (x+1)\]
\[log.odds(x)=\frac{P(y=1|x)}{P(y=0|x)}=\beta_0+\beta_1 x\]
de modo que
\[log.ods (x+1)/x = \beta_1 \rightarrow exp(\beta_1)=\frac{odds(x+1)}{odds(x)}=OR(x+1,x).\]
Así \(\beta_1\) representa el cambio en los odds a favor de un éxito cuando se incrementa en una unidad el predictor \(x\) al que acompaña en el predictor lineal. Esta interpretación es muy común en Epidemiología.

\hypertarget{ejemplo-modelo-logit.-mortalidad-por-infarto-en-sheffield.}{%
\section{Ejemplo modelo logit. Mortalidad por infarto en Sheffield.}\label{ejemplo-modelo-logit.-mortalidad-por-infarto-en-sheffield.}}

Utilizamos los datos \emph{stroke}, disponibles en \href{https://sites.google.com/a/r-inla.org/stbook/datasets}{datasets in SSTM-RINLA}. Queremos evaluar la presencia de cierta asociación entre los niveles de NOx y el infarto en Sheffield, UK. Se dispone de la concentración anual de NOx medida en \(\mu g/m^3\) y categorizada en quintiles, promediada durante el periodo 1994-1999, en la variable \emph{NOx.class} y su análoga \(NOx\), y el número de muertes por infarto \(y\) en cada distrito identificado por el índice de desventajas y privación \emph{Townsend} (categorizado en quintiles). Se dispone igualmente del tamaño de la población para cada registro, en la variable \(pop\). La respuesta \(y\) se puede considerar entonces como conteos (de muertes) sobre la población de cada distrito,
\[y_i|\pi_i \sim Bin(n_i, \pi_i)\]
y el predictor lineal es función del nivel de NOx y del distrito:
\[\eta_i=logit(\pi_i)=\beta_0 + \sum_{k=2}^5 \beta_{1k} I(NOx_i=k)+ \sum_{h=2}^5 \beta_{2h} I(Townsend_i=h)+logit(\tilde{p_i})\]
siendo \(n_i\) la población (número total de habitantes) del distrito en el que se ubica el registro \(i\) (disponible en la variable \(pop\)). El término \(\tilde{p_i}\) representa el resgo ajustado por sexo y edad de la mortalidad por infarto, calculada utilizando estandarización indirecta con ratios de referencia internos basados en 18 estratos (9 para edad y 2 para género), y que se usa como un riesgo base en el modelo (Maheswaran et al.2006). En el ejemplo se calcula como el ratio de la mortalidad dividido por la población de cada registro.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.dir}\OtherTok{=}\StringTok{"\textasciitilde{}/Dropbox/ESTADISTICA/BAYESIAN/VARIOS/"}
\NormalTok{Stroke }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(my.dir,}\StringTok{"Stroke.csv"}\NormalTok{),}\AttributeTok{sep=}\StringTok{","}\NormalTok{,}\AttributeTok{dec=}\StringTok{"."}\NormalTok{,}\AttributeTok{header=}\ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#riesgo base: ajuste por tamaño de la población}
\NormalTok{Stroke}\SpecialCharTok{$}\NormalTok{Adjusted.prob }\OtherTok{\textless{}{-}}\NormalTok{ Stroke}\SpecialCharTok{$}\NormalTok{stroke\_exp}\SpecialCharTok{/}\NormalTok{Stroke}\SpecialCharTok{$}\NormalTok{pop}
\CommentTok{\# logit del riesgo base}
\NormalTok{Stroke}\SpecialCharTok{$}\NormalTok{logit.adjusted.prob }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(Stroke}\SpecialCharTok{$}\NormalTok{Adjusted.prob}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{Stroke}\SpecialCharTok{$}\NormalTok{Adjusted.prob))                          }
\end{Highlighting}
\end{Shaded}

Ajustamos ya el modelo, en el que las variables NOx y Townsend actúan como factores (efectos fijos) y el riesgo base se introduce como offset, para estandarizar los riesgos en función del tamaño de la población y poder equiparar así todos los distritos:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{formula.inla }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(NOx) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(Townsend) }\SpecialCharTok{+} \FunctionTok{offset}\NormalTok{(logit.adjusted.prob)}
\NormalTok{model.logistic }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula.inla, }\AttributeTok{family=}\StringTok{"binomial"}\NormalTok{, }\AttributeTok{Ntrials=}\NormalTok{pop, }\AttributeTok{data=}\NormalTok{Stroke)}
\FunctionTok{round}\NormalTok{(model.logistic}\SpecialCharTok{$}\NormalTok{summary.fixed[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{],}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}                     mean    sd 0.025quant 0.5quant}
\CommentTok{\#\textgreater{} (Intercept)       {-}0.181 0.057     {-}0.293   {-}0.180}
\CommentTok{\#\textgreater{} factor(NOx)2       0.132 0.059      0.016    0.132}
\CommentTok{\#\textgreater{} factor(NOx)3       0.105 0.061     {-}0.014    0.105}
\CommentTok{\#\textgreater{} factor(NOx)4       0.261 0.059      0.144    0.260}
\CommentTok{\#\textgreater{} factor(NOx)5       0.425 0.062      0.302    0.425}
\CommentTok{\#\textgreater{} factor(Townsend)2  0.077 0.061     {-}0.043    0.077}
\CommentTok{\#\textgreater{} factor(Townsend)3  0.137 0.060      0.020    0.137}
\CommentTok{\#\textgreater{} factor(Townsend)4 {-}0.132 0.063     {-}0.255   {-}0.132}
\CommentTok{\#\textgreater{} factor(Townsend)5 {-}0.118 0.067     {-}0.250   {-}0.118}
\CommentTok{\#\textgreater{}                   0.975quant}
\CommentTok{\#\textgreater{} (Intercept)           {-}0.071}
\CommentTok{\#\textgreater{} factor(NOx)2           0.248}
\CommentTok{\#\textgreater{} factor(NOx)3           0.225}
\CommentTok{\#\textgreater{} factor(NOx)4           0.377}
\CommentTok{\#\textgreater{} factor(NOx)5           0.547}
\CommentTok{\#\textgreater{} factor(Townsend)2      0.198}
\CommentTok{\#\textgreater{} factor(Townsend)3      0.255}
\CommentTok{\#\textgreater{} factor(Townsend)4     {-}0.009}
\CommentTok{\#\textgreater{} factor(Townsend)5      0.014}
\end{Highlighting}
\end{Shaded}

Para obtener la probabilidad promedio de muerte por infarto en el distrito Townsend=1 y para el nivel NOx=1, que son los niveles base, nos apoyamos en la interceptación \(\beta_0\). Sobre sus simulaciones será preciso deshacer el logit (con la función logit-inversa):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob.stroke }\OtherTok{\textless{}{-}} \FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{exp}\NormalTok{(x)}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{+}\FunctionTok{exp}\NormalTok{(x)), model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed[[}\DecValTok{1}\NormalTok{]])}
\FunctionTok{inla.zmarginal}\NormalTok{(prob.stroke)}
\CommentTok{\#\textgreater{} Mean            0.455034 }
\CommentTok{\#\textgreater{} Stdev           0.0139168 }
\CommentTok{\#\textgreater{} Quantile  0.025 0.427486 }
\CommentTok{\#\textgreater{} Quantile  0.25  0.445615 }
\CommentTok{\#\textgreater{} Quantile  0.5   0.455082 }
\CommentTok{\#\textgreater{} Quantile  0.75  0.464485 }
\CommentTok{\#\textgreater{} Quantile  0.975 0.482137}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(prob.stroke),}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}\FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
         \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(pi),}\AttributeTok{y=} \FunctionTok{expression}\NormalTok{(}\FunctionTok{tilde}\NormalTok{(p)(}\FunctionTok{paste}\NormalTok{(pi,}\StringTok{"|"}\NormalTok{,y,}\StringTok{","}\NormalTok{,NOx[}\DecValTok{1}\NormalTok{],}\StringTok{","}\NormalTok{,TS[}\DecValTok{1}\NormalTok{]))))}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-glm_files/figure-latex/unnamed-chunk-4-1.pdf}

El efecto \(\beta_{12}\) representa el efecto en los log.odds de la mortalidad por infarto de estar en el nivel \(NOx=2\) frente al de estar en el nivel \(NOx=1\). Si queremos evaluar el odds-ratio, simplemente calculamos la distribución posterior de \(exp(\beta_{12})\) con \texttt{inla.tmarginal}. Si sólo estamos interesados en su media, bastaría utilizar `inla.emarginal':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{odds.nox21 }\OtherTok{\textless{}{-}} \FunctionTok{inla.tmarginal}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{exp}\NormalTok{(x), model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"factor(NOx)2"}\NormalTok{)}
\NormalTok{e}\OtherTok{\textless{}{-}}\FunctionTok{inla.emarginal}\NormalTok{(exp, model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"factor(NOx)2"}\NormalTok{)}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(odds.nox21),}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{x,}\AttributeTok{y=}\NormalTok{y))}\SpecialCharTok{+}\FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
        \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\FunctionTok{expression}\NormalTok{(}\FunctionTok{OR}\NormalTok{(NOx[}\DecValTok{21}\NormalTok{])),}\AttributeTok{y=} \FunctionTok{expression}\NormalTok{(}\FunctionTok{tilde}\NormalTok{(p)(}\FunctionTok{paste}\NormalTok{(}\FunctionTok{OR}\NormalTok{(NOx[}\DecValTok{21}\NormalTok{]),}\StringTok{"|"}\NormalTok{,y))))}\SpecialCharTok{+}
        \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{e,}\AttributeTok{color=}\StringTok{"pink"}\NormalTok{)}\SpecialCharTok{+} \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{x=}\NormalTok{e,}\AttributeTok{y=}\DecValTok{1}\NormalTok{,}\AttributeTok{label=}\FunctionTok{paste}\NormalTok{(}\StringTok{"mean="}\NormalTok{,}\FunctionTok{round}\NormalTok{(e,}\DecValTok{3}\NormalTok{)),}\AttributeTok{color=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{03-glm_files/figure-latex/unnamed-chunk-5-1.pdf}
La probabilidad de muerte por infarto se incrementa en un 14.3\% cuando la exposición de NOx cambia del primer al segundo nivel. Los odds-ratio para el resto de los niveles resultan realmente significativos: 11,3\% el odds-ratio NOx3/NOx1, 30\% NOx4/NOx1 y 53.2\% NOx5/NOx1.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{inla.emarginal}\NormalTok{(exp, model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"factor(NOx)3"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.113128}
\FunctionTok{inla.emarginal}\NormalTok{(exp, model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"factor(NOx)4"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.299909}
\FunctionTok{inla.emarginal}\NormalTok{(exp, model.logistic}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\StringTok{"factor(NOx)5"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.532265}
\end{Highlighting}
\end{Shaded}

\hypertarget{regresiuxf3n-de-poisson}{%
\section{Regresión de Poisson}\label{regresiuxf3n-de-poisson}}

La regresión de Poisson es útil cuando la variable respuesta representa conteos y estos toman valores discretos entre 0 y \(+\infty\), sin una cota superior de referencia. El parámetro de interés es el número promedio de eventos \(\lambda_i=E(y_i)\) y el link natural es el logaritmo, de modo que el predictor lineal está ligado con las covariables y factores según:
\[\eta_i=log(\lambda_i)=x_i \beta, \ \ \mbox{ y } \ \ \lambda_i=exp(x_i \beta)\]

Un modelo de Poisson puede especificarse según
\[y_i \sim Po(\lambda_i), i=1,...,n\]
\[\eta_i=log(\lambda_i)=\beta_0+\sum_{m=1}^M \beta_mx_{im}.\]

Para completar el modelo se especifican distribuciones a priori para \(\beta\), típicamente como normales con media cero y una varianza grande cuando no hay información disponible de estudios previos u opinión de expertos.

Los coeficientes se interpretan a través de la función exponencial:

\begin{itemize}
\tightlist
\item
  \(exp(\beta_0)=\lambda_i\) cuando todas las \(x=0\) si son continuas, o para el primer nivel de las categorías posibles si son categóricas.
\item
  \(exp(\beta_m)\) es el cambio que se produce en la respuesta promedio \(y\) cuando \(x_m\) se incrementa en una unidad.
\end{itemize}

La mayoría de las veces que se utiliza la regresión de Poisson, el interés recáe en las ratios o riesgos relativos, más que en el número promedio de casos \(\lambda_i\). Para cambiar la escala en términos de riesgo, ha de utilizarse un offset como factor de corrección en la especificación del modelo. Este offset representa el denominador del riesgo y entra en la regresión en una escala logarítmica, asumiendo que tiene un coeficiente de regresión fijado a 1:
\[\eta_i=log(\lambda_i)=\beta_0+\sum_{m=1}^M \beta_mx_{im}+log(Offset_i)\]
donde el riesgo relativo de que se produzca un evento se obtiene según
\[log\left(\frac{\lambda_i}{Offset_i}\right)=\beta_0+\sum_{m=1}^M \beta_mx_{im}\]
y los coeficientes entonces se interpretan en una escala de riesgo. En este caso al exponenciar la interceptación obtenemos el riesgo base, mientras que \(exp(\beta_m)\) representa el cambio en el riesgo relativo debido a un cambio de unidad en el predictor correspondiente.

\hypertarget{ejemplo-modelo-poisson-incidentes-en-barcos}{%
\subsection{Ejemplo modelo Poisson: incidentes en barcos}\label{ejemplo-modelo-poisson-incidentes-en-barcos}}

Utilizamos los datos \emph{ships.csv} en \href{https://sites.google.com/a/r-inla.org/stbook/datasets}{datasets for SSTM-RINLA} para estimar el riesgo mensual de incidentes en barcos. Los factores potenciales del riesgo son el periodo de construcción (\emph{built}), el periodo de operación (\emph{oper}) y el tipo de barco (\emph{type}).
El modelo se escribe en INLA a continuación, utilizando como offset el \emph{log(months)}, que son los meses que ha navegado y ponderan en consecuencia el riesgo de incidentes. El modelo con el offset será entonces
\[y_i \sim Poisson (E_i \rho_i),\]
donde \(\eta_i=log(\rho_i)\) es el predictor lineal y el promedio del número de incidentes \(\lambda_i=E_i \rho_i\). El offset no se incluye en esta formulación en el predictor lineal.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.dir}\OtherTok{=}\StringTok{"\textasciitilde{}/Dropbox/ESTADISTICA/BAYESIAN/VARIOS/"}
\NormalTok{ShipsIncidents }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file=}\FunctionTok{paste0}\NormalTok{(my.dir,}\StringTok{"Ships.csv"}\NormalTok{),}\AttributeTok{sep=}\StringTok{","}\NormalTok{) }

\NormalTok{formula.inla }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ built }\SpecialCharTok{+}\NormalTok{ oper }\SpecialCharTok{+}\NormalTok{ type}
\NormalTok{model.poisson }\OtherTok{\textless{}{-}} \FunctionTok{inla}\NormalTok{(formula.inla,}\AttributeTok{family=}\StringTok{"poisson"}\NormalTok{, }\AttributeTok{data=}\NormalTok{ShipsIncidents, }\AttributeTok{offset=}\FunctionTok{log}\NormalTok{(months))}

\FunctionTok{round}\NormalTok{(model.poisson}\SpecialCharTok{$}\NormalTok{summary.fixed[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{],}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}               mean    sd 0.025quant 0.5quant 0.975quant}
\CommentTok{\#\textgreater{} (Intercept) {-}6.416 0.217     {-}6.852   {-}6.413     {-}5.998}
\CommentTok{\#\textgreater{} built65{-}69   0.696 0.150      0.406    0.695      0.994}
\CommentTok{\#\textgreater{} built70{-}74   0.819 0.170      0.487    0.818      1.153}
\CommentTok{\#\textgreater{} built75{-}79   0.453 0.233     {-}0.012    0.455      0.903}
\CommentTok{\#\textgreater{} oper75{-}79    0.384 0.118      0.153    0.384      0.617}
\CommentTok{\#\textgreater{} typeB       {-}0.543 0.178     {-}0.882   {-}0.546     {-}0.185}
\CommentTok{\#\textgreater{} typeC       {-}0.688 0.329     {-}1.366   {-}0.678     {-}0.075}
\CommentTok{\#\textgreater{} typeD       {-}0.075 0.291     {-}0.664   {-}0.069      0.476}
\CommentTok{\#\textgreater{} typeE        0.326 0.236     {-}0.141    0.327      0.785}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(model.poisson}\SpecialCharTok{$}\NormalTok{marginals.fixed)}
\CommentTok{\#\textgreater{} [1] "(Intercept)" "built65{-}69"  "built70{-}74"  "built75{-}79" }
\CommentTok{\#\textgreater{} [5] "oper75{-}79"   "typeB"       "typeC"       "typeD"      }
\CommentTok{\#\textgreater{} [9] "typeE"}
\CommentTok{\# ratio medio de incidentes por mes en las categorías base}
\FunctionTok{inla.emarginal}\NormalTok{(exp,model.poisson}\SpecialCharTok{$}\NormalTok{marginals.fixed[[}\DecValTok{1}\NormalTok{]])}
\CommentTok{\#\textgreater{} [1] 0.001674164}
\CommentTok{\# riesgo relativo de barcos tipo E}
\FunctionTok{inla.emarginal}\NormalTok{(exp,model.poisson}\SpecialCharTok{$}\NormalTok{marginals.fixed}\SpecialCharTok{$}\NormalTok{typeE)}
\CommentTok{\#\textgreater{} [1] 1.424414}
\end{Highlighting}
\end{Shaded}

Así, la media de \(exp(\beta_0)\), 0.0018, representa el ratio medio de incidentes por mes entre los barcos que fueron construidos entre el 60 y el 64, han operado entre el 60 y el 74 y son de tipo A (las categorías de referencia). El ratio en 1000 meses sería del 1.8.Para los barcos de tipo E el incremento en el ratio mensual de incidentes, comparado con los de tipo A es del 42,4\%.

Otros datos modelizables con una regresión de Poisson son los que provienen del libro de Andrews and Herzberg y están descritos en (\href{http://www.randomservices.org/random/data/HorseKicks.html}{randomservices.org/random}) consistentes en el número de soldados muertos por coces de caballo en diversos cuerpos de caballería del ejército prusiano, entre 1875 y 1894.

Este modelo se implementa en INLA, a partir de datos simulados, con el siguiente código

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my.dir}\OtherTok{=}\StringTok{"\textasciitilde{}/Dropbox/ESTADISTICA/BAYESIAN/VARIOS/"}
\NormalTok{horse}\OtherTok{\textless{}{-}}\FunctionTok{read.csv}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(my.dir,}\StringTok{"HorseKicks.txt"}\NormalTok{),}\AttributeTok{sep=}\StringTok{""}\NormalTok{, }\AttributeTok{dec=}\StringTok{"."}\NormalTok{,}\AttributeTok{header=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{horse}\SpecialCharTok{$}\NormalTok{sum}\OtherTok{\textless{}{-}}\FunctionTok{apply}\NormalTok{(horse[,}\DecValTok{2}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(horse)],}\DecValTok{1}\NormalTok{,sum)}

\NormalTok{fit}\OtherTok{=}\FunctionTok{inla}\NormalTok{(sum}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}\AttributeTok{data=}\NormalTok{horse,}\AttributeTok{family=}\StringTok{"poisson"}\NormalTok{,}\AttributeTok{control.predictor=}\FunctionTok{list}\NormalTok{(}\AttributeTok{compute=}\ConstantTok{TRUE}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(fit)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{}    c("inla.core(formula = formula, family = family, }
\CommentTok{\#\textgreater{}    contrasts = contrasts, ", " data = data, quantiles = }
\CommentTok{\#\textgreater{}    quantiles, E = E, offset = offset, ", " scale = }
\CommentTok{\#\textgreater{}    scale, weights = weights, Ntrials = Ntrials, strata = }
\CommentTok{\#\textgreater{}    strata, ", " lp.scale = lp.scale, link.covariates = }
\CommentTok{\#\textgreater{}    link.covariates, verbose = verbose, ", " lincomb = }
\CommentTok{\#\textgreater{}    lincomb, selection = selection, control.compute = }
\CommentTok{\#\textgreater{}    control.compute, ", " control.predictor = }
\CommentTok{\#\textgreater{}    control.predictor, control.family = control.family, }
\CommentTok{\#\textgreater{}    ", " control.inla = control.inla, control.fixed = }
\CommentTok{\#\textgreater{}    control.fixed, ", " control.mode = control.mode, }
\CommentTok{\#\textgreater{}    control.expert = control.expert, ", " control.hazard }
\CommentTok{\#\textgreater{}    = control.hazard, control.lincomb = control.lincomb, }
\CommentTok{\#\textgreater{}    ", " control.update = control.update, }
\CommentTok{\#\textgreater{}    control.lp.scale = control.lp.scale, ", " }
\CommentTok{\#\textgreater{}    control.pardiso = control.pardiso, only.hyperparam = }
\CommentTok{\#\textgreater{}    only.hyperparam, ", " inla.call = inla.call, inla.arg }
\CommentTok{\#\textgreater{}    = inla.arg, num.threads = num.threads, ", " }
\CommentTok{\#\textgreater{}    blas.num.threads = blas.num.threads, keep = keep, }
\CommentTok{\#\textgreater{}    working.directory = working.directory, ", " silent = }
\CommentTok{\#\textgreater{}    silent, inla.mode = inla.mode, safe = FALSE, debug = }
\CommentTok{\#\textgreater{}    debug, ", " .parent.frame = .parent.frame)") }
\CommentTok{\#\textgreater{} Time used:}
\CommentTok{\#\textgreater{}     Pre = 2.08, Running = 0.135, Post = 0.00666, Total = 2.22 }
\CommentTok{\#\textgreater{} Fixed effects:}
\CommentTok{\#\textgreater{}              mean    sd 0.025quant 0.5quant 0.975quant mode}
\CommentTok{\#\textgreater{} (Intercept) 2.282 0.071      2.139    2.283       2.42   NA}
\CommentTok{\#\textgreater{}             kld}
\CommentTok{\#\textgreater{} (Intercept)   0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Marginal log{-}Likelihood:  {-}61.30 }
\CommentTok{\#\textgreater{}  is computed }
\CommentTok{\#\textgreater{} Posterior summaries for the linear predictor and the fitted values are computed}
\CommentTok{\#\textgreater{} (Posterior marginals needs also \textquotesingle{}control.compute=list(return.marginals.predictor=TRUE)\textquotesingle{})}
\end{Highlighting}
\end{Shaded}


  \bibliography{book.bib,packages.bib}

\end{document}
